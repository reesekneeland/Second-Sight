{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import numpy as np\n",
    "import argparse\n",
    "import torchvision.transforms as T\n",
    "from data_utils import *\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import pickle\n",
    "import PIL\n",
    "os.chdir(\"..\")\n",
    "from src.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [01:05<00:00,  8.25s/it]\n"
     ]
    }
   ],
   "source": [
    "for subject in tqdm(range(1,9)):\n",
    "    create_whole_region_imagery_unnormalized(subject, mask=True)\n",
    "    create_whole_region_imagery_normalized(subject, mask=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zscore(x, mean=None, stddev=None, return_stats=False):\n",
    "    new_x = x\n",
    "    if mean is not None:\n",
    "        m = mean\n",
    "    else:\n",
    "        m = torch.mean(new_x, axis=0, keepdims=True)\n",
    "    if stddev is not None:\n",
    "        s = stddev\n",
    "    else:\n",
    "        s = torch.std(new_x, axis=0, keepdims=True)\n",
    "    if return_stats:\n",
    "        return (x - m)/(s+1e-6), m, s\n",
    "    else:\n",
    "        x = torch.where(s==0, (new_x - m), (new_x - m)/s)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['meta_dm', 'gdm', 'gcm', 'image_data', 'image_map', 'exps', 'cues', 'modes'])\n"
     ]
    }
   ],
   "source": [
    "# nsd_root = '/export/raid1/home/surly/raid1/kendrick-data/nsd/'\n",
    "# stim_dir = nsd_root + 'nsddata_stimuli/stimuli/nsd/'\n",
    "# beta_dir = nsd_root + 'nsddata_betas/ppdata/'\n",
    "# mask_dir= nsd_root + 'nsddata/ppdata/'\n",
    "# img_stim_file = stim_dir + \"nsdimagery_stimuli.pkl3\"\n",
    "# beta_subj = beta_dir + \"subj%02d/func1pt8mm/nsdimagerybetas_fithrf/betas_nsdimagery.nii.gz\"%subj\n",
    "\n",
    "def image_feature_fn(image):\n",
    "    '''take uint8 image and return floating point (0,1), either color or bw'''\n",
    "    return image.astype(np.float32) / 255\n",
    "\n",
    "## LOAD THE STIM IMAGES AND SEQUENCE ALIGNMENT DESCRIPTORS\n",
    "stim_dir = \"data/nsddata_stimuli/stimuli/nsd/\"\n",
    "img_stim_file = stim_dir + \"nsdimagery_stimuli.pkl3\"\n",
    "ex_file = open(img_stim_file, 'rb')\n",
    "imagery_dict = pickle.load(ex_file)\n",
    "print(imagery_dict.keys())\n",
    "ex_file.close()\n",
    "exps = imagery_dict['exps']\n",
    "cues = imagery_dict['cues']\n",
    "image_map  = imagery_dict['image_map']\n",
    "image_data = imagery_dict['image_data']\n",
    "# for i, im in enumerate(image_data):\n",
    "#     image = Image.fromarray(im.transpose(1,2,0))\n",
    "#     image.save(\"data/nsddata_stimuli/stimuli/imagery_images/{}.png\".format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zscore(x, mean=None, stddev=None, return_stats=False):\n",
    "    if mean is not None:\n",
    "        m = mean\n",
    "    else:\n",
    "        m = np.mean(x, axis=0, keepdims=True)\n",
    "    if stddev is not None:\n",
    "        s = stddev\n",
    "    else:\n",
    "        s = np.std(x, axis=0, keepdims=True)\n",
    "    if return_stats:\n",
    "        return (x - m)/(s+1e-6), m, s\n",
    "    else:\n",
    "        return (x - m)/(s+1e-6)\n",
    "\n",
    "\n",
    "## EXAMPLE CONDITION AVERAGED RESPONSES\n",
    "def condition_average(data, cond):\n",
    "    idx, idx_count = np.unique(cond, return_counts=True)\n",
    "    idx_list = [cond==i for i in np.sort(idx)]\n",
    "    avg_data = np.zeros(shape=(len(idx),)+data.shape[1:], dtype=np.float32)\n",
    "    for i,m in enumerate(idx_list):\n",
    "        avg_data[i] = np.mean(data[m], axis=0)\n",
    "    return avg_data\n",
    "\n",
    "meta_cond_idx = {\n",
    "    'visA': np.arange(len(exps))[exps=='visA'],\n",
    "    'visB': np.arange(len(exps))[exps=='visB'],\n",
    "    'imgA_1': np.arange(len(exps))[exps=='imgA_1'],\n",
    "    'imgA_2': np.arange(len(exps))[exps=='imgA_2'],\n",
    "    'imgB_1': np.arange(len(exps))[exps=='imgB_1'],\n",
    "    'imgB_2': np.arange(len(exps))[exps=='imgB_2']\n",
    "}\n",
    "\n",
    "cond_idx = {\n",
    "    'visA': np.arange(len(exps))[exps=='visA'],\n",
    "    'visB': np.arange(len(exps))[exps=='visB'],\n",
    "    'imgA': np.arange(len(exps))[np.logical_or(exps=='imgA_1', exps=='imgA_2')],\n",
    "    'imgB': np.arange(len(exps))[np.logical_or(exps=='imgB_1', exps=='imgB_2')]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## LOAD THE DATA WITHOUT GLOBAL ZSCORING (EVEN IF IT IS ZSCORED WE ARE GONNA RE-ZSCORE LATER)\n",
    "\n",
    "# voxel_data_raw = {}\n",
    "# subjects = [1,2,3,4,5,6,7,8]\n",
    "# for k,s in enumerate(subjects):\n",
    "#     # print ('--------  subject %d  -------' % s)\n",
    "#     create_whole_region_imagery_unnormalized(s)\n",
    "#     create_whole_region_imagery_normalized(s)\n",
    "    # voxel_data_raw[s] = torch.load(\"data/preprocessed_data/subject{}/nsd_imagery_unnormalized.pt\".format(s))\n",
    "    # print (voxel_data_raw[s].shape)\n",
    "\n",
    "\n",
    "# ## NORMALIZATION OF THE DATA FOR EACH INDIVIDUAL TRIAL\n",
    "# voxel_data_n = {}\n",
    "# for s in voxel_data_raw.keys():\n",
    "#     voxel_data_n[s] = np.copy(voxel_data_raw[s])\n",
    "#     for c,idx in meta_cond_idx.items():\n",
    "#         voxel_data_n[s][idx] = zscore(voxel_data_raw[s][idx])\n",
    "#     print(voxel_data_n[s])\n",
    "\n",
    "\n",
    "# cond_im_idx = {n: [image_map[c] for c in cues[idx]] for n,idx in cond_idx.items()}\n",
    "# ## EXAMPLE USE\n",
    "# for c, idx, im_idx in zip_dict(cond_idx, cond_im_idx): # loop conditions\n",
    "#     data_single = voxel_data_n[s][idx]\n",
    "#     data = condition_average(data_single, im_idx)\n",
    "#     print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([720, 15724])\n",
      "torch.Size([12, 16, 15724]) torch.Size([12, 1024])\n",
      "torch.Size([720, 15724])\n",
      "torch.Size([12, 8, 15724]) torch.Size([12, 1024])\n"
     ]
    }
   ],
   "source": [
    "x, y = load_nsd_mental_imagery(vector = \"c\", subject=1, mode=\"imagery\", stimtype=\"all\", average=False, nest=True)\n",
    "x, y = load_nsd_mental_imagery(vector = \"c\", subject=1, mode=\"vision\", stimtype=\"all\", average=False, nest=True)\n",
    "# x, y = load_nsd_mental_imagery(vector = \"c\", subject=1, mode=\"imagery\", stimtype=\"all\", average=False, nest=True)\n",
    "# x, y = load_nsd_mental_imagery(vector = \"c\", subject=1, mode=\"vision\", stimtype=\"all\", average=False, nest=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 16, 15724]) ['stripes', 'zebra', 'mammal', 'yellow', 'banana', 'fruit']\n"
     ]
    }
   ],
   "source": [
    "vector = \"c\"\n",
    "subject = 1\n",
    "mode = \"imagery\"\n",
    "# stimtype=\"all\"\n",
    "stimtype=\"concepts\"\n",
    "average=False\n",
    "nest=True\n",
    "\n",
    "img_stim_file = \"data/nsddata_stimuli/stimuli/nsd/nsdimagery_stimuli.pkl3\"\n",
    "ex_file = open(img_stim_file, 'rb')\n",
    "imagery_dict = pickle.load(ex_file)\n",
    "ex_file.close()\n",
    "exps = imagery_dict['exps']\n",
    "cues = imagery_dict['cues']\n",
    "image_map  = imagery_dict['image_map']\n",
    "image_data = imagery_dict['image_data']\n",
    "cond_idx = {\n",
    "'visionsimple': np.arange(len(exps))[exps=='visA'],\n",
    "'visioncomplex': np.arange(len(exps))[exps=='visB'],\n",
    "'visionconcepts': np.arange(len(exps))[exps=='visC'],\n",
    "'visionall': np.arange(len(exps))[np.logical_or(exps=='visA', exps=='visB')],\n",
    "'imagerysimple': np.arange(len(exps))[np.logical_or(exps=='imgA_1', exps=='imgA_2')],\n",
    "'imagerycomplex': np.arange(len(exps))[np.logical_or(exps=='imgB_1', exps=='imgB_2')],\n",
    "'imageryconcepts': np.arange(len(exps))[np.logical_or(exps=='imgC_1', exps=='imgC_2')],\n",
    "'imageryall': np.arange(len(exps))[np.logical_or(np.logical_or(exps=='imgA_1', exps=='imgA_2'), np.logical_or(exps=='imgB_1', exps=='imgB_2'))]\n",
    "}\n",
    "x = torch.load(\"data/preprocessed_data/subject{}/nsd_imagery.pt\".format(subject)).requires_grad_(False).to(\"cpu\")\n",
    "if stimtype != \"concepts\":\n",
    "    cond_im_idx = {n: [image_map[c] for c in cues[idx]] for n,idx in cond_idx.items()}\n",
    "    y = torch.load(\"data/preprocessed_data/{}_12.pt\".format(vector)).requires_grad_(False).to(\"cpu\")\n",
    "else:\n",
    "    cond_im_idx = {n: list(cues[idx]) for n,idx in cond_idx.items()}\n",
    "    concept_map = {\"S\" : \"stripes\", \"Z\" :\"zebra\", \"M\" : \"mammal\", \"Y\" : \"yellow\", \"N\" : \"banana\", \"F\" : \"fruit\"}\n",
    "    y = [\"stripes\", \"zebra\", \"mammal\", \"yellow\", \"banana\", \"fruit\"]\n",
    "\n",
    "# Prune down to specific experimental mode/stimuli type\n",
    "x = x[cond_idx[mode+stimtype]]\n",
    "averaged_x, sample_count = condition_average(x, cond_im_idx[mode+stimtype])\n",
    "# Letter cues get sorted out of order, so we need to fix the order\n",
    "trial_count = int(x.shape[0]/sample_count)\n",
    "# Average across trials\n",
    "if average:\n",
    "    x =  averaged_x\n",
    "    if stimtype == \"concepts\":\n",
    "        order = [3, 5, 1, 4, 2, 0]\n",
    "        x = x[order]\n",
    "    x = x.reshape((x.shape[0], 1, x.shape[1]))\n",
    "    \n",
    "elif nest:\n",
    "    x_new = torch.zeros((sample_count, trial_count, x.shape[1]))\n",
    "    for i in range(sample_count):\n",
    "        x_new[i] = x[i*trial_count: i*trial_count + trial_count]\n",
    "    x = x_new\n",
    "\n",
    "\n",
    "if stimtype == \"simple\":\n",
    "    y = y[:sample_count]\n",
    "elif stimtype == \"complex\":\n",
    "    y = y[sample_count:]\n",
    "print(x.shape, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
