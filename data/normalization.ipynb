{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/export/raid1/home/kneel027/miniconda3/envs/SS/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os, sys, shutil\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "from PIL import Image\n",
    "sys.path.append(\"../src\")\n",
    "from utils import *\n",
    "from data_utils import *\n",
    "from autoencoder import AutoEncoder\n",
    "from gnet8_encoder import GNet8_Encoder\n",
    "from matplotlib.lines import Line2D\n",
    "import matplotlib as mpl\n",
    "import math\n",
    "import matplotlib.image as mpimg\n",
    "import random\n",
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading samples: 100%|██████████| 27749/27749 [00:09<00:00, 2813.31it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Shapes... x_train: torch.Size([24979, 15724]), x_val: torch.Size([0]), x_test: torch.Size([982, 3, 15724]), y_train: torch.Size([24979, 541875]), y_val: torch.Size([0]), y_test: torch.Size([982, 541875])\n"
     ]
    }
   ],
   "source": [
    "x_train, x_val, x_test, _, _, images, _ = load_nsd(vector=\"images\", subject=1, loader=False, average=False, nest=True, return_sessions=False, normalized=False, split_val=False, GLM_denoise=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([24979, 15724])\n",
      "tensor(242.8461) tensor(737.2141)\n",
      "tensor(-56.3801) tensor(482.1737)\n",
      "tensor(36.5304) tensor(294.0379)\n",
      "tensor(265.7399) tensor(440.3240)\n",
      "tensor(431.9478) tensor(446.5452)\n",
      "torch.Size([982, 15724])\n"
     ]
    }
   ],
   "source": [
    "train_norm = torch.zeros_like(x_train)\n",
    "test_norm = torch.zeros_like(x_test)\n",
    "print(x_train.shape)\n",
    "for i in range(x_train.shape[1]):\n",
    "    voxel_mean, voxel_std = torch.mean(x_train[:, i]), torch.std(x_train[:, i])  \n",
    "    if i < 5:\n",
    "        print(voxel_mean, voxel_std)\n",
    "    train_norm[:, i] = (x_train[:, i] - voxel_mean) / voxel_std\n",
    "    test_norm[:, :, i] = (x_test[:, :, i] - voxel_mean) / voxel_std\n",
    "test_norm = torch.mean(test_norm, axis=1)\n",
    "print(test_norm.shape)\n",
    "torch.save(test_norm, \"/home/naxos2-raid25/kneel027/home/kneel027/MindEyeV2/subj1test_norm4.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading raw scanning session data:  22%|██▎       | 9/40 [02:18<07:57, 15.39s/it]\n",
      "  0%|          | 0/8 [02:18<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m subject \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m9\u001b[39m)):\n\u001b[0;32m----> 2\u001b[0m     \u001b[43mcreate_whole_region_unnormalized\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubject\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude_heldout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m     create_whole_region_normalized(subject, include_heldout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/export/raid1/home/kneel027/Second-Sight/data/data_utils.py:101\u001b[0m, in \u001b[0;36mcreate_whole_region_unnormalized\u001b[0;34m(subject, include_heldout)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;66;03m# Loads the full collection of beta sessions for subject 1\u001b[39;00m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m,data\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m), desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading raw scanning session data\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 101\u001b[0m     beta \u001b[38;5;241m=\u001b[39m \u001b[43mread_betas\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubject\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msubj0\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msubject\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[43m                            \u001b[49m\u001b[43msession_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mtrial_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# Empty list as index means get all 750 scans for this session (trial --> scan)\u001b[39;49;00m\n\u001b[1;32m    104\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mdata_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbetas_fithrf_GLMdenoise_RR\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    105\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mdata_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfunc1pt8mm\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    107\u001b[0m     \u001b[38;5;66;03m# Reshape the beta trails to be flattened. \u001b[39;00m\n\u001b[1;32m    108\u001b[0m     beta \u001b[38;5;241m=\u001b[39m beta\u001b[38;5;241m.\u001b[39mreshape((nsd_mask\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], beta\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m3\u001b[39m]))\n",
      "File \u001b[0;32m/export/raid1/home/kneel027/Second-Sight/data/data_utils.py:72\u001b[0m, in \u001b[0;36mread_betas\u001b[0;34m(subject, session_index, trial_index, data_type, data_format, mask)\u001b[0m\n\u001b[1;32m     67\u001b[0m data_folder \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/nsddata_betas/ppdata/\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(subject, data_format, data_type)\n\u001b[1;32m     69\u001b[0m si_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(session_index)\u001b[38;5;241m.\u001b[39mzfill(\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     71\u001b[0m out_data \u001b[38;5;241m=\u001b[39m \u001b[43mnb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m---> 72\u001b[0m \u001b[43m    \u001b[49m\u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbetas_session\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43msi_str\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.nii.gz\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_fdata\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(trial_index) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     75\u001b[0m     trial_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mslice\u001b[39m(\u001b[38;5;241m0\u001b[39m, out_data\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n",
      "File \u001b[0;32m/export/raid1/home/kneel027/miniconda3/envs/SS/lib/python3.10/site-packages/nibabel/dataobj_images.py:373\u001b[0m, in \u001b[0;36mDataobjImage.get_fdata\u001b[0;34m(self, caching, dtype)\u001b[0m\n\u001b[1;32m    369\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fdata_cache\n\u001b[1;32m    370\u001b[0m \u001b[38;5;66;03m# Always return requested data type\u001b[39;00m\n\u001b[1;32m    371\u001b[0m \u001b[38;5;66;03m# For array proxies, will attempt to confine data array to dtype\u001b[39;00m\n\u001b[1;32m    372\u001b[0m \u001b[38;5;66;03m# during scaling\u001b[39;00m\n\u001b[0;32m--> 373\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masanyarray\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    374\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m caching \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfill\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    375\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fdata_cache \u001b[38;5;241m=\u001b[39m data\n",
      "File \u001b[0;32m/export/raid1/home/kneel027/miniconda3/envs/SS/lib/python3.10/site-packages/nibabel/arrayproxy.py:439\u001b[0m, in \u001b[0;36mArrayProxy.__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    418\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__array__\u001b[39m(\u001b[38;5;28mself\u001b[39m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    419\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Read data from file and apply scaling, casting to ``dtype``\u001b[39;00m\n\u001b[1;32m    420\u001b[0m \n\u001b[1;32m    421\u001b[0m \u001b[38;5;124;03m    If ``dtype`` is unspecified, the dtype of the returned array is the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[38;5;124;03m        Scaled image data with type `dtype`.\u001b[39;00m\n\u001b[1;32m    438\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 439\u001b[0m     arr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_scaled\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mslicer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    440\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    441\u001b[0m         arr \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m/export/raid1/home/kneel027/miniconda3/envs/SS/lib/python3.10/site-packages/nibabel/arrayproxy.py:408\u001b[0m, in \u001b[0;36mArrayProxy._get_scaled\u001b[0;34m(self, dtype, slicer)\u001b[0m\n\u001b[1;32m    406\u001b[0m scaled \u001b[38;5;241m=\u001b[39m apply_read_scaling(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_unscaled(slicer\u001b[38;5;241m=\u001b[39mslicer), scl_slope, scl_inter)\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 408\u001b[0m     scaled \u001b[38;5;241m=\u001b[39m \u001b[43mscaled\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpromote_types\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscaled\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    409\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m scaled\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for subject in tqdm(range(1,9)):\n",
    "    create_whole_region_unnormalized(subject, include_heldout=True)\n",
    "    create_whole_region_normalized(subject, include_heldout=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "arranging images training data for subject1: 100%|██████████| 30000/30000 [00:53<00:00, 557.61it/s]\n",
      "arranging images training data for subject2: 100%|██████████| 30000/30000 [00:22<00:00, 1359.84it/s]\n",
      "arranging images training data for subject3: 100%|██████████| 24000/24000 [00:33<00:00, 717.94it/s]\n",
      "arranging images training data for subject4: 100%|██████████| 22500/22500 [00:27<00:00, 806.26it/s]\n",
      "arranging images training data for subject5: 100%|██████████| 30000/30000 [00:44<00:00, 674.37it/s]\n",
      "arranging images training data for subject6: 100%|██████████| 24000/24000 [00:27<00:00, 886.81it/s] \n",
      "arranging images training data for subject7: 100%|██████████| 30000/30000 [00:43<00:00, 683.44it/s] \n",
      "arranging images training data for subject8: 100%|██████████| 22500/22500 [00:15<00:00, 1478.43it/s]\n",
      "processing data: 100%|██████████| 8/8 [16:21<00:00, 122.70s/it]\n"
     ]
    }
   ],
   "source": [
    "process_data(vector=\"images\", include_heldout=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([27750, 15724])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading samples: 100%|██████████| 27750/27750 [00:24<00:00, 1145.46it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Shapes... x_train: torch.Size([21217, 15724]), x_val: torch.Size([3763, 15724]), x_test: torch.Size([982, 15724]), y_train: torch.Size([21217, 541875]), y_val: torch.Size([3763, 541875]), y_test: torch.Size([982, 541875])\n",
      "torch.Size([982, 15724]) tensor([[ 0.7171, -0.3140, -0.1861,  ..., -0.3072,  0.5959,  0.2289],\n",
      "        [-0.5112, -0.0537, -0.2221,  ...,  0.9097,  0.2570, -0.1522],\n",
      "        [ 1.1536,  0.8113,  0.3685,  ...,  0.3797,  0.9819,  0.5518],\n",
      "        ...,\n",
      "        [-0.1241, -0.0358,  0.7416,  ..., -0.0606, -0.9639, -0.8716],\n",
      "        [-0.0182, -0.9197, -0.0622,  ..., -0.0695, -0.4521, -0.2796],\n",
      "        [-0.9646, -1.4248, -0.6874,  ..., -0.6318, -0.7369, -0.4036]])\n"
     ]
    }
   ],
   "source": [
    "x_train, x_val, x_test, _, _, images, _ = load_nsd(vector=\"images\", subject=1, loader=False, average=True, nest=False, return_sessions=False, normalized=True, include_heldout=False)\n",
    "print(x_test.shape, x_test)\n",
    "torch.save(x_test, \"/home/naxos2-raid25/kneel027/home/kneel027/MindEyeV2/subj1test_norm5.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_test)\n",
    "print(torch.load(\"/home/naxos2-raid25/kneel027/home/kneel027/Second-Sight/data/preprocessed_data/subject1/nsd_general.pt\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     index  cocoId  cocoSplit                         cropBox     loss  nsdId  \\\n",
      "0     2950  262145  train2017  (0, 0, 0.16640625, 0.16640625)  0.09375   2950   \n",
      "1     2990  262239  train2017    (0, 0, 0.1671875, 0.1671875)  0.10000   2990   \n",
      "2     3049  262414  train2017            (0, 0, 0.125, 0.125)  0.00000   3049   \n",
      "3     3077  524646  train2017    (0, 0, 0.1671875, 0.1671875)  0.00000   3077   \n",
      "4     3146  262690  train2017  (0, 0, 0.16640625, 0.16640625)  0.00000   3146   \n",
      "..     ...     ...        ...                             ...      ...    ...   \n",
      "995  72312  515508  train2017            (0, 0, 0.125, 0.125)  0.00000  72312   \n",
      "996  72510  254130  train2017  (0, 0, 0.16640625, 0.16640625)  0.00000  72510   \n",
      "997  72605  516634  train2017            (0.125, 0.125, 0, 0)  0.00000  72605   \n",
      "998  72719  304627  train2017            (0.125, 0.125, 0, 0)  0.00000  72719   \n",
      "999  72948  517878  train2017      (0, 0, 0.165625, 0.165625)  0.06250  72948   \n",
      "\n",
      "     flagged  BOLD5000  shared1000  subject1  ...  subject5_rep2  \\\n",
      "0      False      True        True         1  ...          27566   \n",
      "1      False      True        True         1  ...          27711   \n",
      "2      False      True        True         1  ...           6697   \n",
      "3      False      True        True         1  ...           4537   \n",
      "4      False      True        True         1  ...          26807   \n",
      "..       ...       ...         ...       ...  ...            ...   \n",
      "995    False      True        True         1  ...           3373   \n",
      "996    False      True        True         1  ...          25310   \n",
      "997    False      True        True         1  ...           7046   \n",
      "998    False      True        True         1  ...          21500   \n",
      "999    False      True        True         1  ...          18694   \n",
      "\n",
      "     subject6_rep0  subject6_rep1  subject6_rep2  subject7_rep0  \\\n",
      "0             2616           9716          27566           2616   \n",
      "1            18458          18697          27711          18458   \n",
      "2             6299           6448           6697           6299   \n",
      "3             4289           4515           4537           4289   \n",
      "4             8087           8443          26807           8087   \n",
      "..             ...            ...            ...            ...   \n",
      "995           2920           3086           3373           2920   \n",
      "996          18619          19110          25310          18619   \n",
      "997           6893           7036           7046           6893   \n",
      "998           2926          11601          21500           2926   \n",
      "999          11127          18664          18694          11127   \n",
      "\n",
      "     subject7_rep1  subject7_rep2  subject8_rep0  subject8_rep1  subject8_rep2  \n",
      "0             9716          27566           2616           9716          27566  \n",
      "1            18697          27711          18458          18697          27711  \n",
      "2             6448           6697           6299           6448           6697  \n",
      "3             4515           4537           4289           4515           4537  \n",
      "4             8443          26807           8087           8443          26807  \n",
      "..             ...            ...            ...            ...            ...  \n",
      "995           3086           3373           2920           3086           3373  \n",
      "996          19110          25310          18619          19110          25310  \n",
      "997           7036           7046           6893           7036           7046  \n",
      "998          11601          21500           2926          11601          21500  \n",
      "999          18664          18694          11127          18664          18694  \n",
      "\n",
      "[1000 rows x 41 columns]\n",
      "(array([0, 1, 2, 3]), array([839, 110,  33,  18]))\n",
      "161 [28, 31, 34, 46, 54, 55, 66, 75, 77, 87, 91, 94, 95, 96, 102, 107, 109, 110, 113, 114, 123, 128, 140, 147, 151, 152, 155, 157, 164, 173, 176, 188, 207, 209, 217, 219, 222, 224, 232, 234, 235, 237, 243, 245, 251, 261, 265, 270, 274, 285, 315, 318, 331, 332, 334, 339, 347, 363, 375, 376, 392, 393, 400, 402, 407, 411, 415, 419, 422, 433, 436, 440, 443, 445, 451, 454, 461, 466, 491, 493, 505, 514, 516, 522, 523, 526, 551, 554, 566, 579, 582, 584, 585, 598, 600, 623, 628, 637, 647, 653, 654, 661, 665, 671, 672, 675, 681, 684, 690, 697, 707, 709, 711, 713, 725, 727, 733, 734, 746, 747, 748, 751, 752, 754, 764, 766, 771, 774, 778, 783, 794, 795, 797, 799, 800, 803, 806, 809, 814, 826, 838, 842, 848, 850, 869, 884, 885, 888, 889, 898, 917, 926, 927, 930, 936, 957, 969, 975, 976, 977, 981]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 2, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 3, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 1, 0, 1, 3, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 3, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 2, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 3, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 2, 0, 0, 0, 2, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 2, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 3, 0, 0, 0, 0, 0, 2, 2, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 3, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 2, 1, 0, 0, 1, 0, 0, 0, 0, 0, 3, 0, 0, 1, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 1, 0, 0, 0, 0, 0, 3, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 3, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 2, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 2, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 3, 0, 0, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 2, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 2, 2, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[46, 55, 66, 91, 110, 151, 393, 514, 516, 582, 637, 681, 725, 733, 752, 814, 826, 885]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 522, 523, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 738, 739, 740, 741, 742, 743, 744, 745, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 896, 897, 898, 899, 900, 901, 903, 904, 905, 906, 907, 908, 909, 910, 911, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961, 962, 963, 964, 965, 966, 967, 968, 969, 970, 971, 972, 973, 974, 975, 976, 977, 978, 979, 980, 981, 982, 983, 984, 985, 986, 987, 988, 989, 990, 991, 992, 993, 994, 995, 996, 997, 998, 999, 1000, 1001, 1002, 1003, 1004, 1005, 1006, 1007, 1008, 1009, 1010, 1011, 1012, 1013, 1014, 1015, 1016, 1017]\n",
      "0 0\n",
      "1 1\n",
      "2 2\n",
      "3 3\n",
      "4 4\n",
      "5 5\n",
      "6 6\n",
      "7 7\n",
      "8 8\n",
      "9 9\n",
      "10 10\n",
      "11 11\n",
      "12 12\n",
      "13 13\n",
      "14 14\n",
      "15 15\n",
      "16 16\n",
      "17 17\n",
      "18 18\n",
      "19 19\n",
      "20 20\n",
      "21 21\n",
      "22 22\n",
      "23 23\n",
      "24 24\n",
      "25 25\n",
      "26 26\n",
      "27 27\n",
      "28 28\n",
      "29 29\n",
      "30 30\n",
      "31 31\n",
      "32 32\n",
      "33 33\n",
      "34 34\n",
      "35 35\n",
      "36 36\n",
      "37 37\n",
      "38 38\n",
      "39 39\n",
      "40 40\n",
      "41 41\n",
      "42 42\n",
      "43 43\n",
      "44 44\n",
      "45 45\n",
      "47 46\n",
      "48 47\n",
      "49 48\n",
      "50 49\n",
      "51 50\n",
      "52 51\n",
      "53 52\n",
      "54 53\n",
      "55 54\n",
      "57 55\n",
      "58 56\n",
      "59 57\n",
      "60 58\n",
      "61 59\n",
      "62 60\n",
      "63 61\n",
      "64 62\n",
      "65 63\n",
      "66 64\n",
      "67 65\n",
      "69 66\n",
      "70 67\n",
      "71 68\n",
      "72 69\n",
      "73 70\n",
      "74 71\n",
      "75 72\n",
      "76 73\n",
      "77 74\n",
      "78 75\n",
      "79 76\n",
      "80 77\n",
      "81 78\n",
      "82 79\n",
      "83 80\n",
      "84 81\n",
      "85 82\n",
      "86 83\n",
      "87 84\n",
      "88 85\n",
      "89 86\n",
      "90 87\n",
      "91 88\n",
      "92 89\n",
      "93 90\n",
      "95 91\n",
      "96 92\n",
      "97 93\n",
      "98 94\n",
      "99 95\n",
      "100 96\n",
      "101 97\n",
      "102 98\n",
      "103 99\n",
      "104 100\n",
      "105 101\n",
      "106 102\n",
      "107 103\n",
      "108 104\n",
      "109 105\n",
      "110 106\n",
      "111 107\n",
      "112 108\n",
      "113 109\n",
      "115 110\n",
      "116 111\n",
      "117 112\n",
      "118 113\n",
      "119 114\n",
      "120 115\n",
      "121 116\n",
      "122 117\n",
      "123 118\n",
      "124 119\n",
      "125 120\n",
      "126 121\n",
      "127 122\n",
      "128 123\n",
      "129 124\n",
      "130 125\n",
      "131 126\n",
      "132 127\n",
      "133 128\n",
      "134 129\n",
      "135 130\n",
      "136 131\n",
      "137 132\n",
      "138 133\n",
      "139 134\n",
      "140 135\n",
      "141 136\n",
      "142 137\n",
      "143 138\n",
      "144 139\n",
      "145 140\n",
      "146 141\n",
      "147 142\n",
      "148 143\n",
      "149 144\n",
      "150 145\n",
      "151 146\n",
      "152 147\n",
      "153 148\n",
      "154 149\n",
      "155 150\n",
      "157 151\n",
      "158 152\n",
      "159 153\n",
      "160 154\n",
      "161 155\n",
      "162 156\n",
      "163 157\n",
      "164 158\n",
      "165 159\n",
      "166 160\n",
      "167 161\n",
      "168 162\n",
      "169 163\n",
      "170 164\n",
      "171 165\n",
      "172 166\n",
      "173 167\n",
      "174 168\n",
      "175 169\n",
      "176 170\n",
      "177 171\n",
      "178 172\n",
      "179 173\n",
      "180 174\n",
      "181 175\n",
      "182 176\n",
      "183 177\n",
      "184 178\n",
      "185 179\n",
      "186 180\n",
      "187 181\n",
      "188 182\n",
      "189 183\n",
      "190 184\n",
      "191 185\n",
      "192 186\n",
      "193 187\n",
      "194 188\n",
      "195 189\n",
      "196 190\n",
      "197 191\n",
      "198 192\n",
      "199 193\n",
      "200 194\n",
      "201 195\n",
      "202 196\n",
      "203 197\n",
      "204 198\n",
      "205 199\n",
      "206 200\n",
      "207 201\n",
      "208 202\n",
      "209 203\n",
      "210 204\n",
      "211 205\n",
      "212 206\n",
      "213 207\n",
      "214 208\n",
      "215 209\n",
      "216 210\n",
      "217 211\n",
      "218 212\n",
      "219 213\n",
      "220 214\n",
      "221 215\n",
      "222 216\n",
      "223 217\n",
      "224 218\n",
      "225 219\n",
      "226 220\n",
      "227 221\n",
      "228 222\n",
      "229 223\n",
      "230 224\n",
      "231 225\n",
      "232 226\n",
      "233 227\n",
      "234 228\n",
      "235 229\n",
      "236 230\n",
      "237 231\n",
      "238 232\n",
      "239 233\n",
      "240 234\n",
      "241 235\n",
      "242 236\n",
      "243 237\n",
      "244 238\n",
      "245 239\n",
      "246 240\n",
      "247 241\n",
      "248 242\n",
      "249 243\n",
      "250 244\n",
      "251 245\n",
      "252 246\n",
      "253 247\n",
      "254 248\n",
      "255 249\n",
      "256 250\n",
      "257 251\n",
      "258 252\n",
      "259 253\n",
      "260 254\n",
      "261 255\n",
      "262 256\n",
      "263 257\n",
      "264 258\n",
      "265 259\n",
      "266 260\n",
      "267 261\n",
      "268 262\n",
      "269 263\n",
      "270 264\n",
      "271 265\n",
      "272 266\n",
      "273 267\n",
      "274 268\n",
      "275 269\n",
      "276 270\n",
      "277 271\n",
      "278 272\n",
      "279 273\n",
      "280 274\n",
      "281 275\n",
      "282 276\n",
      "283 277\n",
      "284 278\n",
      "285 279\n",
      "286 280\n",
      "287 281\n",
      "288 282\n",
      "289 283\n",
      "290 284\n",
      "291 285\n",
      "292 286\n",
      "293 287\n",
      "294 288\n",
      "295 289\n",
      "296 290\n",
      "297 291\n",
      "298 292\n",
      "299 293\n",
      "300 294\n",
      "301 295\n",
      "302 296\n",
      "303 297\n",
      "304 298\n",
      "305 299\n",
      "306 300\n",
      "307 301\n",
      "308 302\n",
      "309 303\n",
      "310 304\n",
      "311 305\n",
      "312 306\n",
      "313 307\n",
      "314 308\n",
      "315 309\n",
      "316 310\n",
      "317 311\n",
      "318 312\n",
      "319 313\n",
      "320 314\n",
      "321 315\n",
      "322 316\n",
      "323 317\n",
      "324 318\n",
      "325 319\n",
      "326 320\n",
      "327 321\n",
      "328 322\n",
      "329 323\n",
      "330 324\n",
      "331 325\n",
      "332 326\n",
      "333 327\n",
      "334 328\n",
      "335 329\n",
      "336 330\n",
      "337 331\n",
      "338 332\n",
      "339 333\n",
      "340 334\n",
      "341 335\n",
      "342 336\n",
      "343 337\n",
      "344 338\n",
      "345 339\n",
      "346 340\n",
      "347 341\n",
      "348 342\n",
      "349 343\n",
      "350 344\n",
      "351 345\n",
      "352 346\n",
      "353 347\n",
      "354 348\n",
      "355 349\n",
      "356 350\n",
      "357 351\n",
      "358 352\n",
      "359 353\n",
      "360 354\n",
      "361 355\n",
      "362 356\n",
      "363 357\n",
      "364 358\n",
      "365 359\n",
      "366 360\n",
      "367 361\n",
      "368 362\n",
      "369 363\n",
      "370 364\n",
      "371 365\n",
      "372 366\n",
      "373 367\n",
      "374 368\n",
      "375 369\n",
      "376 370\n",
      "377 371\n",
      "378 372\n",
      "379 373\n",
      "380 374\n",
      "381 375\n",
      "382 376\n",
      "383 377\n",
      "384 378\n",
      "385 379\n",
      "386 380\n",
      "387 381\n",
      "388 382\n",
      "389 383\n",
      "390 384\n",
      "391 385\n",
      "392 386\n",
      "393 387\n",
      "394 388\n",
      "395 389\n",
      "396 390\n",
      "397 391\n",
      "398 392\n",
      "400 393\n",
      "401 394\n",
      "402 395\n",
      "403 396\n",
      "404 397\n",
      "405 398\n",
      "406 399\n",
      "407 400\n",
      "408 401\n",
      "409 402\n",
      "410 403\n",
      "411 404\n",
      "412 405\n",
      "413 406\n",
      "414 407\n",
      "415 408\n",
      "416 409\n",
      "417 410\n",
      "418 411\n",
      "419 412\n",
      "420 413\n",
      "421 414\n",
      "422 415\n",
      "423 416\n",
      "424 417\n",
      "425 418\n",
      "426 419\n",
      "427 420\n",
      "428 421\n",
      "429 422\n",
      "430 423\n",
      "431 424\n",
      "432 425\n",
      "433 426\n",
      "434 427\n",
      "435 428\n",
      "436 429\n",
      "437 430\n",
      "438 431\n",
      "439 432\n",
      "440 433\n",
      "441 434\n",
      "442 435\n",
      "443 436\n",
      "444 437\n",
      "445 438\n",
      "446 439\n",
      "447 440\n",
      "448 441\n",
      "449 442\n",
      "450 443\n",
      "451 444\n",
      "452 445\n",
      "453 446\n",
      "454 447\n",
      "455 448\n",
      "456 449\n",
      "457 450\n",
      "458 451\n",
      "459 452\n",
      "460 453\n",
      "461 454\n",
      "462 455\n",
      "463 456\n",
      "464 457\n",
      "465 458\n",
      "466 459\n",
      "467 460\n",
      "468 461\n",
      "469 462\n",
      "470 463\n",
      "471 464\n",
      "472 465\n",
      "473 466\n",
      "474 467\n",
      "475 468\n",
      "476 469\n",
      "477 470\n",
      "478 471\n",
      "479 472\n",
      "480 473\n",
      "481 474\n",
      "482 475\n",
      "483 476\n",
      "484 477\n",
      "485 478\n",
      "486 479\n",
      "487 480\n",
      "488 481\n",
      "489 482\n",
      "490 483\n",
      "491 484\n",
      "492 485\n",
      "493 486\n",
      "494 487\n",
      "495 488\n",
      "496 489\n",
      "497 490\n",
      "498 491\n",
      "499 492\n",
      "500 493\n",
      "501 494\n",
      "502 495\n",
      "503 496\n",
      "504 497\n",
      "505 498\n",
      "506 499\n",
      "507 500\n",
      "508 501\n",
      "509 502\n",
      "510 503\n",
      "511 504\n",
      "512 505\n",
      "513 506\n",
      "514 507\n",
      "515 508\n",
      "516 509\n",
      "517 510\n",
      "518 511\n",
      "519 512\n",
      "520 513\n",
      "522 514\n",
      "523 515\n",
      "525 516\n",
      "526 517\n",
      "527 518\n",
      "528 519\n",
      "529 520\n",
      "530 521\n",
      "531 522\n",
      "532 523\n",
      "533 524\n",
      "534 525\n",
      "535 526\n",
      "536 527\n",
      "537 528\n",
      "538 529\n",
      "539 530\n",
      "540 531\n",
      "541 532\n",
      "542 533\n",
      "543 534\n",
      "544 535\n",
      "545 536\n",
      "546 537\n",
      "547 538\n",
      "548 539\n",
      "549 540\n",
      "550 541\n",
      "551 542\n",
      "552 543\n",
      "553 544\n",
      "554 545\n",
      "555 546\n",
      "556 547\n",
      "557 548\n",
      "558 549\n",
      "559 550\n",
      "560 551\n",
      "561 552\n",
      "562 553\n",
      "563 554\n",
      "564 555\n",
      "565 556\n",
      "566 557\n",
      "567 558\n",
      "568 559\n",
      "569 560\n",
      "570 561\n",
      "571 562\n",
      "572 563\n",
      "573 564\n",
      "574 565\n",
      "575 566\n",
      "576 567\n",
      "577 568\n",
      "578 569\n",
      "579 570\n",
      "580 571\n",
      "581 572\n",
      "582 573\n",
      "583 574\n",
      "584 575\n",
      "585 576\n",
      "586 577\n",
      "587 578\n",
      "588 579\n",
      "589 580\n",
      "590 581\n",
      "592 582\n",
      "593 583\n",
      "594 584\n",
      "595 585\n",
      "596 586\n",
      "597 587\n",
      "598 588\n",
      "599 589\n",
      "600 590\n",
      "601 591\n",
      "602 592\n",
      "603 593\n",
      "604 594\n",
      "605 595\n",
      "606 596\n",
      "607 597\n",
      "608 598\n",
      "609 599\n",
      "610 600\n",
      "611 601\n",
      "612 602\n",
      "613 603\n",
      "614 604\n",
      "615 605\n",
      "616 606\n",
      "617 607\n",
      "618 608\n",
      "619 609\n",
      "620 610\n",
      "621 611\n",
      "622 612\n",
      "623 613\n",
      "624 614\n",
      "625 615\n",
      "626 616\n",
      "627 617\n",
      "628 618\n",
      "629 619\n",
      "630 620\n",
      "631 621\n",
      "632 622\n",
      "633 623\n",
      "634 624\n",
      "635 625\n",
      "636 626\n",
      "637 627\n",
      "638 628\n",
      "639 629\n",
      "640 630\n",
      "641 631\n",
      "642 632\n",
      "643 633\n",
      "644 634\n",
      "645 635\n",
      "646 636\n",
      "648 637\n",
      "649 638\n",
      "650 639\n",
      "651 640\n",
      "652 641\n",
      "653 642\n",
      "654 643\n",
      "655 644\n",
      "656 645\n",
      "657 646\n",
      "658 647\n",
      "659 648\n",
      "660 649\n",
      "661 650\n",
      "662 651\n",
      "663 652\n",
      "664 653\n",
      "665 654\n",
      "666 655\n",
      "667 656\n",
      "668 657\n",
      "669 658\n",
      "670 659\n",
      "671 660\n",
      "672 661\n",
      "673 662\n",
      "674 663\n",
      "675 664\n",
      "676 665\n",
      "677 666\n",
      "678 667\n",
      "679 668\n",
      "680 669\n",
      "681 670\n",
      "682 671\n",
      "683 672\n",
      "684 673\n",
      "685 674\n",
      "686 675\n",
      "687 676\n",
      "688 677\n",
      "689 678\n",
      "690 679\n",
      "691 680\n",
      "693 681\n",
      "694 682\n",
      "695 683\n",
      "696 684\n",
      "697 685\n",
      "698 686\n",
      "699 687\n",
      "700 688\n",
      "701 689\n",
      "702 690\n",
      "703 691\n",
      "704 692\n",
      "705 693\n",
      "706 694\n",
      "707 695\n",
      "708 696\n",
      "709 697\n",
      "710 698\n",
      "711 699\n",
      "712 700\n",
      "713 701\n",
      "714 702\n",
      "715 703\n",
      "716 704\n",
      "717 705\n",
      "718 706\n",
      "719 707\n",
      "720 708\n",
      "721 709\n",
      "722 710\n",
      "723 711\n",
      "724 712\n",
      "725 713\n",
      "726 714\n",
      "727 715\n",
      "728 716\n",
      "729 717\n",
      "730 718\n",
      "731 719\n",
      "732 720\n",
      "733 721\n",
      "734 722\n",
      "735 723\n",
      "736 724\n",
      "738 725\n",
      "739 726\n",
      "740 727\n",
      "741 728\n",
      "742 729\n",
      "743 730\n",
      "744 731\n",
      "745 732\n",
      "747 733\n",
      "748 734\n",
      "749 735\n",
      "750 736\n",
      "751 737\n",
      "752 738\n",
      "753 739\n",
      "754 740\n",
      "755 741\n",
      "756 742\n",
      "757 743\n",
      "758 744\n",
      "759 745\n",
      "760 746\n",
      "761 747\n",
      "762 748\n",
      "763 749\n",
      "764 750\n",
      "765 751\n",
      "767 752\n",
      "768 753\n",
      "769 754\n",
      "770 755\n",
      "771 756\n",
      "772 757\n",
      "773 758\n",
      "774 759\n",
      "775 760\n",
      "776 761\n",
      "777 762\n",
      "778 763\n",
      "779 764\n",
      "780 765\n",
      "781 766\n",
      "782 767\n",
      "783 768\n",
      "784 769\n",
      "785 770\n",
      "786 771\n",
      "787 772\n",
      "788 773\n",
      "789 774\n",
      "790 775\n",
      "791 776\n",
      "792 777\n",
      "793 778\n",
      "794 779\n",
      "795 780\n",
      "796 781\n",
      "797 782\n",
      "798 783\n",
      "799 784\n",
      "800 785\n",
      "801 786\n",
      "802 787\n",
      "803 788\n",
      "804 789\n",
      "805 790\n",
      "806 791\n",
      "807 792\n",
      "808 793\n",
      "809 794\n",
      "810 795\n",
      "811 796\n",
      "812 797\n",
      "813 798\n",
      "814 799\n",
      "815 800\n",
      "816 801\n",
      "817 802\n",
      "818 803\n",
      "819 804\n",
      "820 805\n",
      "821 806\n",
      "822 807\n",
      "823 808\n",
      "824 809\n",
      "825 810\n",
      "826 811\n",
      "827 812\n",
      "828 813\n",
      "830 814\n",
      "831 815\n",
      "832 816\n",
      "833 817\n",
      "834 818\n",
      "835 819\n",
      "836 820\n",
      "837 821\n",
      "838 822\n",
      "839 823\n",
      "840 824\n",
      "841 825\n",
      "843 826\n",
      "844 827\n",
      "845 828\n",
      "846 829\n",
      "847 830\n",
      "848 831\n",
      "849 832\n",
      "850 833\n",
      "851 834\n",
      "852 835\n",
      "853 836\n",
      "854 837\n",
      "855 838\n",
      "856 839\n",
      "857 840\n",
      "858 841\n",
      "859 842\n",
      "860 843\n",
      "861 844\n",
      "862 845\n",
      "863 846\n",
      "864 847\n",
      "865 848\n",
      "866 849\n",
      "867 850\n",
      "868 851\n",
      "869 852\n",
      "870 853\n",
      "871 854\n",
      "872 855\n",
      "873 856\n",
      "874 857\n",
      "875 858\n",
      "876 859\n",
      "877 860\n",
      "878 861\n",
      "879 862\n",
      "880 863\n",
      "881 864\n",
      "882 865\n",
      "883 866\n",
      "884 867\n",
      "885 868\n",
      "886 869\n",
      "887 870\n",
      "888 871\n",
      "889 872\n",
      "890 873\n",
      "891 874\n",
      "892 875\n",
      "893 876\n",
      "894 877\n",
      "895 878\n",
      "896 879\n",
      "897 880\n",
      "898 881\n",
      "899 882\n",
      "900 883\n",
      "901 884\n",
      "903 885\n",
      "904 886\n",
      "905 887\n",
      "906 888\n",
      "907 889\n",
      "908 890\n",
      "909 891\n",
      "910 892\n",
      "911 893\n",
      "912 894\n",
      "913 895\n",
      "914 896\n",
      "915 897\n",
      "916 898\n",
      "917 899\n",
      "918 900\n",
      "919 901\n",
      "920 902\n",
      "921 903\n",
      "922 904\n",
      "923 905\n",
      "924 906\n",
      "925 907\n",
      "926 908\n",
      "927 909\n",
      "928 910\n",
      "929 911\n",
      "930 912\n",
      "931 913\n",
      "932 914\n",
      "933 915\n",
      "934 916\n",
      "935 917\n",
      "936 918\n",
      "937 919\n",
      "938 920\n",
      "939 921\n",
      "940 922\n",
      "941 923\n",
      "942 924\n",
      "943 925\n",
      "944 926\n",
      "945 927\n",
      "946 928\n",
      "947 929\n",
      "948 930\n",
      "949 931\n",
      "950 932\n",
      "951 933\n",
      "952 934\n",
      "953 935\n",
      "954 936\n",
      "955 937\n",
      "956 938\n",
      "957 939\n",
      "958 940\n",
      "959 941\n",
      "960 942\n",
      "961 943\n",
      "962 944\n",
      "963 945\n",
      "964 946\n",
      "965 947\n",
      "966 948\n",
      "967 949\n",
      "968 950\n",
      "969 951\n",
      "970 952\n",
      "971 953\n",
      "972 954\n",
      "973 955\n",
      "974 956\n",
      "975 957\n",
      "976 958\n",
      "977 959\n",
      "978 960\n",
      "979 961\n",
      "980 962\n",
      "981 963\n",
      "982 964\n",
      "983 965\n",
      "984 966\n",
      "985 967\n",
      "986 968\n",
      "987 969\n",
      "988 970\n",
      "989 971\n",
      "990 972\n",
      "991 973\n",
      "992 974\n",
      "993 975\n",
      "994 976\n",
      "995 977\n",
      "996 978\n",
      "997 979\n",
      "998 980\n",
      "999 981\n",
      "1000 982\n",
      "1001 983\n",
      "1002 984\n",
      "1003 985\n",
      "1004 986\n",
      "1005 987\n",
      "1006 988\n",
      "1007 989\n",
      "1008 990\n",
      "1009 991\n",
      "1010 992\n",
      "1011 993\n",
      "1012 994\n",
      "1013 995\n",
      "1014 996\n",
      "1015 997\n",
      "1016 998\n",
      "1017 999\n"
     ]
    }
   ],
   "source": [
    "subject=1\n",
    "stim_descriptions = pd.read_csv('data/nsddata/experiments/nsd/nsd_stim_info_merged.csv', index_col=0)\n",
    "subj_train = stim_descriptions[(stim_descriptions['subject{}'.format(subject)] != 0) & (stim_descriptions['shared1000'] == True)]\n",
    "subj_test = stim_descriptions[(stim_descriptions['subject{}'.format(subject)] != 0) & (stim_descriptions['shared1000'] == True)].reset_index()\n",
    "print(subj_test)\n",
    "scanIDs = [0]*1000\n",
    "for i in range(subj_train.shape[0]):\n",
    "    nsdID = subj_train.iloc[i]['nsdId']\n",
    "    for j in range(3):\n",
    "        scanID = subj_train.iloc[i]['subject{}_rep{}'.format(subject, j)] - 1\n",
    "        if scanID > 37*750:\n",
    "            shared1000idx = subj_test[subj_test['nsdId'] == nsdID].index\n",
    "            # print(shared1000idx, shared1000idx[0])\n",
    "            scanIDs[int(shared1000idx[0])] += 1\n",
    "print(np.unique(scanIDs, return_counts=True))\n",
    "indices = [i for i, value in enumerate(scanIDs) if value > 0]\n",
    "missing = [i for i, value in enumerate(scanIDs) if value == 3]\n",
    "print(len(indices), indices)\n",
    "print(scanIDs)\n",
    "print(missing)\n",
    "\n",
    "# incomplete_ids = []\n",
    "# for nsdId, count in scanIDs.items():\n",
    "#     if count != 3:\n",
    "#         shared1000idx = subj_test[subj_test['nsdId'] == nsdId].index\n",
    "#         incomplete_ids.append(shared1000idx.astype(int))\n",
    "# incomplete_ids = list(np.concatenate(incomplete_ids))\n",
    "# print(len(incomplete_ids), incomplete_ids)\n",
    "adjustment_idx = []\n",
    "swap_margin = 0\n",
    "for i in range(1000):\n",
    "    if scanIDs[i] == 3:\n",
    "        swap_margin += 1\n",
    "    adjustment_idx.append(i+swap_margin)\n",
    "print(adjustment_idx)\n",
    "incrementidx = [j for j in range(1000)]\n",
    "for i, j in zip(adjustment_idx, incrementidx):\n",
    "    print(i, j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "# Load the file\n",
    "# data = torch.load(\"data/preprocessed_data/subject1/nsd_general_large.pt\")\n",
    "# print(data[:,0].mean(), data[:,0].std())\n",
    "# Save it in HDF5 format\n",
    "# with h5py.File(\"/home/naxos2-raid25/kneel027/home/kneel027/MindEyeV2/new_betas/betas_all_subj01_fp32_renorm.hdf5\", \"w\") as f:\n",
    "#     f.create_dataset(\"betas\", data=data.numpy())\n",
    "    \n",
    "    \n",
    "# Open the HDF5 file\n",
    "file_path = \"/home/naxos2-raid25/kneel027/home/kneel027/MindEyeV2/new_betas/betas_all_subj01_fp32_renorm copy.hdf5\"\n",
    "file_path2 = \"/home/naxos2-raid25/kneel027/home/kneel027/MindEyeV2/new_betas/betas_all_subj01_fp32_renorm.hdf5\"\n",
    "with h5py.File(file_path, \"r\") as f:\n",
    "    with h5py.File(file_path2, \"r\") as f2:\n",
    "    # Access the data or perform operations on the file\n",
    "    # For example, you can print the keys of the datasets in the file\n",
    "        are_equal = np.array_equal(f[\"betas\"], f2[\"betas\"])\n",
    "        print(are_equal)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
