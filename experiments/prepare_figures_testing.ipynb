{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"3\"\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "from PIL import Image\n",
    "sys.path.append('../src')\n",
    "from utils import *\n",
    "from matplotlib.lines import Line2D\n",
    "import matplotlib as mpl\n",
    "import math\n",
    "import matplotlib.image as mpimg\n",
    "import scipy.stats as stats\n",
    "import scipy as sp\n",
    "from scipy.stats import pearsonr,binom,linregress\n",
    "from ast import literal_eval\n",
    "import json\n",
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def column_string_to_list(df):\n",
    "    df_new = df\n",
    "    \n",
    "    for index, row in tqdm(df.iterrows(), \"creating lists\"):\n",
    "        df_new.at[index, 'CLIP Two-way']    = json.loads(row['CLIP Two-way'])\n",
    "        df_new.at[index, 'AlexNet 2']       = json.loads(row['AlexNet 2'])\n",
    "        df_new.at[index, 'AlexNet 5']       = json.loads(row['AlexNet 5'])\n",
    "        df_new.at[index, 'AlexNet 7']       = json.loads(row['AlexNet 7'])\n",
    "        df_new.at[index, 'Inception V3']    = json.loads(row['Inception V3'])\n",
    "        df_new.at[index, 'EffNet-B']        = json.loads(row['EffNet-B'])\n",
    "        df_new.at[index, 'SwAV']            = json.loads(row['SwAV'])\n",
    "        \n",
    "    return df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "creating lists: 84it [00:02, 29.14it/s]\n",
      "creating lists: 84it [00:02, 29.00it/s]\n",
      "creating lists: 84it [00:03, 27.24it/s]\n",
      "creating lists: 84it [00:02, 28.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Unnamed: 0  ID  Sample Count  Batch Number  Sample Indicator  Strength  \\\n",
      "0            0   0           NaN           NaN                10       NaN   \n",
      "1            1   0           NaN           NaN                11       NaN   \n",
      "2            2   0           0.0           NaN                12       NaN   \n",
      "3            3   0           1.0           NaN                12       NaN   \n",
      "4            4   0           2.0           NaN                12       NaN   \n",
      "..         ...  ..           ...           ...               ...       ...   \n",
      "79          79  11           0.0           NaN                12       NaN   \n",
      "80          80  11           1.0           NaN                12       NaN   \n",
      "81          81  11           2.0           NaN                12       NaN   \n",
      "82          82  11           3.0           NaN                12       NaN   \n",
      "83          83  11           4.0           NaN                12       NaN   \n",
      "\n",
      "    Brain Correlation V1  Brain Correlation V2  Brain Correlation V3  \\\n",
      "0               0.458491              0.465391              0.448230   \n",
      "1              -0.052848             -0.127699              0.009851   \n",
      "2              -0.018327             -0.013752             -0.024114   \n",
      "3               0.255337              0.293315              0.214294   \n",
      "4               0.113883              0.015459             -0.148342   \n",
      "..                   ...                   ...                   ...   \n",
      "79              0.098284              0.331293              0.080895   \n",
      "80              0.032696              0.310425              0.209231   \n",
      "81              0.221193              0.312306              0.124597   \n",
      "82              0.430688              0.221724              0.030767   \n",
      "83              0.349505              0.347301              0.169452   \n",
      "\n",
      "    Brain Correlation V4  ...      SSIM  Pixel Correlation  CLIP Cosine  \\\n",
      "0               0.453340  ...  1.000000           1.000000     1.000000   \n",
      "1               0.023714  ...  0.107119          -0.057165     0.595924   \n",
      "2              -0.179317  ...  0.337575          -0.102631     0.541792   \n",
      "3              -0.079733  ...  0.235451          -0.053662     0.613814   \n",
      "4              -0.128784  ...  0.363775          -0.092190     0.465748   \n",
      "..                   ...  ...       ...                ...          ...   \n",
      "79              0.298135  ...  0.096763          -0.198030     0.563439   \n",
      "80              0.266840  ...  0.098437          -0.288506     0.613621   \n",
      "81              0.481203  ...  0.072143          -0.264537     0.516961   \n",
      "82              0.159925  ...  0.098275          -0.216894     0.517278   \n",
      "83              0.361710  ...  0.080048          -0.249059     0.491803   \n",
      "\n",
      "                                         CLIP Two-way  \\\n",
      "0   [-0.12636740505695343, 0.7458265423774719, -0....   \n",
      "1   [0.3047230839729309, -0.08027887344360352, -0....   \n",
      "2   [0.23303860425949097, 0.5614702701568604, 0.09...   \n",
      "3   [0.4010815918445587, 0.594423770904541, -0.250...   \n",
      "4   [0.534762442111969, 0.3701360821723938, -0.045...   \n",
      "..                                                ...   \n",
      "79  [0.8338737487792969, 0.3309897184371948, -0.31...   \n",
      "80  [0.5139117240905762, -0.0864284485578537, 0.08...   \n",
      "81  [0.3845705986022949, 0.3075058162212372, -0.37...   \n",
      "82  [0.4693911671638489, 0.8052582740783691, -0.55...   \n",
      "83  [0.3035767078399658, 0.5762424468994141, -0.68...   \n",
      "\n",
      "                                            AlexNet 2  \\\n",
      "0   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "1   [12.063179016113281, 0.0, 0.0, 1.3012562990188...   \n",
      "2   [1.7960162162780762, 0.1017972007393837, 0.0, ...   \n",
      "3   [5.10131311416626, 0.0, 1.2943053245544434, 5....   \n",
      "4   [5.943284034729004, 2.023167610168457, 0.0, 0....   \n",
      "..                                                ...   \n",
      "79  [4.585059642791748, 4.819113731384277, 4.50312...   \n",
      "80  [1.3982335329055786, 1.1308050155639648, 0.450...   \n",
      "81  [0.3552761375904083, 0.20368337631225586, 0.0,...   \n",
      "82  [1.7891470193862915, 0.027787260711193085, 0.0...   \n",
      "83  [5.496029376983643, 1.3297605514526367, 0.0, 3...   \n",
      "\n",
      "                                            AlexNet 5  \\\n",
      "0   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "1   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "2   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "3   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "4   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "..                                                ...   \n",
      "79  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "80  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "81  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "82  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "83  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "\n",
      "                                            AlexNet 7  \\\n",
      "0   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "1   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "2   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "3   [0.0, 1.8231995105743408, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "4   [0.0, 0.0, 0.0, 0.0, 1.7447408437728882, 0.0, ...   \n",
      "..                                                ...   \n",
      "79  [0.0, 0.0, 0.0, 0.0, 0.051367003470659256, 0.0...   \n",
      "80  [0.0, 0.0, 0.0, 0.0, 1.5109704732894897, 0.0, ...   \n",
      "81  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.1900072097778...   \n",
      "82  [0.0, 0.0, 0.0, 0.0, 0.4174327254295349, 0.0, ...   \n",
      "83  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8655006289482...   \n",
      "\n",
      "                                         Inception V3  \\\n",
      "0   [0.5798888206481934, 0.001762425061315298, 0.0...   \n",
      "1   [1.4989161491394043, 0.06554390490055084, 1.78...   \n",
      "2   [0.6055394411087036, 0.1532532423734665, 0.646...   \n",
      "3   [0.3023679554462433, 0.029366282746195793, 0.0...   \n",
      "4   [0.12731821835041046, 0.28222689032554626, 0.1...   \n",
      "..                                                ...   \n",
      "79  [1.3795139789581299, 0.9674606323242188, 1.228...   \n",
      "80  [0.375618040561676, 1.9294111728668213, 1.2639...   \n",
      "81  [0.641642153263092, 1.1252812147140503, 0.1737...   \n",
      "82  [0.7425933480262756, 0.6761474609375, 0.617125...   \n",
      "83  [0.16142064332962036, 0.395068496465683, 0.278...   \n",
      "\n",
      "                                             EffNet-B  \\\n",
      "0   [-0.21931815147399902, -0.2251397669315338, -0...   \n",
      "1   [0.1334487497806549, -0.1553211659193039, -0.1...   \n",
      "2   [-0.06709454208612442, -0.13299822807312012, 0...   \n",
      "3   [-0.0831158459186554, -0.13151398301124573, -0...   \n",
      "4   [0.8528410792350769, -0.11659351736307144, -0....   \n",
      "..                                                ...   \n",
      "79  [0.11553211510181427, 0.3050263226032257, 0.77...   \n",
      "80  [0.061408478766679764, -0.10594585537910461, 0...   \n",
      "81  [0.05952707305550575, 0.18555621802806854, 0.4...   \n",
      "82  [0.21248240768909454, 0.19034068286418915, 0.3...   \n",
      "83  [0.5158725380897522, 0.8936625719070435, 0.254...   \n",
      "\n",
      "                                                 SwAV  \n",
      "0   [0.0, 0.0, 0.0, 0.00012018125562462956, 0.0689...  \n",
      "1   [0.010303100571036339, 0.0, 0.0093342652544379...  \n",
      "2   [0.04516725242137909, 0.0, 0.03301269933581352...  \n",
      "3   [0.013846187852323055, 0.03325137868523598, 0....  \n",
      "4   [0.14729371666908264, 0.003904922166839242, 0....  \n",
      "..                                                ...  \n",
      "79  [0.18055063486099243, 0.05714978277683258, 0.0...  \n",
      "80  [0.11496221274137497, 0.011517089791595936, 0....  \n",
      "81  [0.11528719216585159, 0.15534739196300507, 0.0...  \n",
      "82  [0.15056075155735016, 0.09389893710613251, 0.0...  \n",
      "83  [0.25882673263549805, 0.07133975625038147, 0.0...  \n",
      "\n",
      "[336 rows x 23 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Mental Imagery Paper\n",
    "method = \"tagaki\"\n",
    "mode = \"vision\"\n",
    "\n",
    "directory_path = f\"output/mental_imagery_paper/{mode}/{method}/subject1_statistics_12.csv\"\n",
    "df = pd.read_csv(directory_path)\n",
    "df = column_string_to_list(df)\n",
    "for subject in [2,5,7]:\n",
    "    new_df = pd.read_csv(f\"output/mental_imagery_paper/{mode}/{method}/subject{subject}_statistics_12.csv\")\n",
    "    new_df = column_string_to_list(new_df)\n",
    "    df = pd.concat([df, new_df])\n",
    "\n",
    "df.head(100)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12, 139968) (12, 139968)\n",
      "AlexNet 2 ()\n",
      "(12, 43264) (12, 43264)\n",
      "AlexNet 5 ()\n",
      "(12, 4096) (12, 4096)\n",
      "AlexNet 7 ()\n",
      "(12, 768) (12, 768)\n",
      "CLIP Two-way ()\n",
      "(12, 2048) (12, 2048)\n",
      "Inception V3 ()\n",
      "(12, 1280) (12, 1280)\n",
      "EffNet-B ()\n",
      "(12, 2048) (12, 2048)\n",
      "SwAV ()\n",
      "(12, 139968) (12, 139968)\n",
      "AlexNet 2 ()\n",
      "(12, 43264) (12, 43264)\n",
      "AlexNet 5 ()\n",
      "(12, 4096) (12, 4096)\n",
      "AlexNet 7 ()\n",
      "(12, 768) (12, 768)\n",
      "CLIP Two-way ()\n",
      "(12, 2048) (12, 2048)\n",
      "Inception V3 ()\n",
      "(12, 1280) (12, 1280)\n",
      "EffNet-B ()\n",
      "(12, 2048) (12, 2048)\n",
      "SwAV ()\n",
      "(12, 139968) (12, 139968)\n",
      "AlexNet 2 ()\n",
      "(12, 43264) (12, 43264)\n",
      "AlexNet 5 ()\n",
      "(12, 4096) (12, 4096)\n",
      "AlexNet 7 ()\n",
      "(12, 768) (12, 768)\n",
      "CLIP Two-way ()\n",
      "(12, 2048) (12, 2048)\n",
      "Inception V3 ()\n",
      "(12, 1280) (12, 1280)\n",
      "EffNet-B ()\n",
      "(12, 2048) (12, 2048)\n",
      "SwAV ()\n",
      "(12, 139968) (12, 139968)\n",
      "AlexNet 2 ()\n",
      "(12, 43264) (12, 43264)\n",
      "AlexNet 5 ()\n",
      "(12, 4096) (12, 4096)\n",
      "AlexNet 7 ()\n",
      "(12, 768) (12, 768)\n",
      "CLIP Two-way ()\n",
      "(12, 2048) (12, 2048)\n",
      "Inception V3 ()\n",
      "(12, 1280) (12, 1280)\n",
      "EffNet-B ()\n",
      "(12, 2048) (12, 2048)\n",
      "SwAV ()\n",
      "(12, 139968) (12, 139968)\n",
      "AlexNet 2 ()\n",
      "(12, 43264) (12, 43264)\n",
      "AlexNet 5 ()\n",
      "(12, 4096) (12, 4096)\n",
      "AlexNet 7 ()\n",
      "(12, 768) (12, 768)\n",
      "CLIP Two-way ()\n",
      "(12, 2048) (12, 2048)\n",
      "Inception V3 ()\n",
      "(12, 1280) (12, 1280)\n",
      "EffNet-B ()\n",
      "(12, 2048) (12, 2048)\n",
      "SwAV ()\n",
      "------------------------------------------------ SSIM -----------------------------------------------------------------\n",
      "SSIM:  0.30507427618334954\n",
      "Confidence Interval SSIM:  0.029134290497595368\n",
      "------------------------------------------------ Pixel Correlation -----------------------------------------------------------------\n",
      "Pixel Correlation:  -0.0029214852407891314\n",
      "Confidence Interval Pixel Correlation:  0.02705270566006141\n",
      "------------------------------------------------ CLIP Cosine -----------------------------------------------------------------\n",
      "CLIP Cosine:  0.5737797250350316\n",
      "Confidence Interval CLIP Cosine:  0.016963339864438595\n",
      "------------------------------------------------ CLIP Two-way -----------------------------------------------------------------\n",
      "CLIP Two-way:  0.5742424242424243\n",
      "------------------------------------------------ AlexNet 2 -----------------------------------------------------------------\n",
      "AlexNet 2:  0.4924242424242425\n",
      "------------------------------------------------ AlexNet 5 -----------------------------------------------------------------\n",
      "AlexNet 5:  0.5121212121212121\n",
      "------------------------------------------------ AlexNet 7 -----------------------------------------------------------------\n",
      "AlexNet 7:  0.5242424242424242\n",
      "------------------------------------------------ Inception V3 -----------------------------------------------------------------\n",
      "Inception V3:  0.5075757575757576\n",
      "------------------------------------------------ EffNet-B -----------------------------------------------------------------\n",
      "EffNet-B:  0.9892504998751479\n",
      "------------------------------------------------ SwAV -----------------------------------------------------------------\n",
      "SwAV:  0.6169608538128343\n"
     ]
    }
   ],
   "source": [
    "# Statistical Analysis Second Sight\n",
    "\n",
    "# Input: Dataframe containing the samples one type of image\n",
    "def create_cnn_numpy_array(df):\n",
    "    cnn_dict = {}\n",
    "    df = df.reset_index()\n",
    "    \n",
    "    alexnet_2       = []\n",
    "    alexnet_5       = []\n",
    "    alexnet_7       = []\n",
    "    clip_two_way    = []\n",
    "    inception_v3    = []\n",
    "    effnet_b        = []\n",
    "    swav            = []\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        \n",
    "        alexnet_2.append(row['AlexNet 2'])\n",
    "        alexnet_5.append(np.array(row['AlexNet 5']))\n",
    "        alexnet_7.append(np.array(row['AlexNet 7']))\n",
    "        clip_two_way.append(np.array(row['CLIP Two-way']))\n",
    "        inception_v3.append(np.array(row['Inception V3']))\n",
    "        effnet_b.append(np.array(row['EffNet-B']))\n",
    "        swav.append(np.array(row['SwAV']))\n",
    "    \n",
    "    cnn_dict['AlexNet 2']      = np.concatenate([alexnet_2])\n",
    "    cnn_dict['AlexNet 5']      = np.concatenate([alexnet_5])\n",
    "    cnn_dict['AlexNet 7']      = np.concatenate([alexnet_7])\n",
    "    cnn_dict['CLIP Two-way']   = np.concatenate([clip_two_way])\n",
    "    cnn_dict['Inception V3']   = np.concatenate([inception_v3])\n",
    "    cnn_dict['EffNet-B']       = np.concatenate([effnet_b])\n",
    "    cnn_dict['SwAV']           = np.concatenate([swav])\n",
    "    # print(cnn_dict['AlexNet 2'])\n",
    "    return cnn_dict\n",
    "\n",
    "def pairwise_corr_all(ground_truth, predictions):\n",
    "    r = np.corrcoef(ground_truth, predictions)      #cosine_similarity(ground_truth, predictions)#\n",
    "    r = r[:len(ground_truth), len(ground_truth):]   # rows: groundtruth, columns: predicitons\n",
    "    \n",
    "    # congruent pairs are on diagonal\n",
    "    congruents = np.diag(r)\n",
    "    \n",
    "    # for each column (predicition) we should count the number of rows (groundtruth) \n",
    "    # that the value is lower than the congruent (e.g. success).\n",
    "    success = r < congruents\n",
    "    success_cnt = np.sum(success, 0)\n",
    "    \n",
    "    # note: diagonal of 'success' is always zero so we can discard it. That's why we divide by len-1\n",
    "    perf = np.mean(success_cnt) / (len(ground_truth)-1)\n",
    "    p = 1 - binom.cdf(perf*len(ground_truth)*(len(ground_truth)-1), len(ground_truth)*(len(ground_truth)-1), 0.5)\n",
    "    \n",
    "    return perf, p\n",
    "\n",
    "def compute_cnn_metrics(cnn_metrics_ground_truth, cnn_metrics_reconstructions):\n",
    "    distance_fn = sp.spatial.distance.correlation\n",
    "    pairwise_corrs = []\n",
    "    cnn_metrics = {}\n",
    "    # print(cnn_metrics_reconstructions)\n",
    "    for net_name, predictions_np in cnn_metrics_reconstructions.items():\n",
    "        \n",
    "        gt_feat = cnn_metrics_ground_truth[net_name]\n",
    "        \n",
    "        eval_feat = predictions_np\n",
    "        print(gt_feat.shape, eval_feat.shape)\n",
    "        num_test = predictions_np.shape[0]\n",
    "        # print(net_name, predictions_np.shape)\n",
    "        if net_name == 'EffNet-B' or net_name == 'SwAV':\n",
    "            cnn_metrics[net_name] = np.array([distance_fn(gt_feat[i],eval_feat[i]) for i in range(num_test)]).mean()\n",
    "            \n",
    "        else:\n",
    "            cnn_metrics[net_name] = pairwise_corr_all(gt_feat[:num_test],eval_feat[:num_test])[0]\n",
    "        print(net_name, cnn_metrics[net_name].shape)\n",
    "    return cnn_metrics \n",
    "\n",
    "df_final_samples    = new_df.loc[(new_df['Sample Indicator'] == 12)]\n",
    "df_ground_truth     = new_df.loc[(new_df['Sample Indicator'] == 10)]\n",
    "df_final_samples_0  = df_final_samples.loc[(df_final_samples['Sample Count'] == 0)]\n",
    "df_final_samples_1  = df_final_samples.loc[(df_final_samples['Sample Count'] == 1)]\n",
    "df_final_samples_2  = df_final_samples.loc[(df_final_samples['Sample Count'] == 2)]\n",
    "df_final_samples_3  = df_final_samples.loc[(df_final_samples['Sample Count'] == 3)]\n",
    "df_final_samples_4  = df_final_samples.loc[(df_final_samples['Sample Count'] == 4)]\n",
    "\n",
    "\n",
    "cnn_metrics_0 = compute_cnn_metrics(create_cnn_numpy_array(df_ground_truth), create_cnn_numpy_array(df_final_samples_0))\n",
    "cnn_metrics_1 = compute_cnn_metrics(create_cnn_numpy_array(df_ground_truth), create_cnn_numpy_array(df_final_samples_1))\n",
    "cnn_metrics_2 = compute_cnn_metrics(create_cnn_numpy_array(df_ground_truth), create_cnn_numpy_array(df_final_samples_2))\n",
    "cnn_metrics_3 = compute_cnn_metrics(create_cnn_numpy_array(df_ground_truth), create_cnn_numpy_array(df_final_samples_3))\n",
    "cnn_metrics_4 = compute_cnn_metrics(create_cnn_numpy_array(df_ground_truth), create_cnn_numpy_array(df_final_samples_4))\n",
    "\n",
    "print(\"------------------------------------------------ SSIM -----------------------------------------------------------------\")\n",
    "\n",
    "print(\"SSIM: \", df_final_samples['SSIM'].mean())\n",
    "\n",
    "print(\"Confidence Interval SSIM: \", ((df_final_samples['SSIM'].std() * 1.96) / math.sqrt(len(df_final_samples.index))))\n",
    "\n",
    "print(\"------------------------------------------------ Pixel Correlation -----------------------------------------------------------------\")\n",
    "\n",
    "print(\"Pixel Correlation: \", df_final_samples['Pixel Correlation'].mean())\n",
    "\n",
    "print(\"Confidence Interval Pixel Correlation: \", ((df_final_samples['Pixel Correlation'].std() * 1.96) / math.sqrt(len(df_final_samples.index))))\n",
    "\n",
    "print(\"------------------------------------------------ CLIP Cosine -----------------------------------------------------------------\")\n",
    "\n",
    "print(\"CLIP Cosine: \", df_final_samples['CLIP Cosine'].mean())\n",
    "\n",
    "print(\"Confidence Interval CLIP Cosine: \", ((df_final_samples['CLIP Cosine'].std() * 1.96) / math.sqrt(len(df_final_samples.index))))\n",
    "\n",
    "print(\"------------------------------------------------ CLIP Two-way -----------------------------------------------------------------\")\n",
    "\n",
    "print(\"CLIP Two-way: \", ((cnn_metrics_0['CLIP Two-way'] + cnn_metrics_1['CLIP Two-way'] + cnn_metrics_2['CLIP Two-way'] + cnn_metrics_3['CLIP Two-way'] + cnn_metrics_4['CLIP Two-way']) / 5))\n",
    "\n",
    "print(\"------------------------------------------------ AlexNet 2 -----------------------------------------------------------------\")\n",
    "\n",
    "print(\"AlexNet 2: \", ((cnn_metrics_0['AlexNet 2'] + cnn_metrics_1['AlexNet 2'] + cnn_metrics_2['AlexNet 2'] + cnn_metrics_3['AlexNet 2'] + cnn_metrics_4['AlexNet 2']) / 5))\n",
    "\n",
    "print(\"------------------------------------------------ AlexNet 5 -----------------------------------------------------------------\")\n",
    "\n",
    "print(\"AlexNet 5: \", ((cnn_metrics_0['AlexNet 5'] + cnn_metrics_1['AlexNet 5'] + cnn_metrics_2['AlexNet 5'] + cnn_metrics_3['AlexNet 5'] + cnn_metrics_4['AlexNet 5']) / 5))\n",
    "\n",
    "print(\"------------------------------------------------ AlexNet 7 -----------------------------------------------------------------\")\n",
    "\n",
    "print(\"AlexNet 7: \", ((cnn_metrics_0['AlexNet 7'] + cnn_metrics_1['AlexNet 7'] + cnn_metrics_2['AlexNet 7'] + cnn_metrics_3['AlexNet 7'] + cnn_metrics_4['AlexNet 7']) / 5))\n",
    "\n",
    "print(\"------------------------------------------------ Inception V3 -----------------------------------------------------------------\")\n",
    "\n",
    "print(\"Inception V3: \", ((cnn_metrics_0['Inception V3'] + cnn_metrics_1['Inception V3'] + cnn_metrics_2['Inception V3'] + cnn_metrics_3['Inception V3'] + cnn_metrics_4['Inception V3']) / 5))\n",
    "\n",
    "print(\"------------------------------------------------ EffNet-B -----------------------------------------------------------------\")\n",
    "\n",
    "print(\"EffNet-B: \", ((cnn_metrics_0['EffNet-B'] + cnn_metrics_1['EffNet-B'] + cnn_metrics_2['EffNet-B'] + cnn_metrics_3['EffNet-B'] + cnn_metrics_4['EffNet-B']) / 5))\n",
    "\n",
    "print(\"------------------------------------------------ SwAV -----------------------------------------------------------------\")\n",
    "\n",
    "print(\"SwAV: \", ((cnn_metrics_0['SwAV'] + cnn_metrics_1['SwAV'] + cnn_metrics_2['SwAV'] + cnn_metrics_3['SwAV'] + cnn_metrics_4['SwAV']) / 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------ Brain Correlation V1 -----------------------------------------------------------------\n",
      "Brain Correlation V1:  0.005562405052478427\n",
      "------------------------------------------------ Brain Correlation V2 -----------------------------------------------------------------\n",
      "Brain Correlation V2:  -0.004314067726712274\n",
      "------------------------------------------------ Brain Correlation V3 -----------------------------------------------------------------\n",
      "Brain Correlation V3:  -0.028385967421005857\n",
      "------------------------------------------------ Brain Correlation V4 -----------------------------------------------------------------\n",
      "Brain Correlation V4:  -0.029459960975994667\n",
      "------------------------------------------------ Brain Correlation Early Visual -------------------------------------------------------\n",
      "Brain Correlation Early Visual:  -0.004835919255856417\n",
      "------------------------------------------------ Brain Correlation Higher Visual -------------------------------------------------------\n",
      "Brain Correlation Higher Visual:  -0.04536169186721962\n",
      "------------------------------------------------ Brain Correlation NSD General ---------------------------------------------------------\n",
      "Brain Correlation NSD General:  -0.027669074108901744\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ID</th>\n",
       "      <th>Sample Count</th>\n",
       "      <th>Batch Number</th>\n",
       "      <th>Sample Indicator</th>\n",
       "      <th>Strength</th>\n",
       "      <th>Brain Correlation V1</th>\n",
       "      <th>Brain Correlation V2</th>\n",
       "      <th>Brain Correlation V3</th>\n",
       "      <th>Brain Correlation V4</th>\n",
       "      <th>...</th>\n",
       "      <th>SSIM</th>\n",
       "      <th>Pixel Correlation</th>\n",
       "      <th>CLIP Cosine</th>\n",
       "      <th>CLIP Two-way</th>\n",
       "      <th>AlexNet 2</th>\n",
       "      <th>AlexNet 5</th>\n",
       "      <th>AlexNet 7</th>\n",
       "      <th>Inception V3</th>\n",
       "      <th>EffNet-B</th>\n",
       "      <th>SwAV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>58</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.021280</td>\n",
       "      <td>0.182502</td>\n",
       "      <td>0.082919</td>\n",
       "      <td>-0.005453</td>\n",
       "      <td>...</td>\n",
       "      <td>0.190621</td>\n",
       "      <td>-0.055833</td>\n",
       "      <td>0.437987</td>\n",
       "      <td>[0.058743398636579514, -0.3748611509799957, 0....</td>\n",
       "      <td>[0.0, 0.0, 9.507308959960938, 8.64023685455322...</td>\n",
       "      <td>[7.910593032836914, 10.540233612060547, 10.378...</td>\n",
       "      <td>[0.4446442425251007, 4.647583961486816, 0.0, 0...</td>\n",
       "      <td>[0.7332108020782471, 0.8371985554695129, 0.438...</td>\n",
       "      <td>[0.11796651035547256, -0.13083019852638245, 0....</td>\n",
       "      <td>[0.1606316864490509, 0.0, 0.07132810354232788,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>59</td>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.058387</td>\n",
       "      <td>0.134190</td>\n",
       "      <td>0.045099</td>\n",
       "      <td>-0.056514</td>\n",
       "      <td>...</td>\n",
       "      <td>0.203421</td>\n",
       "      <td>-0.024698</td>\n",
       "      <td>0.483969</td>\n",
       "      <td>[-0.4510958790779114, 1.1721807718276978, 0.56...</td>\n",
       "      <td>[0.6437945365905762, 0.0, 0.0, 0.0, 12.9693603...</td>\n",
       "      <td>[3.59698224067688, 4.996384143829346, 7.255982...</td>\n",
       "      <td>[0.0, 4.359976291656494, 0.0, 0.0, 0.0, 0.0, 0...</td>\n",
       "      <td>[0.24337342381477356, 0.1451941877603531, 0.78...</td>\n",
       "      <td>[-0.13056465983390808, -0.08199292421340942, 0...</td>\n",
       "      <td>[0.04924654960632324, 0.10594171285629272, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>60</td>\n",
       "      <td>8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.106923</td>\n",
       "      <td>0.079227</td>\n",
       "      <td>-0.051711</td>\n",
       "      <td>0.008481</td>\n",
       "      <td>...</td>\n",
       "      <td>0.148486</td>\n",
       "      <td>-0.016383</td>\n",
       "      <td>0.476071</td>\n",
       "      <td>[-0.22353658080101013, -0.2705431282520294, 0....</td>\n",
       "      <td>[8.310758590698242, 1.345560908317566, 0.0, 0....</td>\n",
       "      <td>[0.0, 0.0, 0.5323666334152222, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 4.3086466789245605, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.9461851119995117, 0.01041814498603344, 0.27...</td>\n",
       "      <td>[0.4573146104812622, -0.10895085334777832, -0....</td>\n",
       "      <td>[0.02732289955019951, 0.02447810210287571, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>61</td>\n",
       "      <td>8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.195845</td>\n",
       "      <td>-0.010054</td>\n",
       "      <td>-0.107340</td>\n",
       "      <td>-0.213470</td>\n",
       "      <td>...</td>\n",
       "      <td>0.259443</td>\n",
       "      <td>0.012875</td>\n",
       "      <td>0.501911</td>\n",
       "      <td>[-0.3440742790699005, 0.4917072653770447, 0.53...</td>\n",
       "      <td>[0.9824042320251465, 0.0, 0.0, 0.0, 2.13560914...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[5.637965202331543, 2.598076581954956, 0.0, 0....</td>\n",
       "      <td>[0.7504007816314697, 0.5141189694404602, 0.085...</td>\n",
       "      <td>[0.21721605956554413, 0.06002497673034668, -0....</td>\n",
       "      <td>[0.0076486459001898766, 0.08338148891925812, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>62</td>\n",
       "      <td>8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.107887</td>\n",
       "      <td>0.020331</td>\n",
       "      <td>-0.072604</td>\n",
       "      <td>-0.125339</td>\n",
       "      <td>...</td>\n",
       "      <td>0.230420</td>\n",
       "      <td>-0.000549</td>\n",
       "      <td>0.436594</td>\n",
       "      <td>[-0.24961692094802856, 0.1521618366241455, 0.3...</td>\n",
       "      <td>[1.2677420377731323, 1.7433723211288452, 0.233...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[2.4919917583465576, 6.0540080070495605, 0.0, ...</td>\n",
       "      <td>[0.33920818567276, 0.18566592037677765, 0.0314...</td>\n",
       "      <td>[0.3192221224308014, -0.1470678597688675, -0.0...</td>\n",
       "      <td>[0.020717304199934006, 0.03640280291438103, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>65</td>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.154485</td>\n",
       "      <td>-0.143037</td>\n",
       "      <td>-0.014261</td>\n",
       "      <td>-0.203378</td>\n",
       "      <td>...</td>\n",
       "      <td>0.226083</td>\n",
       "      <td>0.007553</td>\n",
       "      <td>0.552631</td>\n",
       "      <td>[-0.42503541707992554, 0.26153674721717834, -0...</td>\n",
       "      <td>[1.5665440559387207, 1.341271162033081, 0.2553...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4836444854736...</td>\n",
       "      <td>[0.1462002396583557, 0.4032117426395416, 0.089...</td>\n",
       "      <td>[-0.05466541275382042, 0.15029829740524292, 1....</td>\n",
       "      <td>[0.36383309960365295, 0.0701654851436615, 0.02...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>66</td>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.227568</td>\n",
       "      <td>-0.066952</td>\n",
       "      <td>-0.021137</td>\n",
       "      <td>-0.380814</td>\n",
       "      <td>...</td>\n",
       "      <td>0.223169</td>\n",
       "      <td>0.057960</td>\n",
       "      <td>0.435001</td>\n",
       "      <td>[-0.5982149243354797, 1.1748614311218262, -0.1...</td>\n",
       "      <td>[1.0997706651687622, 0.34191277623176575, 0.20...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 1.367985725402832, 0.0, 0.0, 0...</td>\n",
       "      <td>[0.2513813376426697, 0.6397149562835693, 0.102...</td>\n",
       "      <td>[0.4717042148113251, 0.25946807861328125, 0.26...</td>\n",
       "      <td>[0.007726115640252829, 0.20479148626327515, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>67</td>\n",
       "      <td>9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.249281</td>\n",
       "      <td>-0.173805</td>\n",
       "      <td>-0.109292</td>\n",
       "      <td>-0.245969</td>\n",
       "      <td>...</td>\n",
       "      <td>0.226838</td>\n",
       "      <td>0.000514</td>\n",
       "      <td>0.527526</td>\n",
       "      <td>[-0.45809030532836914, 0.24257133901119232, -0...</td>\n",
       "      <td>[1.9647246599197388, 0.73797208070755, 0.22422...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.1152446269989...</td>\n",
       "      <td>[0.3306311070919037, 0.5399559140205383, 0.143...</td>\n",
       "      <td>[0.5658812522888184, 0.14174285531044006, 1.72...</td>\n",
       "      <td>[0.1871039718389511, 0.17521421611309052, 0.07...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>68</td>\n",
       "      <td>9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.030682</td>\n",
       "      <td>-0.143203</td>\n",
       "      <td>0.055374</td>\n",
       "      <td>-0.060331</td>\n",
       "      <td>...</td>\n",
       "      <td>0.250672</td>\n",
       "      <td>0.095967</td>\n",
       "      <td>0.508826</td>\n",
       "      <td>[0.6594982147216797, 0.9010300636291504, -0.02...</td>\n",
       "      <td>[0.07944317907094955, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.14007775485515594, 0.0,...</td>\n",
       "      <td>[0.31351107358932495, 1.0246304273605347, 0.12...</td>\n",
       "      <td>[0.002913538133725524, 0.05819639191031456, 0....</td>\n",
       "      <td>[0.2094479203224182, 0.03686278313398361, 0.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>69</td>\n",
       "      <td>9</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.017926</td>\n",
       "      <td>-0.077549</td>\n",
       "      <td>0.030300</td>\n",
       "      <td>-0.097681</td>\n",
       "      <td>...</td>\n",
       "      <td>0.243924</td>\n",
       "      <td>0.005740</td>\n",
       "      <td>0.525949</td>\n",
       "      <td>[0.1530441790819168, -0.07023569941520691, 0.1...</td>\n",
       "      <td>[1.0307018756866455, 0.26584601402282715, 0.0,...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.5255361199378967, 0.0, ...</td>\n",
       "      <td>[0.3337961435317993, 0.846046507358551, 0.0900...</td>\n",
       "      <td>[0.388578325510025, 0.11661688983440399, 0.557...</td>\n",
       "      <td>[0.19142675399780273, 0.016550062224268913, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>72</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.049355</td>\n",
       "      <td>-0.099753</td>\n",
       "      <td>-0.195981</td>\n",
       "      <td>-0.434585</td>\n",
       "      <td>...</td>\n",
       "      <td>0.227254</td>\n",
       "      <td>0.005458</td>\n",
       "      <td>0.488238</td>\n",
       "      <td>[-0.5239149332046509, 0.12052140384912491, 0.3...</td>\n",
       "      <td>[3.75508975982666, 4.448290824890137, 0.0, 0.0...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.4399695098400116, 1.4555251598358154, 0.274...</td>\n",
       "      <td>[-0.12527808547019958, 0.10292448848485947, 0....</td>\n",
       "      <td>[0.1848812997341156, 0.007837839424610138, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>73</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.127406</td>\n",
       "      <td>0.171525</td>\n",
       "      <td>0.239343</td>\n",
       "      <td>0.301360</td>\n",
       "      <td>...</td>\n",
       "      <td>0.243590</td>\n",
       "      <td>-0.093162</td>\n",
       "      <td>0.565183</td>\n",
       "      <td>[-0.14077313244342804, 0.6472176313400269, -0....</td>\n",
       "      <td>[2.031827688217163, 5.080326557159424, 0.0, 0....</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.5882706046104431, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.40190601348876953, 0.6678149104118347, 0.35...</td>\n",
       "      <td>[0.02618008852005005, 0.1555686593055725, 0.56...</td>\n",
       "      <td>[0.20050321519374847, 0.1347011774778366, 0.08...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>74</td>\n",
       "      <td>10</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.131561</td>\n",
       "      <td>-0.023155</td>\n",
       "      <td>-0.147722</td>\n",
       "      <td>-0.194417</td>\n",
       "      <td>...</td>\n",
       "      <td>0.295558</td>\n",
       "      <td>-0.050840</td>\n",
       "      <td>0.580631</td>\n",
       "      <td>[-0.24256150424480438, 0.5921431183815002, -0....</td>\n",
       "      <td>[0.7061170339584351, 0.2484588623046875, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 3.466590404510498, 0.0, 0.0, 0.0, 0.0, 0...</td>\n",
       "      <td>[0.6081722974777222, 1.1252070665359497, 0.669...</td>\n",
       "      <td>[0.27644652128219604, 0.010255341418087482, 0....</td>\n",
       "      <td>[0.18241813778877258, 0.03189263492822647, 0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>75</td>\n",
       "      <td>10</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.098983</td>\n",
       "      <td>0.087978</td>\n",
       "      <td>-0.001304</td>\n",
       "      <td>-0.196870</td>\n",
       "      <td>...</td>\n",
       "      <td>0.262085</td>\n",
       "      <td>0.065348</td>\n",
       "      <td>0.596997</td>\n",
       "      <td>[0.1564967781305313, 0.48954227566719055, -0.4...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.18416239321231842, 0.0,...</td>\n",
       "      <td>[0.4295355975627899, 1.6564648151397705, 0.456...</td>\n",
       "      <td>[-0.010015602223575115, 0.20139937102794647, 0...</td>\n",
       "      <td>[0.05929999426007271, 0.008365996181964874, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>76</td>\n",
       "      <td>10</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.058727</td>\n",
       "      <td>-0.083750</td>\n",
       "      <td>-0.068644</td>\n",
       "      <td>-0.426755</td>\n",
       "      <td>...</td>\n",
       "      <td>0.262528</td>\n",
       "      <td>-0.133370</td>\n",
       "      <td>0.570681</td>\n",
       "      <td>[-0.12311151623725891, 0.6351945400238037, -0....</td>\n",
       "      <td>[3.9983835220336914, 4.446861743927002, 2.2513...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 1.2747567892074585, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.17406241595745087, 0.037519268691539764, 0....</td>\n",
       "      <td>[0.3634061813354492, 0.33145445585250854, 0.66...</td>\n",
       "      <td>[0.017012866213917732, 0.04213583096861839, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>79</td>\n",
       "      <td>11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.098284</td>\n",
       "      <td>0.331293</td>\n",
       "      <td>0.080895</td>\n",
       "      <td>0.298135</td>\n",
       "      <td>...</td>\n",
       "      <td>0.096763</td>\n",
       "      <td>-0.198030</td>\n",
       "      <td>0.563439</td>\n",
       "      <td>[0.8338737487792969, 0.3309897184371948, -0.31...</td>\n",
       "      <td>[4.585059642791748, 4.819113731384277, 4.50312...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.051367003470659256, 0.0...</td>\n",
       "      <td>[1.3795139789581299, 0.9674606323242188, 1.228...</td>\n",
       "      <td>[0.11553211510181427, 0.3050263226032257, 0.77...</td>\n",
       "      <td>[0.18055063486099243, 0.05714978277683258, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>80</td>\n",
       "      <td>11</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.032696</td>\n",
       "      <td>0.310425</td>\n",
       "      <td>0.209231</td>\n",
       "      <td>0.266840</td>\n",
       "      <td>...</td>\n",
       "      <td>0.098437</td>\n",
       "      <td>-0.288506</td>\n",
       "      <td>0.613621</td>\n",
       "      <td>[0.5139117240905762, -0.0864284485578537, 0.08...</td>\n",
       "      <td>[1.3982335329055786, 1.1308050155639648, 0.450...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.5109704732894897, 0.0, ...</td>\n",
       "      <td>[0.375618040561676, 1.9294111728668213, 1.2639...</td>\n",
       "      <td>[0.061408478766679764, -0.10594585537910461, 0...</td>\n",
       "      <td>[0.11496221274137497, 0.011517089791595936, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>81</td>\n",
       "      <td>11</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.221193</td>\n",
       "      <td>0.312306</td>\n",
       "      <td>0.124597</td>\n",
       "      <td>0.481203</td>\n",
       "      <td>...</td>\n",
       "      <td>0.072143</td>\n",
       "      <td>-0.264537</td>\n",
       "      <td>0.516961</td>\n",
       "      <td>[0.3845705986022949, 0.3075058162212372, -0.37...</td>\n",
       "      <td>[0.3552761375904083, 0.20368337631225586, 0.0,...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.1900072097778...</td>\n",
       "      <td>[0.641642153263092, 1.1252812147140503, 0.1737...</td>\n",
       "      <td>[0.05952707305550575, 0.18555621802806854, 0.4...</td>\n",
       "      <td>[0.11528719216585159, 0.15534739196300507, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>82</td>\n",
       "      <td>11</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.430688</td>\n",
       "      <td>0.221724</td>\n",
       "      <td>0.030767</td>\n",
       "      <td>0.159925</td>\n",
       "      <td>...</td>\n",
       "      <td>0.098275</td>\n",
       "      <td>-0.216894</td>\n",
       "      <td>0.517278</td>\n",
       "      <td>[0.4693911671638489, 0.8052582740783691, -0.55...</td>\n",
       "      <td>[1.7891470193862915, 0.027787260711193085, 0.0...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.4174327254295349, 0.0, ...</td>\n",
       "      <td>[0.7425933480262756, 0.6761474609375, 0.617125...</td>\n",
       "      <td>[0.21248240768909454, 0.19034068286418915, 0.3...</td>\n",
       "      <td>[0.15056075155735016, 0.09389893710613251, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>83</td>\n",
       "      <td>11</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.349505</td>\n",
       "      <td>0.347301</td>\n",
       "      <td>0.169452</td>\n",
       "      <td>0.361710</td>\n",
       "      <td>...</td>\n",
       "      <td>0.080048</td>\n",
       "      <td>-0.249059</td>\n",
       "      <td>0.491803</td>\n",
       "      <td>[0.3035767078399658, 0.5762424468994141, -0.68...</td>\n",
       "      <td>[5.496029376983643, 1.3297605514526367, 0.0, 3...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8655006289482...</td>\n",
       "      <td>[0.16142064332962036, 0.395068496465683, 0.278...</td>\n",
       "      <td>[0.5158725380897522, 0.8936625719070435, 0.254...</td>\n",
       "      <td>[0.25882673263549805, 0.07133975625038147, 0.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0  ID  Sample Count  Batch Number  Sample Indicator  Strength  \\\n",
       "58          58   8           0.0           NaN                12       NaN   \n",
       "59          59   8           1.0           NaN                12       NaN   \n",
       "60          60   8           2.0           NaN                12       NaN   \n",
       "61          61   8           3.0           NaN                12       NaN   \n",
       "62          62   8           4.0           NaN                12       NaN   \n",
       "65          65   9           0.0           NaN                12       NaN   \n",
       "66          66   9           1.0           NaN                12       NaN   \n",
       "67          67   9           2.0           NaN                12       NaN   \n",
       "68          68   9           3.0           NaN                12       NaN   \n",
       "69          69   9           4.0           NaN                12       NaN   \n",
       "72          72  10           0.0           NaN                12       NaN   \n",
       "73          73  10           1.0           NaN                12       NaN   \n",
       "74          74  10           2.0           NaN                12       NaN   \n",
       "75          75  10           3.0           NaN                12       NaN   \n",
       "76          76  10           4.0           NaN                12       NaN   \n",
       "79          79  11           0.0           NaN                12       NaN   \n",
       "80          80  11           1.0           NaN                12       NaN   \n",
       "81          81  11           2.0           NaN                12       NaN   \n",
       "82          82  11           3.0           NaN                12       NaN   \n",
       "83          83  11           4.0           NaN                12       NaN   \n",
       "\n",
       "    Brain Correlation V1  Brain Correlation V2  Brain Correlation V3  \\\n",
       "58             -0.021280              0.182502              0.082919   \n",
       "59              0.058387              0.134190              0.045099   \n",
       "60              0.106923              0.079227             -0.051711   \n",
       "61              0.195845             -0.010054             -0.107340   \n",
       "62              0.107887              0.020331             -0.072604   \n",
       "65             -0.154485             -0.143037             -0.014261   \n",
       "66             -0.227568             -0.066952             -0.021137   \n",
       "67             -0.249281             -0.173805             -0.109292   \n",
       "68             -0.030682             -0.143203              0.055374   \n",
       "69             -0.017926             -0.077549              0.030300   \n",
       "72              0.049355             -0.099753             -0.195981   \n",
       "73              0.127406              0.171525              0.239343   \n",
       "74              0.131561             -0.023155             -0.147722   \n",
       "75             -0.098983              0.087978             -0.001304   \n",
       "76             -0.058727             -0.083750             -0.068644   \n",
       "79              0.098284              0.331293              0.080895   \n",
       "80              0.032696              0.310425              0.209231   \n",
       "81              0.221193              0.312306              0.124597   \n",
       "82              0.430688              0.221724              0.030767   \n",
       "83              0.349505              0.347301              0.169452   \n",
       "\n",
       "    Brain Correlation V4  ...      SSIM  Pixel Correlation  CLIP Cosine  \\\n",
       "58             -0.005453  ...  0.190621          -0.055833     0.437987   \n",
       "59             -0.056514  ...  0.203421          -0.024698     0.483969   \n",
       "60              0.008481  ...  0.148486          -0.016383     0.476071   \n",
       "61             -0.213470  ...  0.259443           0.012875     0.501911   \n",
       "62             -0.125339  ...  0.230420          -0.000549     0.436594   \n",
       "65             -0.203378  ...  0.226083           0.007553     0.552631   \n",
       "66             -0.380814  ...  0.223169           0.057960     0.435001   \n",
       "67             -0.245969  ...  0.226838           0.000514     0.527526   \n",
       "68             -0.060331  ...  0.250672           0.095967     0.508826   \n",
       "69             -0.097681  ...  0.243924           0.005740     0.525949   \n",
       "72             -0.434585  ...  0.227254           0.005458     0.488238   \n",
       "73              0.301360  ...  0.243590          -0.093162     0.565183   \n",
       "74             -0.194417  ...  0.295558          -0.050840     0.580631   \n",
       "75             -0.196870  ...  0.262085           0.065348     0.596997   \n",
       "76             -0.426755  ...  0.262528          -0.133370     0.570681   \n",
       "79              0.298135  ...  0.096763          -0.198030     0.563439   \n",
       "80              0.266840  ...  0.098437          -0.288506     0.613621   \n",
       "81              0.481203  ...  0.072143          -0.264537     0.516961   \n",
       "82              0.159925  ...  0.098275          -0.216894     0.517278   \n",
       "83              0.361710  ...  0.080048          -0.249059     0.491803   \n",
       "\n",
       "                                         CLIP Two-way  \\\n",
       "58  [0.058743398636579514, -0.3748611509799957, 0....   \n",
       "59  [-0.4510958790779114, 1.1721807718276978, 0.56...   \n",
       "60  [-0.22353658080101013, -0.2705431282520294, 0....   \n",
       "61  [-0.3440742790699005, 0.4917072653770447, 0.53...   \n",
       "62  [-0.24961692094802856, 0.1521618366241455, 0.3...   \n",
       "65  [-0.42503541707992554, 0.26153674721717834, -0...   \n",
       "66  [-0.5982149243354797, 1.1748614311218262, -0.1...   \n",
       "67  [-0.45809030532836914, 0.24257133901119232, -0...   \n",
       "68  [0.6594982147216797, 0.9010300636291504, -0.02...   \n",
       "69  [0.1530441790819168, -0.07023569941520691, 0.1...   \n",
       "72  [-0.5239149332046509, 0.12052140384912491, 0.3...   \n",
       "73  [-0.14077313244342804, 0.6472176313400269, -0....   \n",
       "74  [-0.24256150424480438, 0.5921431183815002, -0....   \n",
       "75  [0.1564967781305313, 0.48954227566719055, -0.4...   \n",
       "76  [-0.12311151623725891, 0.6351945400238037, -0....   \n",
       "79  [0.8338737487792969, 0.3309897184371948, -0.31...   \n",
       "80  [0.5139117240905762, -0.0864284485578537, 0.08...   \n",
       "81  [0.3845705986022949, 0.3075058162212372, -0.37...   \n",
       "82  [0.4693911671638489, 0.8052582740783691, -0.55...   \n",
       "83  [0.3035767078399658, 0.5762424468994141, -0.68...   \n",
       "\n",
       "                                            AlexNet 2  \\\n",
       "58  [0.0, 0.0, 9.507308959960938, 8.64023685455322...   \n",
       "59  [0.6437945365905762, 0.0, 0.0, 0.0, 12.9693603...   \n",
       "60  [8.310758590698242, 1.345560908317566, 0.0, 0....   \n",
       "61  [0.9824042320251465, 0.0, 0.0, 0.0, 2.13560914...   \n",
       "62  [1.2677420377731323, 1.7433723211288452, 0.233...   \n",
       "65  [1.5665440559387207, 1.341271162033081, 0.2553...   \n",
       "66  [1.0997706651687622, 0.34191277623176575, 0.20...   \n",
       "67  [1.9647246599197388, 0.73797208070755, 0.22422...   \n",
       "68  [0.07944317907094955, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "69  [1.0307018756866455, 0.26584601402282715, 0.0,...   \n",
       "72  [3.75508975982666, 4.448290824890137, 0.0, 0.0...   \n",
       "73  [2.031827688217163, 5.080326557159424, 0.0, 0....   \n",
       "74  [0.7061170339584351, 0.2484588623046875, 0.0, ...   \n",
       "75  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "76  [3.9983835220336914, 4.446861743927002, 2.2513...   \n",
       "79  [4.585059642791748, 4.819113731384277, 4.50312...   \n",
       "80  [1.3982335329055786, 1.1308050155639648, 0.450...   \n",
       "81  [0.3552761375904083, 0.20368337631225586, 0.0,...   \n",
       "82  [1.7891470193862915, 0.027787260711193085, 0.0...   \n",
       "83  [5.496029376983643, 1.3297605514526367, 0.0, 3...   \n",
       "\n",
       "                                            AlexNet 5  \\\n",
       "58  [7.910593032836914, 10.540233612060547, 10.378...   \n",
       "59  [3.59698224067688, 4.996384143829346, 7.255982...   \n",
       "60  [0.0, 0.0, 0.5323666334152222, 0.0, 0.0, 0.0, ...   \n",
       "61  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "62  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "65  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "66  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "67  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "68  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "69  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "72  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "73  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "74  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "75  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "76  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "79  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "80  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "81  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "82  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "83  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "                                            AlexNet 7  \\\n",
       "58  [0.4446442425251007, 4.647583961486816, 0.0, 0...   \n",
       "59  [0.0, 4.359976291656494, 0.0, 0.0, 0.0, 0.0, 0...   \n",
       "60  [0.0, 4.3086466789245605, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "61  [5.637965202331543, 2.598076581954956, 0.0, 0....   \n",
       "62  [2.4919917583465576, 6.0540080070495605, 0.0, ...   \n",
       "65  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4836444854736...   \n",
       "66  [0.0, 0.0, 0.0, 1.367985725402832, 0.0, 0.0, 0...   \n",
       "67  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.1152446269989...   \n",
       "68  [0.0, 0.0, 0.0, 0.0, 0.14007775485515594, 0.0,...   \n",
       "69  [0.0, 0.0, 0.0, 0.0, 0.5255361199378967, 0.0, ...   \n",
       "72  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "73  [0.0, 0.0, 0.5882706046104431, 0.0, 0.0, 0.0, ...   \n",
       "74  [0.0, 3.466590404510498, 0.0, 0.0, 0.0, 0.0, 0...   \n",
       "75  [0.0, 0.0, 0.0, 0.0, 0.18416239321231842, 0.0,...   \n",
       "76  [0.0, 0.0, 1.2747567892074585, 0.0, 0.0, 0.0, ...   \n",
       "79  [0.0, 0.0, 0.0, 0.0, 0.051367003470659256, 0.0...   \n",
       "80  [0.0, 0.0, 0.0, 0.0, 1.5109704732894897, 0.0, ...   \n",
       "81  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.1900072097778...   \n",
       "82  [0.0, 0.0, 0.0, 0.0, 0.4174327254295349, 0.0, ...   \n",
       "83  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8655006289482...   \n",
       "\n",
       "                                         Inception V3  \\\n",
       "58  [0.7332108020782471, 0.8371985554695129, 0.438...   \n",
       "59  [0.24337342381477356, 0.1451941877603531, 0.78...   \n",
       "60  [0.9461851119995117, 0.01041814498603344, 0.27...   \n",
       "61  [0.7504007816314697, 0.5141189694404602, 0.085...   \n",
       "62  [0.33920818567276, 0.18566592037677765, 0.0314...   \n",
       "65  [0.1462002396583557, 0.4032117426395416, 0.089...   \n",
       "66  [0.2513813376426697, 0.6397149562835693, 0.102...   \n",
       "67  [0.3306311070919037, 0.5399559140205383, 0.143...   \n",
       "68  [0.31351107358932495, 1.0246304273605347, 0.12...   \n",
       "69  [0.3337961435317993, 0.846046507358551, 0.0900...   \n",
       "72  [0.4399695098400116, 1.4555251598358154, 0.274...   \n",
       "73  [0.40190601348876953, 0.6678149104118347, 0.35...   \n",
       "74  [0.6081722974777222, 1.1252070665359497, 0.669...   \n",
       "75  [0.4295355975627899, 1.6564648151397705, 0.456...   \n",
       "76  [0.17406241595745087, 0.037519268691539764, 0....   \n",
       "79  [1.3795139789581299, 0.9674606323242188, 1.228...   \n",
       "80  [0.375618040561676, 1.9294111728668213, 1.2639...   \n",
       "81  [0.641642153263092, 1.1252812147140503, 0.1737...   \n",
       "82  [0.7425933480262756, 0.6761474609375, 0.617125...   \n",
       "83  [0.16142064332962036, 0.395068496465683, 0.278...   \n",
       "\n",
       "                                             EffNet-B  \\\n",
       "58  [0.11796651035547256, -0.13083019852638245, 0....   \n",
       "59  [-0.13056465983390808, -0.08199292421340942, 0...   \n",
       "60  [0.4573146104812622, -0.10895085334777832, -0....   \n",
       "61  [0.21721605956554413, 0.06002497673034668, -0....   \n",
       "62  [0.3192221224308014, -0.1470678597688675, -0.0...   \n",
       "65  [-0.05466541275382042, 0.15029829740524292, 1....   \n",
       "66  [0.4717042148113251, 0.25946807861328125, 0.26...   \n",
       "67  [0.5658812522888184, 0.14174285531044006, 1.72...   \n",
       "68  [0.002913538133725524, 0.05819639191031456, 0....   \n",
       "69  [0.388578325510025, 0.11661688983440399, 0.557...   \n",
       "72  [-0.12527808547019958, 0.10292448848485947, 0....   \n",
       "73  [0.02618008852005005, 0.1555686593055725, 0.56...   \n",
       "74  [0.27644652128219604, 0.010255341418087482, 0....   \n",
       "75  [-0.010015602223575115, 0.20139937102794647, 0...   \n",
       "76  [0.3634061813354492, 0.33145445585250854, 0.66...   \n",
       "79  [0.11553211510181427, 0.3050263226032257, 0.77...   \n",
       "80  [0.061408478766679764, -0.10594585537910461, 0...   \n",
       "81  [0.05952707305550575, 0.18555621802806854, 0.4...   \n",
       "82  [0.21248240768909454, 0.19034068286418915, 0.3...   \n",
       "83  [0.5158725380897522, 0.8936625719070435, 0.254...   \n",
       "\n",
       "                                                 SwAV  \n",
       "58  [0.1606316864490509, 0.0, 0.07132810354232788,...  \n",
       "59  [0.04924654960632324, 0.10594171285629272, 0.0...  \n",
       "60  [0.02732289955019951, 0.02447810210287571, 0.0...  \n",
       "61  [0.0076486459001898766, 0.08338148891925812, 0...  \n",
       "62  [0.020717304199934006, 0.03640280291438103, 0....  \n",
       "65  [0.36383309960365295, 0.0701654851436615, 0.02...  \n",
       "66  [0.007726115640252829, 0.20479148626327515, 0....  \n",
       "67  [0.1871039718389511, 0.17521421611309052, 0.07...  \n",
       "68  [0.2094479203224182, 0.03686278313398361, 0.0,...  \n",
       "69  [0.19142675399780273, 0.016550062224268913, 0....  \n",
       "72  [0.1848812997341156, 0.007837839424610138, 0.0...  \n",
       "73  [0.20050321519374847, 0.1347011774778366, 0.08...  \n",
       "74  [0.18241813778877258, 0.03189263492822647, 0.1...  \n",
       "75  [0.05929999426007271, 0.008365996181964874, 0....  \n",
       "76  [0.017012866213917732, 0.04213583096861839, 0....  \n",
       "79  [0.18055063486099243, 0.05714978277683258, 0.0...  \n",
       "80  [0.11496221274137497, 0.011517089791595936, 0....  \n",
       "81  [0.11528719216585159, 0.15534739196300507, 0.0...  \n",
       "82  [0.15056075155735016, 0.09389893710613251, 0.0...  \n",
       "83  [0.25882673263549805, 0.07133975625038147, 0.0...  \n",
       "\n",
       "[20 rows x 23 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test_idx = [20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 45, 46, 47, 48, 50, 51, 52, 53, 54, 55, 56, 58, 59, 60, 62, 63, 64, 65, 66, 67, 68, 69, 71, 72, 73, 74, 75, 79, 80, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 106, 107, 108, 109, 111, 113, 115, 116, 117, 118, 119, 120, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140]\n",
    "# test_idx = [20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 71, 72, 73, 74, 75, 77, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 106, 107, 108, 109, 110, 111, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140]\n",
    "# Paper Only\n",
    "# df_final_samples    = df.loc[(df['Sample Indicator'] == 11) & (df['ID'].isin(test_idx))]\n",
    "# df_final_samples.head()\n",
    "# print(df.keys())\n",
    "# df_final_samples    = df.loc[(df['Search Reconstruction'] == True)]\n",
    "simple = [0,1,2,3,4,5]\n",
    "comp = [6,7,8,9,10,11]\n",
    "df_final_samples    = df.loc[(df['Sample Indicator'] == 12)]\n",
    "# df_final_samples    = df.loc[(df['Sample Indicator'] == 12) & (df['ID'].isin(comp))]\n",
    "# df_final_samples    = df.loc[(df['Search Reconstruction'] == True) & (df['ID'].isin(test_idx))]\n",
    "# print(len(df_final_samples), len(df_final_samples)/5)\n",
    "# print(np.unique(np.array(df_final_samples['ID'].tolist()), return_counts=True))\n",
    "# df_final_samples.head()\n",
    "\n",
    "\n",
    "print(\"------------------------------------------------ Brain Correlation V1 -----------------------------------------------------------------\")\n",
    "\n",
    "print(\"Brain Correlation V1: \", df_final_samples['Brain Correlation V1'].mean())\n",
    "\n",
    "print(\"------------------------------------------------ Brain Correlation V2 -----------------------------------------------------------------\")\n",
    "\n",
    "print(\"Brain Correlation V2: \", df_final_samples['Brain Correlation V2'].mean())\n",
    "\n",
    "print(\"------------------------------------------------ Brain Correlation V3 -----------------------------------------------------------------\")\n",
    "\n",
    "print(\"Brain Correlation V3: \", df_final_samples['Brain Correlation V3'].mean())\n",
    "\n",
    "print(\"------------------------------------------------ Brain Correlation V4 -----------------------------------------------------------------\")\n",
    "\n",
    "print(\"Brain Correlation V4: \", df_final_samples['Brain Correlation V4'].mean())\n",
    "\n",
    "print(\"------------------------------------------------ Brain Correlation Early Visual -------------------------------------------------------\")\n",
    "\n",
    "print(\"Brain Correlation Early Visual: \", df_final_samples['Brain Correlation Early Visual'].mean())\n",
    "\n",
    "print(\"------------------------------------------------ Brain Correlation Higher Visual -------------------------------------------------------\")\n",
    "\n",
    "print(\"Brain Correlation Higher Visual: \", df_final_samples['Brain Correlation Higher Visual'].mean())\n",
    "\n",
    "print(\"------------------------------------------------ Brain Correlation NSD General ---------------------------------------------------------\")\n",
    "\n",
    "print(\"Brain Correlation NSD General: \", df_final_samples['Brain Correlation NSD General'].mean())\n",
    "df_final_samples.tail(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average Iteration Brain Region Plot\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "brain_correlation_V1 = []\n",
    "brain_correlation_V2 = []\n",
    "brain_correlation_V3 = []\n",
    "brain_correlation_V4 = []\n",
    "brain_correlation_early_visual = []\n",
    "brain_correlation_higher_visual = []\n",
    "brain_correlation_unmasked = []\n",
    "brain_correlation_ground_truth = []\n",
    "\n",
    "folders = {\"vdvae_distribution\" : 2, \"clip_distribution\" : 1, \"clip+vdvae_distribution\" : 3, \"iter_0\" : 4, \"iter_1\" : 5 , \"iter_2\" : 6, \"iter_3\" : 7, \"iter_4\" : 8, \"iter_5\" : 9}\n",
    "x = [\"vdvae\", \"clip\", \"clip+\\nvdvae\", \"iter 0\", \"iter 1\", \"iter 2\", \"iter 3\", \"iter 4\", \"iter 5\"]\n",
    "\n",
    "for folder, sample_indicator in folders.items():\n",
    "    \n",
    "    iteration_val_v1 = df.loc[(df['Sample Indicator'] == sample_indicator)]['Brain Correlation V1'].mean()\n",
    "    iteration_val_v2 = df.loc[(df['Sample Indicator'] == sample_indicator)]['Brain Correlation V2'].mean()\n",
    "    iteration_val_v3 = df.loc[(df['Sample Indicator'] == sample_indicator)]['Brain Correlation V3'].mean()\n",
    "    iteration_val_v4 = df.loc[(df['Sample Indicator'] == sample_indicator)]['Brain Correlation V4'].mean()\n",
    "    iteration_val_ev = df.loc[(df['Sample Indicator'] == sample_indicator)]['Brain Correlation Early Visual'].mean()\n",
    "    iteration_val_hv = df.loc[(df['Sample Indicator'] == sample_indicator)]['Brain Correlation Higher Visual'].mean()\n",
    "    iteration_val_unmasked = df.loc[(df['Sample Indicator'] == sample_indicator)]['Brain Correlation NSD General'].mean()\n",
    "    \n",
    "    brain_correlation_V1.append(iteration_val_v1)\n",
    "    brain_correlation_V2.append(iteration_val_v2)\n",
    "    brain_correlation_V3.append(iteration_val_v3)\n",
    "    brain_correlation_V4.append(iteration_val_v4)\n",
    "    brain_correlation_early_visual.append(iteration_val_ev)\n",
    "    brain_correlation_higher_visual.append(iteration_val_hv)\n",
    "    brain_correlation_unmasked.append(iteration_val_unmasked)\n",
    "    \n",
    "\n",
    "# plt.axhline(y = df.loc[(df['Sample Indicator'] == 0.0)]['Brain Correlation V1'].mean(), color = 'blue', linestyle = 'dashed', linewidth=1)\n",
    "# plt.axhline(y = df.loc[(df['Sample Indicator'] == 0.0)]['Brain Correlation V2'].mean(), color = 'green', linestyle = 'dashed', linewidth=1)\n",
    "# plt.axhline(y = df.loc[(df['Sample Indicator'] == 0.0)]['Brain Correlation V3'].mean(), color = 'red',linestyle = 'dashed', linewidth=1)\n",
    "# plt.axhline(y = df.loc[(df['Sample Indicator'] == 0.0)]['Brain Correlation V4'].mean(), color = 'orange',linestyle = 'dashed', linewidth=1)\n",
    "# plt.axhline(y = df.loc[(df['Sample Indicator'] == 0.0)]['Brain Correlation Higher Visual'].mean(), color = 'brown', linestyle = 'dashed', linewidth=1)\n",
    "# plt.axhline(y = df.loc[(df['Sample Indicator'] == 0.0)]['Brain Correlation Early Visual'].mean(),  color = 'magenta',linestyle = 'dashed', linewidth=1)\n",
    "plt.axhline(y = df.loc[(df['Sample Indicator'] == 0.0)]['Brain Correlation NSD General'].mean(), color = 'black', linestyle = 'dashed', linewidth=1)\n",
    "\n",
    "plt.plot(brain_correlation_V1, marker='.', color = 'blue', label = 'V1', linewidth=1)\n",
    "plt.plot(brain_correlation_V2, marker='.', color = 'green',label = 'V2', linewidth=1)\n",
    "plt.plot(brain_correlation_V3, marker='.', color = 'red',  label = 'V3', linewidth=1)\n",
    "plt.plot(brain_correlation_V4, marker='.', color = 'orange', label = 'V4', linewidth=1)\n",
    "plt.plot(brain_correlation_higher_visual, marker='.', color = 'brown', label = 'Higher Visual', linewidth=1)\n",
    "plt.plot(brain_correlation_early_visual, marker='.',  color = 'magenta', label = 'Early Visual', linewidth=1)\n",
    "plt.plot(brain_correlation_unmasked, marker='.',  color = 'black', label = 'NSD General', linewidth=1)\n",
    "plt.xticks(range(len(x)), x,fontsize=9)\n",
    "\n",
    "plt.legend(fontsize = \"xx-small\")\n",
    "plt.xlabel(\"Search Iteration\")\n",
    "plt.ylabel(\"Avearge Brain Pearson Correlation\")\n",
    "plt.title(\"Encoded Brain Pearson Correlation\")\n",
    "mpl.rcParams['figure.dpi'] = 300\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average Iteration Brain Region Plot\n",
    "\n",
    "brain_correlation_V1 = []\n",
    "brain_correlation_V2 = []\n",
    "brain_correlation_V3 = []\n",
    "brain_correlation_V4 = []\n",
    "brain_correlation_early_visual = []\n",
    "brain_correlation_higher_visual = []\n",
    "brain_correlation_unmasked = []\n",
    "brain_correlation_ground_truth = []\n",
    "\n",
    "y_v1 = df.loc[(df['Sample Indicator'] == 0.0)]['Brain Correlation V1'].mean()\n",
    "y_v2 = df.loc[(df['Sample Indicator'] == 0.0)]['Brain Correlation V2'].mean()\n",
    "y_v3 = df.loc[(df['Sample Indicator'] == 0.0)]['Brain Correlation V3'].mean()\n",
    "y_v4 = df.loc[(df['Sample Indicator'] == 0.0)]['Brain Correlation V4'].mean()\n",
    "y_ev = df.loc[(df['Sample Indicator'] == 0.0)]['Brain Correlation Early Visual'].mean()\n",
    "y_hv = df.loc[(df['Sample Indicator'] == 0.0)]['Brain Correlation Higher Visual'].mean()\n",
    "y_unmasked = df.loc[(df['Sample Indicator'] == 0.0)]['Brain Correlation NSD General'].mean()\n",
    "\n",
    "v1_set = True\n",
    "v2_set = True\n",
    "v3_set = True\n",
    "v4_set = True\n",
    "ev_set = True\n",
    "hv_set = True\n",
    "unmasked_set = True\n",
    "\n",
    "x_v1 = 0 \n",
    "x_v2 = 0 \n",
    "x_v3 = 0 \n",
    "x_v4 = 0 \n",
    "x_ev = 0 \n",
    "x_hv = 0 \n",
    "x_umasked = 0 \n",
    "\n",
    "folders = {\"vdvae_distribution\" : 2, \"clip_distribution\" : 1, \"clip+vdvae_distribution\" : 3, \"iter_0\" : 4, \"iter_1\" : 5 , \"iter_2\" : 6, \"iter_3\" : 7, \"iter_4\" : 8, \"iter_5\" : 9}\n",
    "x = [\"vdvae\", \"clip\", \"clip+\\nvdvae\", \"iter 0\", \"iter 1\", \"iter 2\", \"iter 3\", \"iter 4\", \"iter 5\"]\n",
    "iteration = 0\n",
    "\n",
    "\n",
    "for folder, sample_indicator in folders.items():\n",
    "    \n",
    "    iteration_val_v1 = df.loc[(df['Sample Indicator'] == sample_indicator)]['Brain Correlation V1'].mean()\n",
    "    iteration_val_v2 = df.loc[(df['Sample Indicator'] == sample_indicator)]['Brain Correlation V2'].mean()\n",
    "    iteration_val_v3 = df.loc[(df['Sample Indicator'] == sample_indicator)]['Brain Correlation V3'].mean()\n",
    "    iteration_val_v4 = df.loc[(df['Sample Indicator'] == sample_indicator)]['Brain Correlation V4'].mean()\n",
    "    iteration_val_ev = df.loc[(df['Sample Indicator'] == sample_indicator)]['Brain Correlation Early Visual'].mean()\n",
    "    iteration_val_hv = df.loc[(df['Sample Indicator'] == sample_indicator)]['Brain Correlation Higher Visual'].mean()\n",
    "    iteration_val_unmasked = df.loc[(df['Sample Indicator'] == sample_indicator)]['Brain Correlation NSD General'].mean()\n",
    "    \n",
    "    brain_correlation_V1.append(iteration_val_v1)\n",
    "    brain_correlation_V2.append(iteration_val_v2)\n",
    "    brain_correlation_V3.append(iteration_val_v3)\n",
    "    brain_correlation_V4.append(iteration_val_v4)\n",
    "    brain_correlation_early_visual.append(iteration_val_ev)\n",
    "    brain_correlation_higher_visual.append(iteration_val_hv)\n",
    "    brain_correlation_unmasked.append(iteration_val_unmasked)\n",
    "    \n",
    "    if(iteration_val_v1 > y_v1 and v1_set):\n",
    "        x_v1 = iteration - 1\n",
    "        v1_set = False\n",
    "        \n",
    "    if(iteration_val_v2 > y_v2 and v2_set):\n",
    "        x_v2 = iteration - 1\n",
    "        v2_set = False\n",
    "        \n",
    "    if(iteration_val_v3 > y_v3 and v3_set):\n",
    "        x_v3 = iteration - 1\n",
    "        v3_set = False\n",
    "        \n",
    "    if(iteration_val_v4 > y_v4 and v4_set):\n",
    "        x_v4 = iteration - 1\n",
    "        v4_set = False\n",
    "        \n",
    "    if(iteration_val_ev > y_ev and ev_set):\n",
    "        x_ev = iteration - 1\n",
    "        ev_set = False\n",
    "        \n",
    "    if(iteration_val_hv > y_hv and hv_set):\n",
    "        x_hv = iteration - 1\n",
    "        hv_set = False\n",
    "        \n",
    "    if(iteration_val_unmasked > y_unmasked and unmasked_set):\n",
    "        x_unmasked = iteration - 1\n",
    "        unmasked_set = False\n",
    "        \n",
    "    iteration += 1\n",
    "    \n",
    "# print(df.loc[(df['Sample Indicator'] == 0.0)]['Brain Correlation Unmasked'].mean())\n",
    "# plt.axhline(y = df.loc[(df['Sample Indicator'] == 0.0)]['Brain Correlation Unmasked'].mean(), linestyle = 'dashed', label = 'Brain Correlation Unmasked')\n",
    "# plt.axhline(y = df.loc[(df['Sample Indicator'] == 0.0)]['Brain Correlation V1'].mean(), linestyle = '-', label = 'Brain Correlation V1')\n",
    "# plt.axhline(y = df.loc[(df['Sample Indicator'] == 0.0)]['Brain Correlation V2'].mean(), linestyle = '-', label = 'Brain Correlation V2')\n",
    "# plt.axhline(y = df.loc[(df['Sample Indicator'] == 0.0)]['Brain Correlation V3'].mean(), linestyle = '-', label = 'Brain Correlation V3')\n",
    "# plt.axhline(y = df.loc[(df['Sample Indicator'] == 0.0)]['Brain Correlation V4'].mean(), linestyle = '-', label = 'Brain Correlation V4')\n",
    "# plt.axhline(y = df.loc[(df['Sample Indicator'] == 0.0)]['Brain Correlation Higher Visual'].mean(), linestyle = '-', label = 'Brain Correlation Higher Visual')\n",
    "# plt.axhline(y = df.loc[(df['Sample Indicator'] == 0.0)]['Brain Correlation Early Visual'].mean(), linestyle = '-', label = 'Brain Correlation Higher Visual')\n",
    "\n",
    "\n",
    "N = 9\n",
    "#x = np.array([0,1,2,3,4,5,6,7,8,9])\n",
    "# y = np.array(brain_correlation_unmasked)\n",
    "# a, b = np.polyfit(x, brain_correlation_unmasked, deg=1)\n",
    "# y_est = a * x + b\n",
    "# y_err = st.t.interval(alpha=0.95, df=len(y)-1, loc=np.mean(y), scale=st.sem(y))\n",
    "# print(y_err[0])\n",
    "# print(y_err[1])\n",
    "\n",
    "y_un = np.array(brain_correlation_unmasked)\n",
    "ci_un = 0.95 * np.std(y_un) / math.sqrt(N)\n",
    "\n",
    "\n",
    "# def mean_confidence_interval(data, confidence=0.95):\n",
    "#     a = 1.0 * np.array(data)\n",
    "#     n = len(a)\n",
    "#     m, se = np.mean(a), scipy.stats.sem(a)\n",
    "#     h = se * scipy.stats.t.ppf((1 + confidence) / 2., n-1)\n",
    "#     return m, m-h, m+h\n",
    "\n",
    "# mean, lower, upper = [],[],[]\n",
    "# ci = 0.95\n",
    "\n",
    "# m, ml, mu = mean_confidence_interval(y, ci)\n",
    "# mean.append(m)\n",
    "# lower.append(ml)\n",
    "# upper.append(mu)\n",
    "\n",
    "\n",
    "plt.plot(brain_correlation_V1, marker='.', label = 'V1', linewidth=1, color = \"royalblue\")\n",
    "plt.plot(brain_correlation_V2, marker='.', label = 'V2', linewidth=1, color = \"darkviolet\")\n",
    "plt.plot(brain_correlation_V3, marker='.', label = 'V3', linewidth=1, color = \"red\")\n",
    "plt.plot(brain_correlation_V4, marker='.', label = 'V4', linewidth=1, color = \"forestgreen\")\n",
    "#plt.plot(brain_correlation_early_visual, marker='.', label = 'Early Visual', linewidth=1, color = \"red\")\n",
    "plt.plot(brain_correlation_higher_visual, marker='.', label = 'Higher Visual', linewidth=1, color = \"darkorange\")\n",
    "plt.plot(brain_correlation_unmasked, marker='.', label = 'NSD General', linewidth=1, color = \"black\")\n",
    "plt.xticks(range(len(x)), x,fontsize=9)\n",
    "# plt.fill_between(x, y_err[0], y_err[0], color='dimgray', alpha=0.2)\n",
    "# plt.fill_between(x, upper, lower, color='dimgray', alpha=0.2)\n",
    "plt.fill_between(x, (y_un-ci_un), (y_un+ci_un), color='black', alpha=.2)\n",
    "# plt.fill_between(x, (y_hi-ci_hi), (y_hi+ci_hi), color='darkorange', alpha=.2)\n",
    "# plt.fill_between(x, (y_er-ci_er), (y_er+ci_er), color='red', alpha=.2)\n",
    "# plt.fill_between(x, (y_vo-ci_vo), (y_vo+ci_vo), color='royalblue', alpha=.2)\n",
    "# plt.fill_between(x, (y_vt-ci_vt), (y_vt+ci_vt), color='darkviolet', alpha=.2)\n",
    "# plt.fill_between(x, (y_vth-ci_vth), (y_vth+ci_vth), color='violet', alpha=.2)\n",
    "# plt.fill_between(x, (y_vf-ci_vf), (y_vf+ci_vf), color='forestgreen', alpha=.2)\n",
    "\n",
    "# plt.plot([7.25, 7 + 1], [y_v1, y_v1] , color = \"royalblue\", linestyle=\"dashed\", linewidth=2)\n",
    "# plt.plot([7.25, 7 + 1], [y_v2, y_v2] , color = \"darkviolet\", linestyle=\"dashed\", linewidth=2)\n",
    "# plt.plot([7.25, 7 + 1], [y_v3, y_v3] , color = \"violet\", linestyle=\"dashed\", linewidth=2)\n",
    "# plt.plot([x_v4 + 0.25, x_v4 + 1], [y_v4, y_v4] , color = 'forestgreen', linestyle=\"dashed\", linewidth=2)\n",
    "# plt.plot([7.25, 7 + 1], [y_ev - 0.002, y_ev - 0.002] , color = 'red', linestyle=\"dashed\", linewidth=2)\n",
    "# plt.plot([x_hv - 0.25, x_hv + 0.50], [y_hv, y_hv] , color = \"darkorange\", linestyle=\"dashed\", linewidth=2)\n",
    "# plt.plot([x_unmasked + 0.5, x_unmasked + 1.25], [y_unmasked, y_unmasked] , color = 'black', linestyle=\"dashed\", linewidth=2, label=\"Ground Truth Image\")\n",
    "#plt.axhline(x = [1,3], y = df.loc[(df['Sample Indicator'] == 0.0)]['Brain Correlation Unmasked'].mean(), linestyle = 'dashed', label = 'Brain Correlation Unmasked')\n",
    "# plt.axhline(y = df.loc[(df['Sample Indicator'] == 0.0)]['Brain Correlation V1'].mean(), linestyle = '-', label = 'Brain Correlation V1')\n",
    "# plt.axhline(y = df.loc[(df['Sample Indicator'] == 0.0)]['Brain Correlation V2'].mean(), linestyle = '-', label = 'Brain Correlation V2')\n",
    "# plt.axhline(y = df.loc[(df['Sample Indicator'] == 0.0)]['Brain Correlation V3'].mean(), linestyle = '-', label = 'Brain Correlation V3')\n",
    "# plt.axhline(y = df.loc[(df['Sample Indicator'] == 0.0)]['Brain Correlation V4'].mean(), linestyle = '-', label = 'Brain Correlation V4')\n",
    "# plt.axhline(y = df.loc[(df['Sample Indicator'] == 0.0)]['Brain Correlation Higher Visual'].mean(), linestyle = '-', label = 'Brain Correlation Higher Visual')\n",
    "# plt.axhline(y = df.loc[(df['Sample Indicator'] == 0.0)]['Brain Correlation Early Visual'].mean(), linestyle = '-', label = 'Brain Correlation Higher Visual')\n",
    "leg = plt.legend(loc=\"upper left\", ncol = 2, fontsize = \"4.5\")\n",
    "# leg.legendHandles[7].set_color('silver')\n",
    "plt.xlabel(\"Search Iteration\")\n",
    "plt.ylabel(\"Avearge Brain Pearson Correlation\")\n",
    "plt.title(\"Encoded Brain Pearson Correlation\")\n",
    "mpl.rcParams['figure.dpi'] = 2500\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search iterations to Ground Truth\n",
    "\n",
    "x_iter_values = []\n",
    "\n",
    "x_iter_values.append(10)\n",
    "x_iter_values.append(10)\n",
    "x_iter_values.append(10)\n",
    "x_iter_values.append(9)\n",
    "x_iter_values.append(0)\n",
    "\n",
    "x_labels = ['V1', 'V2', 'V3', 'V4', 'Higher Visual']\n",
    "x_axis = np.arange(len(x_labels))\n",
    "# y_labels = [\"0\", \"2\", \"4\", \"6\", \"8\", \"10 >=\"]\n",
    "# y_axis = np.arange(len(y_labels))\n",
    "\n",
    "# x_iter_values.append(0)\n",
    "# x_iter_values.append(x_v4)\n",
    "# x_iter_values.append(x_v3)\n",
    "# x_iter_values.append(x_v2)\n",
    "# x_iter_values.append(9)\n",
    "\n",
    "# x_labels = ['Higher Visual', 'V4', 'V3', 'V2', 'V1']\n",
    "plt.xticks(x_axis, x_labels)\n",
    "# plt.yticks(y_axis, y_labels)\n",
    "plt.plot(x_iter_values, marker='o', linewidth=2, color = \"darkgray\")\n",
    "plt.xlabel(\"Brain Areas\", fontsize=18)\n",
    "plt.ylabel(\"Iterations to ground truth\", fontsize=18)\n",
    "plt.title(\"Search iterations to surpass ground truth\\n brain correlation score\", fontsize=20)\n",
    "mpl.rcParams['figure.dpi'] = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar Plot Sample Counts \n",
    "\n",
    "idx = [20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, \n",
    "        64, 65, 66, 67, 68, 69, 71, 72, 73, 74, 75, 77, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 106, 107, 108, \n",
    "        109, 110, 111, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145,\n",
    "        147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, \n",
    "        182, 183, 184, 185, 186, 188, 189, 190, 191, 192, 193, 194, 195, 196, 198, 199, 200, 201, 202, 203, 205, 206, 207, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, \n",
    "        221, 222, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 256, 257, \n",
    "        258, 259, 261, 262, 263, 264, 265, 266, 267, 268, 270, 272, 273, 274, 275, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, \n",
    "        297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, \n",
    "        333, 334, 335, 336, 337, 338, 339, 341, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 364, 365, 366, 367, 368, 369, 370, \n",
    "        371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 393, 394, 395, 396, 397, 398, 400, 401, 402, 403, 404, 406, 407, 408, \n",
    "        409, 410, 411, 412, 413, 414, 415, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, \n",
    "        447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 481, 482, \n",
    "        483, 484, 485, 486, 487, 488, 489, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, \n",
    "        521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 547, 548, 549, 551, 552, 553, 554, 555, 556, 557, \n",
    "        558, 559, 560, 561, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, \n",
    "        594, 595, 596, 597, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 616, 617, 618, 619, 620, 621, 622, 624, 625, 626, 627, 628, 629, 630, 631, 632, \n",
    "        633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 655, 656, 657, 659, 661, 662, 663, 664, 666, 667, 668, 669, 670, 671, \n",
    "        672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 694, 695, 696, 698, 699, 700, 701, 702, 703, 704, 705, 706, 708, 709, \n",
    "        710, 711, 712, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, \n",
    "        747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 782, 783, \n",
    "        784, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819,\n",
    "        820, 821, 822, 823, 824, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 838, 839, 840, 841, 842, 843, 844, 845, 847, 848, 849, 851, 852, 854, 855, 856, 857, 858, 859,\n",
    "        861, 862, 863, 864, 865, 866, 867, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 892, 893, 894, 895, 896, 897, \n",
    "        898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 911, 912, 913, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, \n",
    "        934, 936, 937, 938, 939, 940, 941, 942, 943, 944, 945, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961, 962, 963, 964, 965, 966, 967, 968, 969, 970, \n",
    "        971, 974, 976, 977, 978, 979, 980, 981]\n",
    "\n",
    "v1 = [0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "v2 = [0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "v3 = [0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "v4 = [0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "ev = [0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "hv = [0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "nsd = [0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "\n",
    "#folders = {\"vdvae_distribution\" : 0, \"clip_distribution\" : 1, \"clip+vdvae_distribution\" : 2, \"iter_0\" : 3, \"iter_1\" : 4, \"iter_2\" : 5, \"iter_3\" : 6, \"iter_4\" : 7 , \"iter_5\": 8}\n",
    "#folders = {\"clip_distribution\" : 1, \"vdvae_distribution\" : 2, \"clip+vdvae_distribution\" : 3, \"iter_0\" : 4, \"iter_1\" : 5 , \"iter_2\" : 6, \"iter_3\" : 7, \"iter_4\" : 8, \"iter_5\" : 9}\n",
    "folders = {\"vdvae_distribution\" : 2, \"clip_distribution\" : 1, \"clip+vdvae_distribution\" : 3, \"iter_0\" : 4, \"iter_1\" : 5 , \"iter_2\" : 6, \"iter_3\" : 7, \"iter_4\" : 8, \"iter_5\" : 9}\n",
    "list_indicator = {2 : 0, 1 : 1, 3 : 2, 4 : 3, 5 : 4 , 6 : 5, 7 : 6, 8 : 7, 9 : 8}\n",
    "\n",
    "ground_truth_samples = df.loc[(df['Sample Indicator'] == 0)]\n",
    "\n",
    "# Append rows to an empty DataFrame\n",
    "for i in tqdm(idx, desc=\"creating bar graph numbers\"):\n",
    "        \n",
    "    ground_truth_v1     = float(ground_truth_samples.loc[(ground_truth_samples['ID'] == i)]['Brain Correlation V1'])\n",
    "    ground_truth_v2     = float(ground_truth_samples.loc[(ground_truth_samples['ID'] == i)]['Brain Correlation V2'])\n",
    "    ground_truth_v3     = float(ground_truth_samples.loc[(ground_truth_samples['ID'] == i)]['Brain Correlation V3'])\n",
    "    ground_truth_v4     = float(ground_truth_samples.loc[(ground_truth_samples['ID'] == i)]['Brain Correlation V4'])\n",
    "    ground_truth_ev     = float(ground_truth_samples.loc[(ground_truth_samples['ID'] == i)]['Brain Correlation Early Visual'])\n",
    "    ground_truth_hv     = float(ground_truth_samples.loc[(ground_truth_samples['ID'] == i)]['Brain Correlation Higher Visual'])\n",
    "    ground_truth_nsd    = float(ground_truth_samples.loc[(ground_truth_samples['ID'] == i)]['Brain Correlation NSD General'])\n",
    "    \n",
    "    single_sample = df.loc[(df['ID'] == i)]\n",
    "    single_sample = single_sample[:-2]\n",
    "    \n",
    "    for folder, value in folders.items():\n",
    "    \n",
    "        v1_bc = single_sample.loc[(single_sample['Sample Indicator'] == value)]['Brain Correlation V1'].mean()\n",
    "        v2_bc = single_sample.loc[(single_sample['Sample Indicator'] == value)]['Brain Correlation V2'].mean()\n",
    "        v3_bc = single_sample.loc[(single_sample['Sample Indicator'] == value)]['Brain Correlation V3'].mean()\n",
    "        v4_bc = single_sample.loc[(single_sample['Sample Indicator'] == value)]['Brain Correlation V4'].mean()\n",
    "        ev_bc = single_sample.loc[(single_sample['Sample Indicator'] == value)]['Brain Correlation Early Visual'].mean()\n",
    "        hv_bc = single_sample.loc[(single_sample['Sample Indicator'] == value)]['Brain Correlation Higher Visual'].mean()\n",
    "        nsd_bc = single_sample.loc[(single_sample['Sample Indicator'] == value)]['Brain Correlation NSD General'].mean()\n",
    "\n",
    "        if(v1_bc > ground_truth_v1):\n",
    "            v1[list_indicator[value]] += 1\n",
    "            \n",
    "        if(v2_bc > ground_truth_v2):\n",
    "            v2[list_indicator[value]] += 1\n",
    "            \n",
    "        if(v3_bc > ground_truth_v3):\n",
    "            v3[list_indicator[value]] += 1\n",
    "            \n",
    "        if(v4_bc > ground_truth_v4):\n",
    "            v4[list_indicator[value]] += 1\n",
    "        \n",
    "        if(ev_bc > ground_truth_ev):\n",
    "            ev[list_indicator[value]] += 1\n",
    "            \n",
    "        if(hv_bc > ground_truth_hv):\n",
    "            hv[list_indicator[value]] += 1\n",
    "            \n",
    "        if(nsd_bc > ground_truth_nsd):\n",
    "            nsd[list_indicator[value]] += 1\n",
    "            \n",
    "print(v1)\n",
    "print(v2)\n",
    "print(v3)\n",
    "print(v4)\n",
    "print(ev)\n",
    "print(hv)\n",
    "print(nsd)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Bar Plots\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "\n",
    "\n",
    "# x = [\"vdvae\", \"clip\", \"clip+\\nvdvae\", \"iter 0\", \"iter 1\", \"iter 2\", \"iter 3\", \"iter 4\", \"iter 5\"]\n",
    "# x = [\"V1\", \"V2\", \"V3\", \"V4\", \"Early \\nVisual\", \"Higher \\nVisual\", \"NSD \\nGeneral\"]\n",
    "\n",
    "# vdvae       = [v1[0], v2[0], v3[0], v4[0], ev[0], hv[0], nsd[0]]\n",
    "# clip        = [v1[1], v2[1], v3[1], v4[1], ev[1], hv[1], nsd[1]]\n",
    "# clip_vdvae  = [v1[2], v2[2], v3[2], v4[2], ev[2], hv[2], nsd[2]]\n",
    "# iter_0      = [v1[3], v2[3], v3[3], v4[3], ev[3], hv[3], nsd[3]]\n",
    "# iter_1      = [v1[4], v2[4], v3[4], v4[4], ev[4], hv[4], nsd[4]]\n",
    "# iter_2      = [v1[5], v2[5], v3[5], v4[5], ev[5], hv[5], nsd[5]]\n",
    "# iter_3      = [v1[6], v2[6], v3[6], v4[6], ev[6], hv[6], nsd[6]]\n",
    "# iter_4      = [v1[7], v2[7], v3[7], v4[7], ev[7], hv[7], nsd[7]]\n",
    "# iter_5      = [v1[8], v2[8], v3[8], v4[8], ev[8], hv[8], nsd[8]]\n",
    "\n",
    "\n",
    "x = [\"V1\", \"V2\", \"V3\", \"V4\", \"Higher \\nVisual\", \"NSD \\nGeneral\"]\n",
    "\n",
    "vdvae       = [v1[0], v2[0], v3[0], v4[0], hv[0], nsd[0]]\n",
    "clip        = [v1[1], v2[1], v3[1], v4[1], hv[1], nsd[1]]\n",
    "clip_vdvae  = [v1[2], v2[2], v3[2], v4[2], hv[2], nsd[2]]\n",
    "iter_0      = [v1[3], v2[3], v3[3], v4[3], hv[3], nsd[3]]\n",
    "iter_1      = [v1[4], v2[4], v3[4], v4[4], hv[4], nsd[4]]\n",
    "iter_2      = [v1[5], v2[5], v3[5], v4[5], hv[5], nsd[5]]\n",
    "iter_3      = [v1[6], v2[6], v3[6], v4[6], hv[6], nsd[6]]\n",
    "iter_4      = [v1[7], v2[7], v3[7], v4[7], hv[7], nsd[7]]\n",
    "iter_5      = [v1[8], v2[8], v3[8], v4[8], hv[8], nsd[8]]\n",
    "\n",
    "\n",
    "x_axis = np.arange(len(x))\n",
    "\n",
    "n = 6\n",
    "r = np.arange(n)\n",
    "width = 0.10\n",
    "\n",
    "\n",
    "plt.bar(r - width * 4, vdvae, color = '#e3342f',\n",
    "        width = width, edgecolor = 'black',\n",
    "        label='VDVAE')\n",
    "plt.bar(r - width * 3, clip, color = '#f6993f',\n",
    "        width = width, edgecolor = 'black',\n",
    "        label='CLIP')\n",
    "plt.bar(r - width * 2, clip_vdvae, color = '#ffed4a',\n",
    "        width = width, edgecolor = 'black',\n",
    "        label='CLIP+VDVAE')\n",
    "plt.bar(r - width, iter_0, color = '#38c172',\n",
    "        width = width, edgecolor = 'black',\n",
    "        label='Iteration 0')\n",
    "plt.bar(r, iter_1, color = '#4dc0b5',\n",
    "        width = width, edgecolor = 'black',\n",
    "        label='Iteration 1')\n",
    "plt.bar(r + width, iter_2, color = '#3490dc',\n",
    "        width = width, edgecolor = 'black',\n",
    "        label='Iteration 2')\n",
    "plt.bar(r + width * 2, iter_3, color = '#6574cd',\n",
    "        width = width, edgecolor = 'black',\n",
    "        label='Iteration 3')\n",
    "plt.bar(r + width * 3, iter_4, color = '#9561e2',\n",
    "        width = width, edgecolor = 'black',\n",
    "        label='Iteration 4')\n",
    "plt.bar(r + width * 4, iter_5, color = '#f66d9b',\n",
    "        width = width, edgecolor = 'black',\n",
    "        label='Iteration 5')\n",
    "\n",
    "plt.xticks(x_axis, x)\n",
    "plt.xlabel(\"Brain Areas\")\n",
    "plt.ylabel(\"Percentage of samples aligned to brain activity\")\n",
    "plt.title(\"Sample Distributions Alighned to Brain Activity (N = 897)\")\n",
    "plt.gca().yaxis.set_major_formatter(ticker.PercentFormatter(897))\n",
    "#plt.xlim(897)\n",
    "plt.legend(fontsize = \"x-small\")\n",
    "mpl.rcParams['figure.dpi'] = 500\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN to brain correlation plot\n",
    "arrays = []\n",
    "for sample in range(5):\n",
    "    arrays.append(np.load(\"/home/naxos2-raid25/kneel027/home/kneel027/Second-Sight-Archive/reconstructions/subject1/dataframes/swav_sample_{}.npy\".format(sample)))\n",
    "arrays = np.mean(np.stack(arrays), 0)\n",
    "print(arrays.shape)\n",
    "df_final_samples = df_final_samples.groupby('ID', as_index=False).mean()\n",
    "x = df_final_samples['Brain Correlation NSD General'].values.tolist()\n",
    "y = list(arrays)\n",
    "print(len(x), len(y))\n",
    "plt.scatter(x, y)\n",
    "plt.xlabel(\"Brain Correlation\", fontsize=18)\n",
    "plt.ylabel(\"SwAV\", fontsize=18)\n",
    "plt.title(\"CNN to brain correlation plot\", fontsize=20)\n",
    "mpl.rcParams['figure.dpi'] = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_iter_values = []\n",
    "\n",
    "x_iter_values.append(.701)\n",
    "x_iter_values.append(.822)\n",
    "x_iter_values.append(.830)\n",
    "x_iter_values.append(.828)\n",
    "x_iter_values.append(.831)\n",
    "x_iter_values.append(.831)\n",
    "x_iter_values.append(.833)\n",
    "x_iter_values.append(.838)\n",
    "x_iter_values.append(.758)\n",
    "\n",
    "x_labels = ['Only VDVAE', 'Only CLIP', 'CLIP+VDVAE', 'Iter 0', 'Iter 1','Iter 2','Iter 3','Iter 4','Iter 5']\n",
    "x_axis = np.arange(len(x_labels))\n",
    "# y_labels = [\"0\", \"2\", \"4\", \"6\", \"8\", \"10 >=\"]\n",
    "# y_axis = np.arange(len(y_labels))\n",
    "\n",
    "# x_iter_values.append(0)\n",
    "# x_iter_values.append(x_v4)\n",
    "# x_iter_values.append(x_v3)\n",
    "# x_iter_values.append(x_v2)\n",
    "# x_iter_values.append(9)\n",
    "\n",
    "# x_labels = ['Higher Visual', 'V4', 'V3', 'V2', 'V1']\n",
    "plt.xticks(x_axis, x_labels)\n",
    "# plt.yticks(y_axis, y_labels)\n",
    "plt.plot(x_iter_values, marker='o', linewidth=2, color = \"darkgray\")\n",
    "plt.xlabel(\"Search Iterations\", fontsize=18)\n",
    "plt.ylabel(\"Inception V3\", fontsize=18)\n",
    "mpl.rcParams['figure.dpi'] = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average Iteration Brain Region Plot\n",
    "\n",
    "idx = [20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, \n",
    "        64, 65, 66, 67, 68, 69, 71, 72, 73, 74, 75, 77, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 106, 107, 108, \n",
    "        109, 110, 111, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145,\n",
    "        147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, \n",
    "        182, 183, 184, 185, 186, 188, 189, 190, 191, 192, 193, 194, 195, 196, 198, 199, 200, 201, 202, 203, 205, 206, 207, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, \n",
    "        221, 222, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 256, 257, \n",
    "        258, 259, 261, 262, 263, 264, 265, 266, 267, 268, 270, 272, 273, 274, 275, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, \n",
    "        297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, \n",
    "        333, 334, 335, 336, 337, 338, 339, 341, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 364, 365, 366, 367, 368, 369, 370, \n",
    "        371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 393, 394, 395, 396, 397, 398, 400, 401, 402, 403, 404, 406, 407, 408, \n",
    "        409, 410, 411, 412, 413, 414, 415, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, \n",
    "        447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 481, 482, \n",
    "        483, 484, 485, 486, 487, 488, 489, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, \n",
    "        521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 547, 548, 549, 551, 552, 553, 554, 555, 556, 557, \n",
    "        558, 559, 560, 561, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, \n",
    "        594, 595, 596, 597, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 616, 617, 618, 619, 620, 621, 622, 624, 625, 626, 627, 628, 629, 630, 631, 632, \n",
    "        633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 655, 656, 657, 659, 661, 662, 663, 664, 666, 667, 668, 669, 670, 671, \n",
    "        672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 694, 695, 696, 698, 699, 700, 701, 702, 703, 704, 705, 706, 708, 709, \n",
    "        710, 711, 712, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, \n",
    "        747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 782, 783, \n",
    "        784, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819,\n",
    "        820, 821, 822, 823, 824, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 838, 839, 840, 841, 842, 843, 844, 845, 847, 848, 849, 851, 852, 854, 855, 856, 857, 858, 859,\n",
    "        861, 862, 863, 864, 865, 866, 867, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 892, 893, 894, 895, 896, 897, \n",
    "        898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 911, 912, 913, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, \n",
    "        934, 936, 937, 938, 939, 940, 941, 942, 943, 944, 945, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961, 962, 963, 964, 965, 966, 967, 968, 969, 970, \n",
    "        971, 974, 976, 977, 978, 979, 980, 981]\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.cm as cmx\n",
    "import seaborn as sns\n",
    "\n",
    "brain_correlation_V1 = []\n",
    "brain_correlation_V2 = []\n",
    "brain_correlation_V3 = []\n",
    "brain_correlation_V4 = []\n",
    "brain_correlation_HV = []\n",
    "brain_correlation_NSD = []\n",
    "\n",
    "folders = {\"vdvae_distribution\" : 2, \"clip_distribution\" : 1, \"clip+vdvae_distribution\" : 3, \"iter_0\" : 4, \"iter_1\" : 5 , \"iter_2\" : 6, \"iter_3\" : 7, \"iter_4\" : 8, \"iter_5\" : 9}\n",
    "x = [\"vdvae\", \"clip\", \"clip+\\nvdvae\", \"iter 0\", \"iter 1\", \"iter 2\", \"iter 3\", \"iter 4\", \"iter 5\"]\n",
    "\n",
    "v1 = {2 : [], 1: [], 3: [], 4 : [], 5 : [], 6: [], 7: [], 8: [], 9: []}\n",
    "v2 = {2 : [], 1: [], 3: [], 4 : [], 5 : [], 6: [], 7: [], 8: [], 9: []}\n",
    "v3 = {2 : [], 1: [], 3: [], 4 : [], 5 : [], 6: [], 7: [], 8: [], 9: []}\n",
    "v4 = {2 : [], 1: [], 3: [], 4 : [], 5 : [], 6: [], 7: [], 8: [], 9: []}\n",
    "hv = {2 : [], 1: [], 3: [], 4 : [], 5 : [], 6: [], 7: [], 8: [], 9: []}\n",
    "nsd = {2 : [], 1: [], 3: [], 4 : [], 5 : [], 6: [], 7: [], 8: [], 9: []}\n",
    "\n",
    "\n",
    "for i in idx:\n",
    "    \n",
    "    sample = df.loc[(df['ID'] == i)]\n",
    "        \n",
    "    for folder, sample_indicator in folders.items():\n",
    "\n",
    "        iteration_val_v1 = sample[(df['Sample Indicator'] == sample_indicator)]['Brain Correlation V1'].var()\n",
    "        iteration_val_v2 = sample[(df['Sample Indicator'] == sample_indicator)]['Brain Correlation V2'].var()\n",
    "        iteration_val_v3 = sample[(df['Sample Indicator'] == sample_indicator)]['Brain Correlation V3'].var()\n",
    "        iteration_val_v4 = sample[(df['Sample Indicator'] == sample_indicator)]['Brain Correlation V4'].var()\n",
    "        iteration_val_hv = sample[(df['Sample Indicator'] == sample_indicator)]['Brain Correlation Higher Visual'].var()\n",
    "        iteration_val_nsd = sample[(df['Sample Indicator'] == sample_indicator)]['Brain Correlation NSD General'].var()\n",
    "        \n",
    "        v1[sample_indicator].append(iteration_val_v1)\n",
    "        v2[sample_indicator].append(iteration_val_v2)\n",
    "        v3[sample_indicator].append(iteration_val_v3)\n",
    "        v4[sample_indicator].append(iteration_val_v4)\n",
    "        hv[sample_indicator].append(iteration_val_hv)\n",
    "        nsd[sample_indicator].append(iteration_val_nsd)\n",
    "    \n",
    "# for sample_indicator, variance_list in v1.items():\n",
    "#         brain_correlation_V1.append(sum(variance_list) / len(variance_list))\n",
    "#         brain_correlation_V2.append(sum(v2[sample_indicator]) / len(v2[sample_indicator]))\n",
    "#         brain_correlation_V3.append(sum(v3[sample_indicator]) / len(v3[sample_indicator]))\n",
    "#         brain_correlation_V4.append(sum(v4[sample_indicator]) / len(v4[sample_indicator]))\n",
    "#         brain_correlation_HV.append(sum(hv[sample_indicator]) / len(hv[sample_indicator]))\n",
    "#         brain_correlation_NSD.append(sum(nsd[sample_indicator]) / len(nsd[sample_indicator]))\n",
    "\n",
    "for sample_indicator, variance_list in v1.items():\n",
    "        brain_correlation_V1.append(variance_list)\n",
    "        brain_correlation_V2.append(v2[sample_indicator])\n",
    "        brain_correlation_V3.append(v3[sample_indicator])\n",
    "        brain_correlation_V4.append(v4[sample_indicator])\n",
    "        brain_correlation_HV.append(hv[sample_indicator])\n",
    "        brain_correlation_NSD.append(nsd[sample_indicator])\n",
    "        \n",
    "# fig, axs = plt.subplots()\n",
    "\n",
    "\n",
    "\n",
    "# axs.scatter(x, brain_correlation_V1)\n",
    "# scatter_nsd = { \"labels\": [\"vdvae\", \"clip\", \"clip+\\nvdvae\", \"iter 0\", \"iter 1\", \"iter 2\", \"iter 3\", \"iter 4\", \"iter 5\"], \n",
    "#                 \"correlation\":  brain_correlation_NSD}\n",
    "\n",
    "df_data = pd.DataFrame(columns = ['Search Iterations', 'Brain Area', 'Variance Of Brain Correlation'])\n",
    "\n",
    "stage_labels = [\"VDVAE\", \"CLIP\", \"CLIP+VDVAE\", \"Iteration 0\", \"Iteration 1\", \"Iteration 2\", \"Iteration 3\", \"Iteration 4\", \"Iteration 5\", ]\n",
    "brain_areas = [v1, v2, v3, v4, hv, nsd]\n",
    "brain_area_labels = [\"V1\", \"V2\", \"V3\", \"V4\", \"Higher\\nVisual\", \"NSD\\nGeneral\"]\n",
    "\n",
    "df_row_num = 0\n",
    "for brain_area, label in zip(brain_areas, brain_area_labels):\n",
    "        for s, stage in enumerate([2, 1, 3, 4, 5, 6, 7, 8, 9]):\n",
    "                # print(brain_area[stage])\n",
    "                for i in tqdm(range(len(brain_area[stage]))):\n",
    "                        row = pd.DataFrame({'Search Iterations' : stage_labels[s], 'Brain Area' : label, 'Variance Of Brain Correlation' : brain_area[stage][i]}, index=[df_row_num])\n",
    "                        df_data = pd.concat([df_data, row])\n",
    "                        df_row_num += 1\n",
    "df_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(df_data.tail())\n",
    "custom_palette = [\"#e3342f\", \"#f6993f\", \"#ffed4a\", \"#38c172\", \"#4dc0b5\", \"#3490dc\", \"#6574cd\", \"#9561e2\", \"#f66d9b\"]\n",
    "\n",
    "# sns.set_palette(custom_palette)\n",
    "# sns.catplot(data=df_data, x=\"Brain Area\", y=\"Variance Of Brain Correlation\", hue=\"Search Iterations\", s=5).set(title='Variance Of Brain Correlation Across Iterations')\n",
    "# sns.barplot(data=df_data, x=\"Brain Area\", y=\"Variance Of Brain Correlation\", hue=\"Search Iterations\").set(title='Variance Of Brain Correlation Across Iterations')\n",
    "x = brain_area_labels\n",
    "x_axis = np.arange(len(x))\n",
    "\n",
    "n = 6\n",
    "r = np.arange(n)\n",
    "width = 0.10\n",
    "print(df_data.loc[df_data[\"Search Iterations\"] == \"VDVAE\"].groupby([\"Brain Area\"]).mean())\n",
    "vdvae = df_data.loc[df_data[\"Search Iterations\"] == \"VDVAE\"].groupby([\"Brain Area\"]).mean()[\"Variance Of Brain Correlation\"]\n",
    "plt.bar(r - width * 4, vdvae[2:].append(vdvae[0:2]), color = '#e3342f',\n",
    "        width = width, edgecolor = 'black',\n",
    "        label='VDVAE')\n",
    "clip = df_data.loc[df_data[\"Search Iterations\"] == \"CLIP\"].groupby([\"Brain Area\"]).mean()[\"Variance Of Brain Correlation\"]\n",
    "plt.bar(r - width * 3, clip[2:].append(clip[0:2]), color = '#f6993f',\n",
    "        width = width, edgecolor = 'black',\n",
    "        label='CLIP')\n",
    "cv = df_data.loc[df_data[\"Search Iterations\"] == \"CLIP+VDVAE\"].groupby([\"Brain Area\"]).mean()[\"Variance Of Brain Correlation\"]\n",
    "plt.bar(r - width * 2, cv[2:].append(cv[0:2]), color = '#ffed4a',\n",
    "        width = width, edgecolor = 'black',\n",
    "        label='CLIP+VDVAE')\n",
    "i0 = df_data.loc[df_data[\"Search Iterations\"] == \"Iteration 0\"].groupby([\"Brain Area\"]).mean()[\"Variance Of Brain Correlation\"]\n",
    "plt.bar(r - width, i0[2:].append(i0[0:2]), color = '#38c172',\n",
    "        width = width, edgecolor = 'black',\n",
    "        label='Iteration 0')\n",
    "i1 = df_data.loc[df_data[\"Search Iterations\"] == \"Iteration 1\"].groupby([\"Brain Area\"]).mean()[\"Variance Of Brain Correlation\"]\n",
    "plt.bar(r, i1[2:].append(i1[0:2]), color = '#4dc0b5',\n",
    "        width = width, edgecolor = 'black',\n",
    "        label='Iteration 1')\n",
    "i2 = df_data.loc[df_data[\"Search Iterations\"] == \"Iteration 2\"].groupby([\"Brain Area\"]).mean()[\"Variance Of Brain Correlation\"]\n",
    "plt.bar(r + width, i2[2:].append(i2[0:2]), color = '#3490dc',\n",
    "        width = width, edgecolor = 'black',\n",
    "        label='Iteration 2')\n",
    "i3 = df_data.loc[df_data[\"Search Iterations\"] == \"Iteration 3\"].groupby([\"Brain Area\"]).mean()[\"Variance Of Brain Correlation\"]\n",
    "plt.bar(r + width * 2, i3[2:].append(i3[0:2]), color = '#6574cd',\n",
    "        width = width, edgecolor = 'black',\n",
    "        label='Iteration 3')\n",
    "i4 = df_data.loc[df_data[\"Search Iterations\"] == \"Iteration 4\"].groupby([\"Brain Area\"]).mean()[\"Variance Of Brain Correlation\"]\n",
    "plt.bar(r + width * 3, i4[2:].append(i4[0:2]), color = '#9561e2',\n",
    "        width = width, edgecolor = 'black',\n",
    "        label='Iteration 4')\n",
    "i5 = df_data.loc[df_data[\"Search Iterations\"] == \"Iteration 5\"].groupby([\"Brain Area\"]).mean()[\"Variance Of Brain Correlation\"]\n",
    "plt.bar(r + width * 4, i5[2:].append(i5[0:2]), color = '#f66d9b',\n",
    "        width = width, edgecolor = 'black',\n",
    "        label='Iteration 5')\n",
    "\n",
    "plt.xticks(x_axis, x)\n",
    "plt.xlabel(\"Brain Areas\")\n",
    "plt.ylabel(\"Variance Of Brain Correlation Across Sample Distributions\")\n",
    "plt.title(\"Convergence of Image Distribution Variance Across Iterations\")\n",
    "#plt.xlim(897)\n",
    "plt.legend(fontsize = \"x-small\")\n",
    "mpl.rcParams['figure.dpi'] = 500\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SS_vd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
