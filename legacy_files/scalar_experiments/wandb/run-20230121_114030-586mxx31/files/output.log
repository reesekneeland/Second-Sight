





train loader: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 25500/25500 [00:13<00:00, 1905.02it/s]
test loader: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2250/2250 [00:01<00:00, 1896.60it/s]
individual scalar training:   0%|                                                                                                                                                     | 0/100 [00:00<?, ?it/s]/export/raid1/home/kneel027/miniconda3/envs/ldm/lib/python3.9/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([750])) that is different to the input size (torch.Size([750, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)                                                                                                                          | 0/100 [00:00<?, ?it/s]
individual scalar training:   0%|                                                                                                                                                     | 0/100 [00:01<?, ?it/s]
epochs:   0%|                                                                                                                                                                         | 0/100 [00:01<?, ?it/s]
load_data shapes torch.Size([25500, 4627]) torch.Size([2250, 4627]) torch.Size([25500, 100]) torch.Size([2250, 100])
[1,    34] train loss: inf

epochs:   3%|████▊                                                                                                                                                            | 3/100 [00:02<01:16,  1.27it/s]
[2,    34] train loss: nan
[2] test loss: nan
loss counter: 1
[3,    34] train loss: nan
[3] test loss: nan
loss counter: 2
[4,    34] train loss: nan
[4] test loss: nan

loss counter: 3
[1,    34] train loss: inf
[1] test loss: inf
[2,    34] train loss: nan
[2] test loss: nan
loss counter: 1
[3,    34] train loss: nan
[3] test loss: nan
loss counter: 2
epochs:   3%|████▊                                                                                                                                                            | 3/100 [00:02<01:24,  1.14it/s]
epochs:   1%|█▌                                                                                                                                                               | 1/100 [00:00<01:28,  1.12it/s]
individual scalar training:   2%|██▊                                                                                                                                          | 2/100 [00:06<05:28,  3.36s/it]
Traceback (most recent call last):
  File "/export/raid1/home/kneel027/Second-Sight/scalar_experiments/scalar_LR.py", line 327, in <module>
    main()
  File "/export/raid1/home/kneel027/Second-Sight/scalar_experiments/scalar_LR.py", line 323, in main
    VM.train_c_seperate(train, test)
  File "/export/raid1/home/kneel027/Second-Sight/scalar_experiments/scalar_LR.py", line 212, in train_c_seperate
    x_data = x_data.to(self.device)
KeyboardInterrupt
[4,    34] train loss: nan
[4] test loss: nan
loss counter: 3
[1,    34] train loss: inf
[1] test loss: inf