{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"2\"\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "from PIL import Image\n",
    "sys.path.append('../src')\n",
    "from utils import *\n",
    "from matplotlib.lines import Line2D\n",
    "import matplotlib as mpl\n",
    "import math\n",
    "import matplotlib.image as mpimg\n",
    "import scipy.stats as stats\n",
    "import scipy as sp\n",
    "from scipy.stats import pearsonr,binom,linregress\n",
    "from ast import literal_eval\n",
    "import json\n",
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/export/raid1/home/kneel027/SS_release_test/Second-Sight\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ID</th>\n",
       "      <th>Sample Count</th>\n",
       "      <th>Batch Number</th>\n",
       "      <th>Search Reconstruction</th>\n",
       "      <th>Sample Indicator</th>\n",
       "      <th>Strength</th>\n",
       "      <th>Brain Correlation V1</th>\n",
       "      <th>Brain Correlation V2</th>\n",
       "      <th>Brain Correlation V3</th>\n",
       "      <th>...</th>\n",
       "      <th>SSIM</th>\n",
       "      <th>Pixel Correlation</th>\n",
       "      <th>CLIP Cosine</th>\n",
       "      <th>CLIP Two-way</th>\n",
       "      <th>AlexNet 2</th>\n",
       "      <th>AlexNet 5</th>\n",
       "      <th>AlexNet 7</th>\n",
       "      <th>Inception V3</th>\n",
       "      <th>EffNet-B</th>\n",
       "      <th>SwAV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>0.918611</td>\n",
       "      <td>0.207833</td>\n",
       "      <td>0.277128</td>\n",
       "      <td>0.380408</td>\n",
       "      <td>...</td>\n",
       "      <td>0.270016</td>\n",
       "      <td>0.303000</td>\n",
       "      <td>0.669212</td>\n",
       "      <td>[0.09348474442958832, -0.03710942715406418, -0...</td>\n",
       "      <td>[2.8248775005340576, 1.6966946125030518, 1.649...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.514281153678894, 1.2454992532730103, 0.0, 0...</td>\n",
       "      <td>[0.3043593764305115, 0.37950101494789124, 0.15...</td>\n",
       "      <td>[0.48474809527397156, 0.24456895887851715, 0.4...</td>\n",
       "      <td>[0.11222729831933975, 0.1208849772810936, 0.00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>0.908889</td>\n",
       "      <td>0.140010</td>\n",
       "      <td>0.208065</td>\n",
       "      <td>0.338118</td>\n",
       "      <td>...</td>\n",
       "      <td>0.273540</td>\n",
       "      <td>0.305071</td>\n",
       "      <td>0.667181</td>\n",
       "      <td>[0.1233302652835846, -0.21952176094055176, -0....</td>\n",
       "      <td>[1.0845296382904053, 0.9652087688446045, 0.620...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[1.1437962055206299, 0.6153535842895508, 0.0, ...</td>\n",
       "      <td>[0.509003221988678, 0.7014191746711731, 0.1648...</td>\n",
       "      <td>[1.6128770112991333, 0.002970079891383648, 0.3...</td>\n",
       "      <td>[0.05043463781476021, 0.037408556789159775, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>0.882500</td>\n",
       "      <td>0.217079</td>\n",
       "      <td>0.224783</td>\n",
       "      <td>0.339159</td>\n",
       "      <td>...</td>\n",
       "      <td>0.274539</td>\n",
       "      <td>0.315701</td>\n",
       "      <td>0.679672</td>\n",
       "      <td>[0.2795616388320923, -0.21886374056339264, -0....</td>\n",
       "      <td>[1.9781793355941772, 2.7266244888305664, 0.065...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[1.5302520990371704, 1.0001270771026611, 0.0, ...</td>\n",
       "      <td>[0.6937299966812134, 0.4997762143611908, 0.108...</td>\n",
       "      <td>[1.986473560333252, -0.08574020117521286, 0.37...</td>\n",
       "      <td>[0.03204690292477608, 0.05444856360554695, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>0.831111</td>\n",
       "      <td>0.161096</td>\n",
       "      <td>0.229807</td>\n",
       "      <td>0.361791</td>\n",
       "      <td>...</td>\n",
       "      <td>0.271564</td>\n",
       "      <td>0.312884</td>\n",
       "      <td>0.656396</td>\n",
       "      <td>[-0.2800777554512024, 0.21646563708782196, -0....</td>\n",
       "      <td>[2.8482725620269775, 1.5187815427780151, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.20134471356868744, 0.0, 0.0, 0.0, 0.4644686...</td>\n",
       "      <td>[0.6353303790092468, 0.39345991611480713, 0.03...</td>\n",
       "      <td>[1.5750030279159546, 0.15930557250976562, 0.34...</td>\n",
       "      <td>[0.03880547732114792, 0.06228385865688324, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>0.746389</td>\n",
       "      <td>0.194154</td>\n",
       "      <td>0.245889</td>\n",
       "      <td>0.381405</td>\n",
       "      <td>...</td>\n",
       "      <td>0.280842</td>\n",
       "      <td>0.317522</td>\n",
       "      <td>0.692385</td>\n",
       "      <td>[0.09306163340806961, -0.2895546555519104, -0....</td>\n",
       "      <td>[1.520384430885315, 1.4446921348571777, 1.7336...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[2.948253631591797, 1.937010645866394, 0.0, 0....</td>\n",
       "      <td>[0.19901397824287415, 0.44455385208129883, 0.1...</td>\n",
       "      <td>[1.3393651247024536, -0.17696736752986908, 0.2...</td>\n",
       "      <td>[0.036087702959775925, 0.06455022096633911, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>95</td>\n",
       "      <td>33</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>0.746389</td>\n",
       "      <td>0.152404</td>\n",
       "      <td>0.301237</td>\n",
       "      <td>0.247283</td>\n",
       "      <td>...</td>\n",
       "      <td>0.301515</td>\n",
       "      <td>0.360918</td>\n",
       "      <td>0.841591</td>\n",
       "      <td>[-0.19578483700752258, 0.6042935848236084, 0.0...</td>\n",
       "      <td>[0.0, 1.129463791847229, 5.374460697174072, 3....</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.31472063064575195, 0.25...</td>\n",
       "      <td>[0.02890937589108944, 0.33065882325172424, 0.3...</td>\n",
       "      <td>[-0.1162351444363594, -0.08513520658016205, -0...</td>\n",
       "      <td>[0.013957052491605282, 0.025152811780571938, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>96</td>\n",
       "      <td>33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.293137</td>\n",
       "      <td>0.361135</td>\n",
       "      <td>0.795420</td>\n",
       "      <td>[0.06268596649169922, 0.60926753282547, 0.3974...</td>\n",
       "      <td>[0.7709363102912903, 0.0, 2.47590970993042, 4....</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.560...</td>\n",
       "      <td>[0.0, 0.0, 1.443772315979004, 0.0, 0.696291565...</td>\n",
       "      <td>[0.032666075974702835, 0.360481858253479, 0.09...</td>\n",
       "      <td>[-0.11039827018976212, -0.14459721744060516, -...</td>\n",
       "      <td>[0.04705039784312248, 0.015114749781787395, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>97</td>\n",
       "      <td>33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.387771</td>\n",
       "      <td>0.377947</td>\n",
       "      <td>0.325607</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[-0.07153837382793427, 0.7417055368423462, -0....</td>\n",
       "      <td>[1.2915480136871338, 0.3816857635974884, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[1.7567111253738403, 0.0, 0.6362689137458801, ...</td>\n",
       "      <td>[0.20355723798274994, 0.17004206776618958, 0.5...</td>\n",
       "      <td>[0.012100922875106335, -0.18567781150341034, -...</td>\n",
       "      <td>[0.10091330111026764, 0.06564648449420929, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>98</td>\n",
       "      <td>34</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>0.918611</td>\n",
       "      <td>0.359926</td>\n",
       "      <td>0.412795</td>\n",
       "      <td>0.442231</td>\n",
       "      <td>...</td>\n",
       "      <td>0.169778</td>\n",
       "      <td>0.316890</td>\n",
       "      <td>0.525618</td>\n",
       "      <td>[0.7374528646469116, -0.34789401292800903, -0....</td>\n",
       "      <td>[10.34838581085205, 4.138106822967529, 3.73744...</td>\n",
       "      <td>[0.0, 0.0, 3.105588674545288, 3.73881435394287...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.26971521973609924, 0.5670994520187378, 0.05...</td>\n",
       "      <td>[0.036659739911556244, -0.1907937079668045, 0....</td>\n",
       "      <td>[0.010827376507222652, 0.019940972328186035, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>99</td>\n",
       "      <td>34</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>0.908889</td>\n",
       "      <td>0.366385</td>\n",
       "      <td>0.411093</td>\n",
       "      <td>0.420958</td>\n",
       "      <td>...</td>\n",
       "      <td>0.160111</td>\n",
       "      <td>0.300316</td>\n",
       "      <td>0.519650</td>\n",
       "      <td>[0.6471140384674072, -0.3863984942436218, -0.4...</td>\n",
       "      <td>[14.70162296295166, 8.486006736755371, 4.14323...</td>\n",
       "      <td>[0.0, 0.0, 3.4345672130584717, 7.3089332580566...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.11071550846099854, 0.6440396904945374, 0.07...</td>\n",
       "      <td>[-0.10584838688373566, -0.17721308767795563, -...</td>\n",
       "      <td>[0.0, 0.009160120040178299, 0.0313585884869098...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0  ID  Sample Count  Batch Number  Search Reconstruction  \\\n",
       "0            0  20           0.0           NaN                    NaN   \n",
       "1            1  20           1.0           NaN                    NaN   \n",
       "2            2  20           2.0           NaN                    NaN   \n",
       "3            3  20           3.0           NaN                    NaN   \n",
       "4            4  20           4.0           NaN                    NaN   \n",
       "..         ...  ..           ...           ...                    ...   \n",
       "95          95  33           4.0           NaN                    NaN   \n",
       "96          96  33           NaN           NaN                    NaN   \n",
       "97          97  33           NaN           NaN                    NaN   \n",
       "98          98  34           0.0           NaN                    NaN   \n",
       "99          99  34           1.0           NaN                    NaN   \n",
       "\n",
       "    Sample Indicator  Strength  Brain Correlation V1  Brain Correlation V2  \\\n",
       "0                 10  0.918611              0.207833              0.277128   \n",
       "1                 10  0.908889              0.140010              0.208065   \n",
       "2                 10  0.882500              0.217079              0.224783   \n",
       "3                 10  0.831111              0.161096              0.229807   \n",
       "4                 10  0.746389              0.194154              0.245889   \n",
       "..               ...       ...                   ...                   ...   \n",
       "95                10  0.746389              0.152404              0.301237   \n",
       "96                11       NaN                   NaN                   NaN   \n",
       "97                 0       NaN              0.387771              0.377947   \n",
       "98                10  0.918611              0.359926              0.412795   \n",
       "99                10  0.908889              0.366385              0.411093   \n",
       "\n",
       "    Brain Correlation V3  ...      SSIM  Pixel Correlation  CLIP Cosine  \\\n",
       "0               0.380408  ...  0.270016           0.303000     0.669212   \n",
       "1               0.338118  ...  0.273540           0.305071     0.667181   \n",
       "2               0.339159  ...  0.274539           0.315701     0.679672   \n",
       "3               0.361791  ...  0.271564           0.312884     0.656396   \n",
       "4               0.381405  ...  0.280842           0.317522     0.692385   \n",
       "..                   ...  ...       ...                ...          ...   \n",
       "95              0.247283  ...  0.301515           0.360918     0.841591   \n",
       "96                   NaN  ...  0.293137           0.361135     0.795420   \n",
       "97              0.325607  ...       NaN                NaN     1.000000   \n",
       "98              0.442231  ...  0.169778           0.316890     0.525618   \n",
       "99              0.420958  ...  0.160111           0.300316     0.519650   \n",
       "\n",
       "                                         CLIP Two-way  \\\n",
       "0   [0.09348474442958832, -0.03710942715406418, -0...   \n",
       "1   [0.1233302652835846, -0.21952176094055176, -0....   \n",
       "2   [0.2795616388320923, -0.21886374056339264, -0....   \n",
       "3   [-0.2800777554512024, 0.21646563708782196, -0....   \n",
       "4   [0.09306163340806961, -0.2895546555519104, -0....   \n",
       "..                                                ...   \n",
       "95  [-0.19578483700752258, 0.6042935848236084, 0.0...   \n",
       "96  [0.06268596649169922, 0.60926753282547, 0.3974...   \n",
       "97  [-0.07153837382793427, 0.7417055368423462, -0....   \n",
       "98  [0.7374528646469116, -0.34789401292800903, -0....   \n",
       "99  [0.6471140384674072, -0.3863984942436218, -0.4...   \n",
       "\n",
       "                                            AlexNet 2  \\\n",
       "0   [2.8248775005340576, 1.6966946125030518, 1.649...   \n",
       "1   [1.0845296382904053, 0.9652087688446045, 0.620...   \n",
       "2   [1.9781793355941772, 2.7266244888305664, 0.065...   \n",
       "3   [2.8482725620269775, 1.5187815427780151, 0.0, ...   \n",
       "4   [1.520384430885315, 1.4446921348571777, 1.7336...   \n",
       "..                                                ...   \n",
       "95  [0.0, 1.129463791847229, 5.374460697174072, 3....   \n",
       "96  [0.7709363102912903, 0.0, 2.47590970993042, 4....   \n",
       "97  [1.2915480136871338, 0.3816857635974884, 0.0, ...   \n",
       "98  [10.34838581085205, 4.138106822967529, 3.73744...   \n",
       "99  [14.70162296295166, 8.486006736755371, 4.14323...   \n",
       "\n",
       "                                            AlexNet 5  \\\n",
       "0   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "1   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "3   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "4   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "..                                                ...   \n",
       "95  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "96  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.560...   \n",
       "97  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "98  [0.0, 0.0, 3.105588674545288, 3.73881435394287...   \n",
       "99  [0.0, 0.0, 3.4345672130584717, 7.3089332580566...   \n",
       "\n",
       "                                            AlexNet 7  \\\n",
       "0   [0.514281153678894, 1.2454992532730103, 0.0, 0...   \n",
       "1   [1.1437962055206299, 0.6153535842895508, 0.0, ...   \n",
       "2   [1.5302520990371704, 1.0001270771026611, 0.0, ...   \n",
       "3   [0.20134471356868744, 0.0, 0.0, 0.0, 0.4644686...   \n",
       "4   [2.948253631591797, 1.937010645866394, 0.0, 0....   \n",
       "..                                                ...   \n",
       "95  [0.0, 0.0, 0.0, 0.0, 0.31472063064575195, 0.25...   \n",
       "96  [0.0, 0.0, 1.443772315979004, 0.0, 0.696291565...   \n",
       "97  [1.7567111253738403, 0.0, 0.6362689137458801, ...   \n",
       "98  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "99  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "                                         Inception V3  \\\n",
       "0   [0.3043593764305115, 0.37950101494789124, 0.15...   \n",
       "1   [0.509003221988678, 0.7014191746711731, 0.1648...   \n",
       "2   [0.6937299966812134, 0.4997762143611908, 0.108...   \n",
       "3   [0.6353303790092468, 0.39345991611480713, 0.03...   \n",
       "4   [0.19901397824287415, 0.44455385208129883, 0.1...   \n",
       "..                                                ...   \n",
       "95  [0.02890937589108944, 0.33065882325172424, 0.3...   \n",
       "96  [0.032666075974702835, 0.360481858253479, 0.09...   \n",
       "97  [0.20355723798274994, 0.17004206776618958, 0.5...   \n",
       "98  [0.26971521973609924, 0.5670994520187378, 0.05...   \n",
       "99  [0.11071550846099854, 0.6440396904945374, 0.07...   \n",
       "\n",
       "                                             EffNet-B  \\\n",
       "0   [0.48474809527397156, 0.24456895887851715, 0.4...   \n",
       "1   [1.6128770112991333, 0.002970079891383648, 0.3...   \n",
       "2   [1.986473560333252, -0.08574020117521286, 0.37...   \n",
       "3   [1.5750030279159546, 0.15930557250976562, 0.34...   \n",
       "4   [1.3393651247024536, -0.17696736752986908, 0.2...   \n",
       "..                                                ...   \n",
       "95  [-0.1162351444363594, -0.08513520658016205, -0...   \n",
       "96  [-0.11039827018976212, -0.14459721744060516, -...   \n",
       "97  [0.012100922875106335, -0.18567781150341034, -...   \n",
       "98  [0.036659739911556244, -0.1907937079668045, 0....   \n",
       "99  [-0.10584838688373566, -0.17721308767795563, -...   \n",
       "\n",
       "                                                 SwAV  \n",
       "0   [0.11222729831933975, 0.1208849772810936, 0.00...  \n",
       "1   [0.05043463781476021, 0.037408556789159775, 0....  \n",
       "2   [0.03204690292477608, 0.05444856360554695, 0.0...  \n",
       "3   [0.03880547732114792, 0.06228385865688324, 0.0...  \n",
       "4   [0.036087702959775925, 0.06455022096633911, 0....  \n",
       "..                                                ...  \n",
       "95  [0.013957052491605282, 0.025152811780571938, 0...  \n",
       "96  [0.04705039784312248, 0.015114749781787395, 0....  \n",
       "97  [0.10091330111026764, 0.06564648449420929, 0.0...  \n",
       "98  [0.010827376507222652, 0.019940972328186035, 0...  \n",
       "99  [0.0, 0.009160120040178299, 0.0313585884869098...  \n",
       "\n",
       "[100 rows x 24 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Used in CCN\n",
    "# folder   = \"SCS UC 10:250:5 0.6 Exp3 AE Fixed copy\"\n",
    "# log_path = \"/export/raid1/home/kneel027/Second-Sight/logs/\" + folder + \"/statistics_df_60.csv\"\n",
    "\n",
    "print(os.getcwd())\n",
    "# Second Sight\n",
    "subject = 1\n",
    "folder = \"dataframes\"\n",
    "# experiment = \"Brain Diffuser regen\"\n",
    "# experiment = \"Cortical Convolutions\"\n",
    "# experiment = \"Mind Diffuser\"\n",
    "# experiment = \"Tagaki\"\n",
    "# experiment = \"Final Run: SCS UC LD 6:100:4 Dual Guided clip_iter_only_brain_correlation\"\n",
    "# experiment = \"Final Run: SCS UC LD 6:100:4 Dual Guided clip_iter\"\n",
    "# experiment = \"iter_5\"\n",
    "# directory_path = \"/export/raid1/home/ojeda040/Second-Sight-Archive/reconstructions/subject\" + str(subject) + \"/\" + folder + \"/statistics_df_\" + experiment + \"_only_brain_correlation_897.csv\"\n",
    "experiment = \"mindeye_extension_v6\"\n",
    "# experiment = \"mindeye\"\n",
    "directory_path = \"output/dataframes/{}/subject{}/statistics_df_{}_114.csv\".format(experiment, subject, experiment)\n",
    "# directory_path = \"output/dataframes/{}/subject{}/statistics_df_{}_105_new_bp.csv\".format(experiment, subject, experiment)\n",
    "# pd.set_option(\"display.max_columns\", None)\n",
    "# pd.set_option(\"display.max_rows\", None)\n",
    "# pd.set_option('display.max_seq_items', None)\n",
    "df = pd.read_csv(directory_path)\n",
    "df.head(100)\n",
    "\n",
    "# experiment = \"Final Run: SCS UC LD 6:100:4 Dual Guided clip_iter_done\"\n",
    "# directory_path2 = \"/export/raid1/home/ojeda040/Second-Sight-Archive/reconstructions/subject\" + str(subject) + \"/\" + folder + \"/statistics_df_\" + experiment2 + \"_897.csv\"\n",
    "\n",
    "# df2 = pd.read_csv(directory_path2)\n",
    "\n",
    "#   0 --> Ground Truth\n",
    "#   1 --> VDVAE Distribution        (Decoded Distribution)\n",
    "#   2 --> Clip Distrubituon         (Decoded CLIP Only)\n",
    "#   3 --> Clip Distrubituon + VDVAE (Decoded CLIP + VDVAE)\n",
    "#   4 --> iter_0\n",
    "#   5 --> iter_1\n",
    "#   6 --> iter_2\n",
    "#   7 --> iter_3\n",
    "#   8 --> iter_4\n",
    "#   9 --> iter_5\n",
    "#  10 --> Search Reconstruction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "creating lists: 798it [00:28, 28.17it/s]\n"
     ]
    }
   ],
   "source": [
    "# Create CNN metric columns into lists (Only run if computing CNN Metrics)\n",
    "\n",
    "def column_string_to_list(df):\n",
    "    df_new = df\n",
    "    \n",
    "    for index, row in tqdm(df.iterrows(), \"creating lists\"):\n",
    "        \n",
    "        df_new.at[index, 'CLIP Two-way']    = json.loads(row['CLIP Two-way'])\n",
    "        df_new.at[index, 'AlexNet 2']       = json.loads(row['AlexNet 2'])\n",
    "        df_new.at[index, 'AlexNet 5']       = json.loads(row['AlexNet 5'])\n",
    "        df_new.at[index, 'AlexNet 7']       = json.loads(row['AlexNet 7'])\n",
    "        df_new.at[index, 'Inception V3']    = json.loads(row['Inception V3'])\n",
    "        df_new.at[index, 'EffNet-B']        = json.loads(row['EffNet-B'])\n",
    "        df_new.at[index, 'SwAV']            = json.loads(row['SwAV'])\n",
    "        \n",
    "    return df_new\n",
    "\n",
    "new_df = column_string_to_list(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------ SSIM -----------------------------------------------------------------\n",
      "SSIM:  0.2876001861087719\n",
      "Confidence Interval SSIM:  0.01186685323913888\n",
      "------------------------------------------------ Pixel Correlation -----------------------------------------------------------------\n",
      "Pixel Correlation:  0.29248264839105265\n",
      "Confidence Interval Pixel Correlation:  0.016620952361593846\n",
      "------------------------------------------------ CLIP Cosine -----------------------------------------------------------------\n",
      "CLIP Cosine:  0.7034787956570174\n",
      "Confidence Interval CLIP Cosine:  0.00897803979129747\n",
      "------------------------------------------------ CLIP Two-way -----------------------------------------------------------------\n",
      "CLIP Two-way:  0.932852041608446\n",
      "------------------------------------------------ AlexNet 2 -----------------------------------------------------------------\n",
      "AlexNet 2:  0.9660611706256793\n",
      "------------------------------------------------ AlexNet 5 -----------------------------------------------------------------\n",
      "AlexNet 5:  0.9787765874864153\n",
      "------------------------------------------------ AlexNet 7 -----------------------------------------------------------------\n",
      "AlexNet 7:  0.9761372457692904\n",
      "------------------------------------------------ Inception V3 -----------------------------------------------------------------\n",
      "Inception V3:  0.9209284272628473\n",
      "------------------------------------------------ EffNet-B -----------------------------------------------------------------\n",
      "EffNet-B:  0.6793957815643934\n",
      "------------------------------------------------ SwAV -----------------------------------------------------------------\n",
      "SwAV:  0.35544518172772993\n",
      "0.9246235056668219\n"
     ]
    }
   ],
   "source": [
    "# Statistical Analysis Second Sight\n",
    "\n",
    "# Input: Dataframe containing the samples one type of image\n",
    "def create_cnn_numpy_array(df):\n",
    "    cnn_dict = {}\n",
    "    df = df.reset_index()\n",
    "    \n",
    "    alexnet_2       = []\n",
    "    alexnet_5       = []\n",
    "    alexnet_7       = []\n",
    "    clip_two_way    = []\n",
    "    inception_v3    = []\n",
    "    effnet_b        = []\n",
    "    swav            = []\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        \n",
    "        alexnet_2.append(row['AlexNet 2'])\n",
    "        alexnet_5.append(np.array(row['AlexNet 5']))\n",
    "        alexnet_7.append(np.array(row['AlexNet 7']))\n",
    "        clip_two_way.append(np.array(row['CLIP Two-way']))\n",
    "        inception_v3.append(np.array(row['Inception V3']))\n",
    "        effnet_b.append(np.array(row['EffNet-B']))\n",
    "        swav.append(np.array(row['SwAV']))\n",
    "    \n",
    "    cnn_dict['AlexNet 2']      = np.concatenate([alexnet_2])\n",
    "    cnn_dict['AlexNet 5']      = np.concatenate([alexnet_5])\n",
    "    cnn_dict['AlexNet 7']      = np.concatenate([alexnet_7])\n",
    "    cnn_dict['CLIP Two-way']   = np.concatenate([clip_two_way])\n",
    "    cnn_dict['Inception V3']   = np.concatenate([inception_v3])\n",
    "    cnn_dict['EffNet-B']       = np.concatenate([effnet_b])\n",
    "    cnn_dict['SwAV']           = np.concatenate([swav])\n",
    "    # print(cnn_dict['AlexNet 2'])\n",
    "    return cnn_dict\n",
    "\n",
    "def pairwise_corr_all(ground_truth, predictions):\n",
    "    r = np.corrcoef(ground_truth, predictions)      #cosine_similarity(ground_truth, predictions)#\n",
    "    r = r[:len(ground_truth), len(ground_truth):]   # rows: groundtruth, columns: predicitons\n",
    "    \n",
    "    # congruent pairs are on diagonal\n",
    "    congruents = np.diag(r)\n",
    "    \n",
    "    # for each column (predicition) we should count the number of rows (groundtruth) \n",
    "    # that the value is lower than the congruent (e.g. success).\n",
    "    success = r < congruents\n",
    "    success_cnt = np.sum(success, 0)\n",
    "    \n",
    "    # note: diagonal of 'success' is always zero so we can discard it. That's why we divide by len-1\n",
    "    perf = np.mean(success_cnt) / (len(ground_truth)-1)\n",
    "    p = 1 - binom.cdf(perf*len(ground_truth)*(len(ground_truth)-1), len(ground_truth)*(len(ground_truth)-1), 0.5)\n",
    "    \n",
    "    return perf, p\n",
    "\n",
    "def compute_cnn_metrics(cnn_metrics_ground_truth, cnn_metrics_reconstructions):\n",
    "    distance_fn = sp.spatial.distance.correlation\n",
    "    pairwise_corrs = []\n",
    "    cnn_metrics = {}\n",
    "    # print(cnn_metrics_reconstructions)\n",
    "    for net_name, predictions_np in cnn_metrics_reconstructions.items():\n",
    "        \n",
    "        gt_feat = cnn_metrics_ground_truth[net_name]\n",
    "        \n",
    "        eval_feat = predictions_np\n",
    "        num_test = predictions_np.shape[0]\n",
    "        # print(net_name, predictions_np.shape)\n",
    "        if net_name == 'EffNet-B' or net_name == 'SwAV':\n",
    "            cnn_metrics[net_name] = np.array([distance_fn(gt_feat[i],eval_feat[i]) for i in range(num_test)]).mean()\n",
    "            \n",
    "        else:\n",
    "            cnn_metrics[net_name] = pairwise_corr_all(gt_feat[:num_test],eval_feat[:num_test])[0]\n",
    "            \n",
    "    return cnn_metrics \n",
    "\n",
    "df_final_samples    = new_df.loc[(new_df['Sample Indicator'] == 10)]\n",
    "df_ground_truth     = new_df.loc[(new_df['Sample Indicator'] == 0)]\n",
    "df_final_samples_0  = df_final_samples.loc[(df_final_samples['Sample Count'] == 0)]\n",
    "df_final_samples_1  = df_final_samples.loc[(df_final_samples['Sample Count'] == 1)]\n",
    "df_final_samples_2  = df_final_samples.loc[(df_final_samples['Sample Count'] == 2)]\n",
    "df_final_samples_3  = df_final_samples.loc[(df_final_samples['Sample Count'] == 3)]\n",
    "df_final_samples_4  = df_final_samples.loc[(df_final_samples['Sample Count'] == 4)]\n",
    "\n",
    "\n",
    "cnn_metrics_0 = compute_cnn_metrics(create_cnn_numpy_array(df_ground_truth), create_cnn_numpy_array(df_final_samples_0))\n",
    "cnn_metrics_1 = compute_cnn_metrics(create_cnn_numpy_array(df_ground_truth), create_cnn_numpy_array(df_final_samples_1))\n",
    "cnn_metrics_2 = compute_cnn_metrics(create_cnn_numpy_array(df_ground_truth), create_cnn_numpy_array(df_final_samples_2))\n",
    "cnn_metrics_3 = compute_cnn_metrics(create_cnn_numpy_array(df_ground_truth), create_cnn_numpy_array(df_final_samples_3))\n",
    "cnn_metrics_4 = compute_cnn_metrics(create_cnn_numpy_array(df_ground_truth), create_cnn_numpy_array(df_final_samples_4))\n",
    "\n",
    "print(\"------------------------------------------------ SSIM -----------------------------------------------------------------\")\n",
    "\n",
    "print(\"SSIM: \", df_final_samples['SSIM'].mean())\n",
    "\n",
    "print(\"Confidence Interval SSIM: \", ((df_final_samples['SSIM'].std() * 1.96) / math.sqrt(len(df_final_samples.index))))\n",
    "\n",
    "print(\"------------------------------------------------ Pixel Correlation -----------------------------------------------------------------\")\n",
    "\n",
    "print(\"Pixel Correlation: \", df_final_samples['Pixel Correlation'].mean())\n",
    "\n",
    "print(\"Confidence Interval Pixel Correlation: \", ((df_final_samples['Pixel Correlation'].std() * 1.96) / math.sqrt(len(df_final_samples.index))))\n",
    "\n",
    "print(\"------------------------------------------------ CLIP Cosine -----------------------------------------------------------------\")\n",
    "\n",
    "print(\"CLIP Cosine: \", df_final_samples['CLIP Cosine'].mean())\n",
    "\n",
    "print(\"Confidence Interval CLIP Cosine: \", ((df_final_samples['CLIP Cosine'].std() * 1.96) / math.sqrt(len(df_final_samples.index))))\n",
    "\n",
    "print(\"------------------------------------------------ CLIP Two-way -----------------------------------------------------------------\")\n",
    "\n",
    "print(\"CLIP Two-way: \", ((cnn_metrics_0['CLIP Two-way'] + cnn_metrics_1['CLIP Two-way'] + cnn_metrics_2['CLIP Two-way'] + cnn_metrics_3['CLIP Two-way'] + cnn_metrics_4['CLIP Two-way']) / 5))\n",
    "\n",
    "print(\"------------------------------------------------ AlexNet 2 -----------------------------------------------------------------\")\n",
    "\n",
    "print(\"AlexNet 2: \", ((cnn_metrics_0['AlexNet 2'] + cnn_metrics_1['AlexNet 2'] + cnn_metrics_2['AlexNet 2'] + cnn_metrics_3['AlexNet 2'] + cnn_metrics_4['AlexNet 2']) / 5))\n",
    "\n",
    "print(\"------------------------------------------------ AlexNet 5 -----------------------------------------------------------------\")\n",
    "\n",
    "print(\"AlexNet 5: \", ((cnn_metrics_0['AlexNet 5'] + cnn_metrics_1['AlexNet 5'] + cnn_metrics_2['AlexNet 5'] + cnn_metrics_3['AlexNet 5'] + cnn_metrics_4['AlexNet 5']) / 5))\n",
    "\n",
    "print(\"------------------------------------------------ AlexNet 7 -----------------------------------------------------------------\")\n",
    "\n",
    "print(\"AlexNet 7: \", ((cnn_metrics_0['AlexNet 7'] + cnn_metrics_1['AlexNet 7'] + cnn_metrics_2['AlexNet 7'] + cnn_metrics_3['AlexNet 7'] + cnn_metrics_4['AlexNet 7']) / 5))\n",
    "\n",
    "print(\"------------------------------------------------ Inception V3 -----------------------------------------------------------------\")\n",
    "\n",
    "print(\"Inception V3: \", ((cnn_metrics_0['Inception V3'] + cnn_metrics_1['Inception V3'] + cnn_metrics_2['Inception V3'] + cnn_metrics_3['Inception V3'] + cnn_metrics_4['Inception V3']) / 5))\n",
    "\n",
    "print(\"------------------------------------------------ EffNet-B -----------------------------------------------------------------\")\n",
    "\n",
    "print(\"EffNet-B: \", ((cnn_metrics_0['EffNet-B'] + cnn_metrics_1['EffNet-B'] + cnn_metrics_2['EffNet-B'] + cnn_metrics_3['EffNet-B'] + cnn_metrics_4['EffNet-B']) / 5))\n",
    "\n",
    "print(\"------------------------------------------------ SwAV -----------------------------------------------------------------\")\n",
    "\n",
    "print(\"SwAV: \", ((cnn_metrics_0['SwAV'] + cnn_metrics_1['SwAV'] + cnn_metrics_2['SwAV'] + cnn_metrics_3['SwAV'] + cnn_metrics_4['SwAV']) / 5))\n",
    "\n",
    "print(cnn_metrics_0['Inception V3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = create_cnn_numpy_array(df_final_samples_2)\n",
    "gt = create_cnn_numpy_array(df_ground_truth)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(897,) (897,)\n"
     ]
    }
   ],
   "source": [
    "cnn = create_cnn_numpy_array(df_final_samples_0)\n",
    "gt = create_cnn_numpy_array(df_ground_truth)\n",
    "distance_fn = sp.spatial.distance.correlation\n",
    "\n",
    "effnet = np.array([distance_fn(gt['EffNet-B'][i],cnn['EffNet-B'][i]) for i in range(897)])\n",
    "swav = np.array([distance_fn(gt['SwAV'][i],cnn['SwAV'][i]) for i in range(897)])\n",
    "print(effnet.shape, swav.shape)\n",
    "# np.save(\"/home/naxos2-raid25/ojeda040/local/ojeda040/Second-Sight-Archive/reconstructions/subject1/dataframes/effnet_sample_0.npy\", effnet)\n",
    "# np.save(\"/home/naxos2-raid25/ojeda040/local/ojeda040/Second-Sight-Archive/reconstructions/subject1/dataframes/swav_sample_0.npy\", swav)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (114,570) (114,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/naxos2-raid25/kneel027/home/kneel027/SS_release_test/Second-Sight/src/prepare_figures.ipynb Cell 7\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bhypatia.cmrr.umn.edu/home/naxos2-raid25/kneel027/home/kneel027/SS_release_test/Second-Sight/src/prepare_figures.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m df_final_samples    \u001b[39m=\u001b[39m new_df\u001b[39m.\u001b[39mloc[(new_df[\u001b[39m'\u001b[39m\u001b[39mSample Indicator\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m10\u001b[39m)]\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bhypatia.cmrr.umn.edu/home/naxos2-raid25/kneel027/home/kneel027/SS_release_test/Second-Sight/src/prepare_figures.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m df_ground_truth     \u001b[39m=\u001b[39m new_df\u001b[39m.\u001b[39mloc[(new_df[\u001b[39m'\u001b[39m\u001b[39mSample Indicator\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m)]\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bhypatia.cmrr.umn.edu/home/naxos2-raid25/kneel027/home/kneel027/SS_release_test/Second-Sight/src/prepare_figures.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m cnn_metrics_0 \u001b[39m=\u001b[39m compute_cnn_metrics(create_cnn_numpy_array(df_ground_truth), create_cnn_numpy_array(df_final_samples))\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bhypatia.cmrr.umn.edu/home/naxos2-raid25/kneel027/home/kneel027/SS_release_test/Second-Sight/src/prepare_figures.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m------------------------------------------------ SSIM -----------------------------------------------------------------\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bhypatia.cmrr.umn.edu/home/naxos2-raid25/kneel027/home/kneel027/SS_release_test/Second-Sight/src/prepare_figures.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mSSIM: \u001b[39m\u001b[39m\"\u001b[39m, df_final_samples[\u001b[39m'\u001b[39m\u001b[39mSSIM\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mmean())\n",
      "\u001b[1;32m/home/naxos2-raid25/kneel027/home/kneel027/SS_release_test/Second-Sight/src/prepare_figures.ipynb Cell 7\u001b[0m line \u001b[0;36m7\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bhypatia.cmrr.umn.edu/home/naxos2-raid25/kneel027/home/kneel027/SS_release_test/Second-Sight/src/prepare_figures.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=66'>67</a>\u001b[0m         cnn_metrics[net_name] \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([distance_fn(gt_feat[i],eval_feat[i]) \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_test)])\u001b[39m.\u001b[39mmean()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bhypatia.cmrr.umn.edu/home/naxos2-raid25/kneel027/home/kneel027/SS_release_test/Second-Sight/src/prepare_figures.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=68'>69</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bhypatia.cmrr.umn.edu/home/naxos2-raid25/kneel027/home/kneel027/SS_release_test/Second-Sight/src/prepare_figures.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=69'>70</a>\u001b[0m         cnn_metrics[net_name] \u001b[39m=\u001b[39m pairwise_corr_all(gt_feat[:num_test],eval_feat[:num_test])[\u001b[39m0\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bhypatia.cmrr.umn.edu/home/naxos2-raid25/kneel027/home/kneel027/SS_release_test/Second-Sight/src/prepare_figures.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=71'>72</a>\u001b[0m \u001b[39mreturn\u001b[39;00m cnn_metrics\n",
      "\u001b[1;32m/home/naxos2-raid25/kneel027/home/kneel027/SS_release_test/Second-Sight/src/prepare_figures.ipynb Cell 7\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bhypatia.cmrr.umn.edu/home/naxos2-raid25/kneel027/home/kneel027/SS_release_test/Second-Sight/src/prepare_figures.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=40'>41</a>\u001b[0m congruents \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mdiag(r)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bhypatia.cmrr.umn.edu/home/naxos2-raid25/kneel027/home/kneel027/SS_release_test/Second-Sight/src/prepare_figures.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=42'>43</a>\u001b[0m \u001b[39m# for each column (predicition) we should count the number of rows (groundtruth) \u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bhypatia.cmrr.umn.edu/home/naxos2-raid25/kneel027/home/kneel027/SS_release_test/Second-Sight/src/prepare_figures.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=43'>44</a>\u001b[0m \u001b[39m# that the value is lower than the congruent (e.g. success).\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bhypatia.cmrr.umn.edu/home/naxos2-raid25/kneel027/home/kneel027/SS_release_test/Second-Sight/src/prepare_figures.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=44'>45</a>\u001b[0m success \u001b[39m=\u001b[39m r \u001b[39m<\u001b[39;49m congruents\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bhypatia.cmrr.umn.edu/home/naxos2-raid25/kneel027/home/kneel027/SS_release_test/Second-Sight/src/prepare_figures.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=45'>46</a>\u001b[0m success_cnt \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39msum(success, \u001b[39m0\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bhypatia.cmrr.umn.edu/home/naxos2-raid25/kneel027/home/kneel027/SS_release_test/Second-Sight/src/prepare_figures.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=47'>48</a>\u001b[0m \u001b[39m# note: diagonal of 'success' is always zero so we can discard it. That's why we divide by len-1\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (114,570) (114,) "
     ]
    }
   ],
   "source": [
    "df_final_samples    = new_df.loc[(new_df['Sample Indicator'] == 10)]\n",
    "df_ground_truth     = new_df.loc[(new_df['Sample Indicator'] == 0)]\n",
    "\n",
    "cnn_metrics_0 = compute_cnn_metrics(create_cnn_numpy_array(df_ground_truth), create_cnn_numpy_array(df_final_samples))\n",
    "\n",
    "print(\"------------------------------------------------ SSIM -----------------------------------------------------------------\")\n",
    "\n",
    "print(\"SSIM: \", df_final_samples['SSIM'].mean())\n",
    "\n",
    "print(\"Confidence Interval SSIM: \", ((df_final_samples['SSIM'].std() * 1.96) / math.sqrt(len(df_final_samples.index))))\n",
    "\n",
    "print(\"------------------------------------------------ Pixel Correlation ----------------------------------------------------\")\n",
    "\n",
    "print(\"Pixel Correlation: \", df_final_samples['Pixel Correlation'].mean())\n",
    "\n",
    "print(\"Confidence Interval Pixel Correlation: \", ((df_final_samples['Pixel Correlation'].std() * 1.96) / math.sqrt(len(df_final_samples.index))))\n",
    "\n",
    "print(\"------------------------------------------------ CLIP Cosine ----------------------------------------------------------\")\n",
    "\n",
    "print(\"CLIP Cosine: \", df_final_samples['CLIP Cosine'].mean())\n",
    "\n",
    "print(\"Confidence Interval CLIP Cosine: \", ((df_final_samples['CLIP Cosine'].std() * 1.96) / math.sqrt(len(df_final_samples.index))))\n",
    "\n",
    "print(\"------------------------------------------------ CLIP Two-way ---------------------------------------------------------\")\n",
    "\n",
    "print(\"CLIP Two-way: \", ((cnn_metrics_0['CLIP Two-way'])))\n",
    "\n",
    "print(\"------------------------------------------------ AlexNet 2 ------------------------------------------------------------\")\n",
    "\n",
    "print(\"AlexNet 2: \", ((cnn_metrics_0['AlexNet 2'])))\n",
    "\n",
    "print(\"------------------------------------------------ AlexNet 5 ------------------------------------------------------------\")\n",
    "\n",
    "print(\"AlexNet 5: \", ((cnn_metrics_0['AlexNet 5'])))\n",
    "\n",
    "print(\"------------------------------------------------ AlexNet 7 ------------------------------------------------------------\")\n",
    "\n",
    "print(\"AlexNet 7: \", ((cnn_metrics_0['AlexNet 7'])))\n",
    "\n",
    "print(\"------------------------------------------------ Inception V3 ---------------------------------------------------------\")\n",
    "\n",
    "print(\"Inception V3: \", ((cnn_metrics_0['Inception V3'])))\n",
    "\n",
    "print(\"------------------------------------------------ EffNet-B -------------------------------------------------------------\")\n",
    "\n",
    "print(\"EffNet-B: \", ((cnn_metrics_0['EffNet-B'])))\n",
    "\n",
    "print(\"------------------------------------------------ SwAV -----------------------------------------------------------------\")\n",
    "\n",
    "print(\"SwAV: \", ((cnn_metrics_0['SwAV'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------ Brain Correlation V1 -----------------------------------------------------------------\n",
      "Brain Correlation V1:  0.38617785627982454\n",
      "------------------------------------------------ Brain Correlation V2 -----------------------------------------------------------------\n",
      "Brain Correlation V2:  0.36045059577368427\n",
      "------------------------------------------------ Brain Correlation V3 -----------------------------------------------------------------\n",
      "Brain Correlation V3:  0.3603544754929824\n",
      "------------------------------------------------ Brain Correlation V4 -----------------------------------------------------------------\n",
      "Brain Correlation V4:  0.33241757830614044\n",
      "------------------------------------------------ Brain Correlation Early Visual -------------------------------------------------------\n",
      "Brain Correlation Early Visual:  0.37188677559122807\n",
      "------------------------------------------------ Brain Correlation Higher Visual -------------------------------------------------------\n",
      "Brain Correlation Higher Visual:  0.36815167353596495\n",
      "------------------------------------------------ Brain Correlation NSD General ---------------------------------------------------------\n",
      "Brain Correlation NSD General:  0.3835926482\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ID</th>\n",
       "      <th>Sample Count</th>\n",
       "      <th>Batch Number</th>\n",
       "      <th>Search Reconstruction</th>\n",
       "      <th>Sample Indicator</th>\n",
       "      <th>Strength</th>\n",
       "      <th>Brain Correlation V1</th>\n",
       "      <th>Brain Correlation V2</th>\n",
       "      <th>Brain Correlation V3</th>\n",
       "      <th>...</th>\n",
       "      <th>SSIM</th>\n",
       "      <th>Pixel Correlation</th>\n",
       "      <th>CLIP Cosine</th>\n",
       "      <th>CLIP Two-way</th>\n",
       "      <th>AlexNet 2</th>\n",
       "      <th>AlexNet 5</th>\n",
       "      <th>AlexNet 7</th>\n",
       "      <th>Inception V3</th>\n",
       "      <th>EffNet-B</th>\n",
       "      <th>SwAV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>282</td>\n",
       "      <td>120</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.211541</td>\n",
       "      <td>0.255005</td>\n",
       "      <td>0.290492</td>\n",
       "      <td>...</td>\n",
       "      <td>0.231562</td>\n",
       "      <td>0.114387</td>\n",
       "      <td>0.682649</td>\n",
       "      <td>[0.8601428270339966, 0.4621444642543793, 0.068...</td>\n",
       "      <td>[4.2238688468933105, 0.25726407766342163, 0.0,...</td>\n",
       "      <td>[0.0, 0.0, 1.757684588432312, 0.14867722988128...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.48669248819351196, 0.0,...</td>\n",
       "      <td>[0.34756341576576233, 0.05925580486655235, 0.3...</td>\n",
       "      <td>[-0.08691135793924332, -0.2146623730659485, 0....</td>\n",
       "      <td>[0.0, 0.052054762840270996, 0.0, 0.19318062067...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>285</td>\n",
       "      <td>121</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.191981</td>\n",
       "      <td>0.232085</td>\n",
       "      <td>0.216655</td>\n",
       "      <td>...</td>\n",
       "      <td>0.401904</td>\n",
       "      <td>0.522101</td>\n",
       "      <td>0.828439</td>\n",
       "      <td>[-0.035639554262161255, 0.9489609599113464, -0...</td>\n",
       "      <td>[0.0, 0.0, 5.173697471618652, 0.44474488496780...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.3698512613773346, 0.0, ...</td>\n",
       "      <td>[0.7240560054779053, 0.35163170099258423, 0.48...</td>\n",
       "      <td>[-0.08289328962564468, -0.11956726759672165, -...</td>\n",
       "      <td>[0.07443360984325409, 0.0, 0.0, 0.0, 0.0791304...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>288</td>\n",
       "      <td>122</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.277557</td>\n",
       "      <td>0.117816</td>\n",
       "      <td>0.080873</td>\n",
       "      <td>...</td>\n",
       "      <td>0.352593</td>\n",
       "      <td>0.598277</td>\n",
       "      <td>0.899088</td>\n",
       "      <td>[0.06282173097133636, 1.1641817092895508, 0.18...</td>\n",
       "      <td>[3.4371659755706787, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 1.2006441354751587, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[1.4704668521881104, 0.25028887391090393, 0.14...</td>\n",
       "      <td>[-0.11759889125823975, -0.049544740468263626, ...</td>\n",
       "      <td>[0.0, 0.022066811099648476, 0.0087081892415881...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>291</td>\n",
       "      <td>124</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.033092</td>\n",
       "      <td>0.056477</td>\n",
       "      <td>0.123699</td>\n",
       "      <td>...</td>\n",
       "      <td>0.381738</td>\n",
       "      <td>0.588193</td>\n",
       "      <td>0.833040</td>\n",
       "      <td>[0.20614571869373322, 1.1074206829071045, 0.73...</td>\n",
       "      <td>[5.654211044311523, 3.1328423023223877, 0.0854...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.36313506960868835, 0.21247270703315735, 0.3...</td>\n",
       "      <td>[-0.0610351637005806, -0.08393349498510361, -0...</td>\n",
       "      <td>[0.05101518705487251, 0.0, 0.0, 0.0, 0.1382670...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>294</td>\n",
       "      <td>125</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.292899</td>\n",
       "      <td>0.218387</td>\n",
       "      <td>0.303519</td>\n",
       "      <td>...</td>\n",
       "      <td>0.032481</td>\n",
       "      <td>0.376428</td>\n",
       "      <td>0.768817</td>\n",
       "      <td>[0.9571543335914612, 0.9463894367218018, -0.13...</td>\n",
       "      <td>[15.472354888916016, 25.573116302490234, 9.885...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[1.0989038944244385, 0.015583536587655544, 0.2...</td>\n",
       "      <td>[-0.022317521274089813, -0.20899473130702972, ...</td>\n",
       "      <td>[0.01967310719192028, 0.04778313636779785, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>297</td>\n",
       "      <td>126</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.527363</td>\n",
       "      <td>0.445815</td>\n",
       "      <td>0.484083</td>\n",
       "      <td>...</td>\n",
       "      <td>0.336756</td>\n",
       "      <td>0.190783</td>\n",
       "      <td>0.821505</td>\n",
       "      <td>[0.616702675819397, -0.4651188254356384, -0.71...</td>\n",
       "      <td>[6.559354305267334, 0.7117111682891846, 0.0851...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 2.296313762664795, 0...</td>\n",
       "      <td>[0.7964139580726624, 0.025477230548858643, 0.5...</td>\n",
       "      <td>[-0.06951962411403656, 0.7926462888717651, -0....</td>\n",
       "      <td>[0.0, 0.01535372156649828, 0.04593706503510475...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>300</td>\n",
       "      <td>127</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.153832</td>\n",
       "      <td>0.071102</td>\n",
       "      <td>-0.037902</td>\n",
       "      <td>...</td>\n",
       "      <td>0.057295</td>\n",
       "      <td>-0.005386</td>\n",
       "      <td>0.667361</td>\n",
       "      <td>[1.0949320793151855, 0.866348385810852, 0.2934...</td>\n",
       "      <td>[2.5267417430877686, 1.3142582178115845, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.21564216...</td>\n",
       "      <td>[3.3017823696136475, 0.07054632157087326, 1.38...</td>\n",
       "      <td>[-0.1269661784172058, -0.16990086436271667, -0...</td>\n",
       "      <td>[0.19225183129310608, 0.05766328051686287, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>303</td>\n",
       "      <td>128</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.622453</td>\n",
       "      <td>0.563634</td>\n",
       "      <td>0.470665</td>\n",
       "      <td>...</td>\n",
       "      <td>0.583809</td>\n",
       "      <td>0.304057</td>\n",
       "      <td>0.623612</td>\n",
       "      <td>[0.618984043598175, -0.5981809496879578, -0.49...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[3.659572124481201, 0.0, 0.0, 0.0, 0.550447344...</td>\n",
       "      <td>[0.2670031189918518, 0.4547840654850006, 0.245...</td>\n",
       "      <td>[-0.08394108712673187, -0.10422228276729584, -...</td>\n",
       "      <td>[0.1629466414451599, 0.013671763241291046, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>306</td>\n",
       "      <td>129</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.459814</td>\n",
       "      <td>0.513667</td>\n",
       "      <td>0.458088</td>\n",
       "      <td>...</td>\n",
       "      <td>0.178612</td>\n",
       "      <td>0.632651</td>\n",
       "      <td>0.871673</td>\n",
       "      <td>[0.03946657478809357, 0.8725806474685669, 0.33...</td>\n",
       "      <td>[1.5147377252578735, 5.193026065826416, 0.8120...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[2.0597407817840576, 0.2124146968126297, 0.121...</td>\n",
       "      <td>[-0.04973549768328667, 0.0015072335954755545, ...</td>\n",
       "      <td>[0.0009561810293234885, 0.09368328750133514, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>309</td>\n",
       "      <td>130</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.498804</td>\n",
       "      <td>0.541754</td>\n",
       "      <td>0.611516</td>\n",
       "      <td>...</td>\n",
       "      <td>0.193343</td>\n",
       "      <td>0.274551</td>\n",
       "      <td>0.562545</td>\n",
       "      <td>[0.2784273624420166, 0.23733465373516083, 1.01...</td>\n",
       "      <td>[2.321463108062744, 1.7710672616958618, 1.2338...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.045937661081552505, 0.4585883915424347, 0.1...</td>\n",
       "      <td>[-0.0634067952632904, -0.13620252907276154, -0...</td>\n",
       "      <td>[0.10486996918916702, 0.014845172874629498, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>312</td>\n",
       "      <td>131</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.370552</td>\n",
       "      <td>0.270243</td>\n",
       "      <td>0.226068</td>\n",
       "      <td>...</td>\n",
       "      <td>0.278322</td>\n",
       "      <td>0.578974</td>\n",
       "      <td>0.577503</td>\n",
       "      <td>[-0.04233205318450928, 0.5397247672080994, -0....</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3894717097282...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.2853809893131256, 0.2863912284374237, 0.185...</td>\n",
       "      <td>[0.6702555418014526, 0.29507172107696533, 0.09...</td>\n",
       "      <td>[0.043866802006959915, 0.48325690627098083, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>315</td>\n",
       "      <td>132</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.440162</td>\n",
       "      <td>0.480298</td>\n",
       "      <td>0.579302</td>\n",
       "      <td>...</td>\n",
       "      <td>0.220226</td>\n",
       "      <td>0.545394</td>\n",
       "      <td>0.770331</td>\n",
       "      <td>[0.249669149518013, 0.1094132661819458, -0.593...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 1.4636844396591187, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.05344991385936737, 0.29405227303504944, 0.1...</td>\n",
       "      <td>[0.0082815857604146, -0.11184491962194443, -0....</td>\n",
       "      <td>[0.0, 0.0, 0.09911888092756271, 0.0, 0.0661689...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>318</td>\n",
       "      <td>133</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.193299</td>\n",
       "      <td>0.067126</td>\n",
       "      <td>0.167046</td>\n",
       "      <td>...</td>\n",
       "      <td>0.058795</td>\n",
       "      <td>0.177501</td>\n",
       "      <td>0.871674</td>\n",
       "      <td>[-0.5869687795639038, 0.6962552070617676, 0.45...</td>\n",
       "      <td>[5.627917766571045, 0.8574362993240356, 0.0, 7...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 3.1571764945983887, 0.0, 0.0, ...</td>\n",
       "      <td>[0.12484695762395859, 0.22987236082553864, 0.0...</td>\n",
       "      <td>[0.24519608914852142, -0.020434748381376266, 0...</td>\n",
       "      <td>[0.05119730532169342, 0.000348422589013353, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>321</td>\n",
       "      <td>134</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.631385</td>\n",
       "      <td>0.512296</td>\n",
       "      <td>0.511945</td>\n",
       "      <td>...</td>\n",
       "      <td>0.514703</td>\n",
       "      <td>0.504294</td>\n",
       "      <td>0.672576</td>\n",
       "      <td>[0.10049229860305786, 0.07620100677013397, 0.2...</td>\n",
       "      <td>[1.0180931091308594, 0.3849928379058838, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.987...</td>\n",
       "      <td>[0.0, 1.5796780586242676, 0.1306583285331726, ...</td>\n",
       "      <td>[0.8256660103797913, 0.7809292674064636, 0.744...</td>\n",
       "      <td>[-0.09502176195383072, 0.2288413643836975, -0....</td>\n",
       "      <td>[0.07734528928995132, 0.020817482843995094, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>324</td>\n",
       "      <td>135</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.195355</td>\n",
       "      <td>0.099527</td>\n",
       "      <td>0.114489</td>\n",
       "      <td>...</td>\n",
       "      <td>0.357655</td>\n",
       "      <td>0.464276</td>\n",
       "      <td>0.748389</td>\n",
       "      <td>[0.7994589805603027, 0.07811986654996872, -0.2...</td>\n",
       "      <td>[4.0040998458862305, 2.701425790786743, 0.0439...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[1.0952032804489136, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.28174889087677, 0.41948074102401733, 0.1731...</td>\n",
       "      <td>[1.3254244327545166, 0.012831226922571659, -0....</td>\n",
       "      <td>[0.0, 0.02665386162698269, 0.01077952049672603...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>327</td>\n",
       "      <td>136</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.373903</td>\n",
       "      <td>0.372653</td>\n",
       "      <td>0.380639</td>\n",
       "      <td>...</td>\n",
       "      <td>0.274660</td>\n",
       "      <td>0.394617</td>\n",
       "      <td>0.592142</td>\n",
       "      <td>[1.2743653059005737, -1.4894688129425049, -0.1...</td>\n",
       "      <td>[1.2974324226379395, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.9262102842330933, 0.0, 0.0, ...</td>\n",
       "      <td>[1.1879547834396362, 0.2042853832244873, 0.180...</td>\n",
       "      <td>[0.5392148494720459, 1.6687936782836914, -0.11...</td>\n",
       "      <td>[0.07210078835487366, 0.20833976566791534, 0.2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>330</td>\n",
       "      <td>137</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.509267</td>\n",
       "      <td>0.359658</td>\n",
       "      <td>0.150244</td>\n",
       "      <td>...</td>\n",
       "      <td>0.426463</td>\n",
       "      <td>0.376010</td>\n",
       "      <td>0.822865</td>\n",
       "      <td>[-0.10265639424324036, 1.1677250862121582, 0.6...</td>\n",
       "      <td>[0.11189224570989609, 0.15599825978279114, 0.0...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.183...</td>\n",
       "      <td>[0.6420049667358398, 0.15556158125400543, 0.52...</td>\n",
       "      <td>[-0.08922557532787323, -0.11901074647903442, -...</td>\n",
       "      <td>[0.021995531395077705, 0.005936590954661369, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>333</td>\n",
       "      <td>138</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.324544</td>\n",
       "      <td>0.208890</td>\n",
       "      <td>0.225211</td>\n",
       "      <td>...</td>\n",
       "      <td>0.188132</td>\n",
       "      <td>0.222127</td>\n",
       "      <td>0.639183</td>\n",
       "      <td>[0.6915091276168823, 0.6846891641616821, 0.118...</td>\n",
       "      <td>[5.7689690589904785, 9.512104034423828, 6.5733...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.6883434653282166, 0.0, ...</td>\n",
       "      <td>[2.5478780269622803, 0.08086305111646652, 1.02...</td>\n",
       "      <td>[-0.14103250205516815, 0.9586131572723389, -0....</td>\n",
       "      <td>[0.009228757582604885, 0.029635651037096977, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>336</td>\n",
       "      <td>139</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.264409</td>\n",
       "      <td>0.337538</td>\n",
       "      <td>0.473232</td>\n",
       "      <td>...</td>\n",
       "      <td>0.485798</td>\n",
       "      <td>0.106177</td>\n",
       "      <td>0.721181</td>\n",
       "      <td>[-0.03830425441265106, 1.4775091409683228, 0.3...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.1234784126281738, 1.496...</td>\n",
       "      <td>[0.08426664024591446, 0.5267136693000793, 0.07...</td>\n",
       "      <td>[-0.15783673524856567, -0.045695312321186066, ...</td>\n",
       "      <td>[0.189242884516716, 0.004741324577480555, 0.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>339</td>\n",
       "      <td>140</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.288309</td>\n",
       "      <td>0.361128</td>\n",
       "      <td>0.493497</td>\n",
       "      <td>...</td>\n",
       "      <td>0.235000</td>\n",
       "      <td>0.345043</td>\n",
       "      <td>0.520483</td>\n",
       "      <td>[-0.38133615255355835, 0.4218408167362213, -0....</td>\n",
       "      <td>[3.0698630809783936, 0.0, 0.0, 0.0, 0.0, 10.97...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.15414564311504364, 0.0, 0.47813552618026733...</td>\n",
       "      <td>[0.5047202706336975, 0.19584934413433075, 0.42...</td>\n",
       "      <td>[0.17814408242702484, 1.3887048959732056, 0.16...</td>\n",
       "      <td>[0.02644127421081066, 0.02242049016058445, 0.1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0   ID  Sample Count  Batch Number  Search Reconstruction  \\\n",
       "282         282  120           NaN           NaN                    NaN   \n",
       "285         285  121           NaN           NaN                    NaN   \n",
       "288         288  122           NaN           NaN                    NaN   \n",
       "291         291  124           NaN           NaN                    NaN   \n",
       "294         294  125           NaN           NaN                    NaN   \n",
       "297         297  126           NaN           NaN                    NaN   \n",
       "300         300  127           NaN           NaN                    NaN   \n",
       "303         303  128           NaN           NaN                    NaN   \n",
       "306         306  129           NaN           NaN                    NaN   \n",
       "309         309  130           NaN           NaN                    NaN   \n",
       "312         312  131           NaN           NaN                    NaN   \n",
       "315         315  132           NaN           NaN                    NaN   \n",
       "318         318  133           NaN           NaN                    NaN   \n",
       "321         321  134           NaN           NaN                    NaN   \n",
       "324         324  135           NaN           NaN                    NaN   \n",
       "327         327  136           NaN           NaN                    NaN   \n",
       "330         330  137           NaN           NaN                    NaN   \n",
       "333         333  138           NaN           NaN                    NaN   \n",
       "336         336  139           NaN           NaN                    NaN   \n",
       "339         339  140           NaN           NaN                    NaN   \n",
       "\n",
       "     Sample Indicator  Strength  Brain Correlation V1  Brain Correlation V2  \\\n",
       "282                10       1.0              0.211541              0.255005   \n",
       "285                10       1.0              0.191981              0.232085   \n",
       "288                10       1.0              0.277557              0.117816   \n",
       "291                10       1.0              0.033092              0.056477   \n",
       "294                10       1.0              0.292899              0.218387   \n",
       "297                10       1.0              0.527363              0.445815   \n",
       "300                10       1.0              0.153832              0.071102   \n",
       "303                10       1.0              0.622453              0.563634   \n",
       "306                10       1.0              0.459814              0.513667   \n",
       "309                10       1.0              0.498804              0.541754   \n",
       "312                10       1.0              0.370552              0.270243   \n",
       "315                10       1.0              0.440162              0.480298   \n",
       "318                10       1.0              0.193299              0.067126   \n",
       "321                10       1.0              0.631385              0.512296   \n",
       "324                10       1.0              0.195355              0.099527   \n",
       "327                10       1.0              0.373903              0.372653   \n",
       "330                10       1.0              0.509267              0.359658   \n",
       "333                10       1.0              0.324544              0.208890   \n",
       "336                10       1.0              0.264409              0.337538   \n",
       "339                10       1.0              0.288309              0.361128   \n",
       "\n",
       "     Brain Correlation V3  ...      SSIM  Pixel Correlation  CLIP Cosine  \\\n",
       "282              0.290492  ...  0.231562           0.114387     0.682649   \n",
       "285              0.216655  ...  0.401904           0.522101     0.828439   \n",
       "288              0.080873  ...  0.352593           0.598277     0.899088   \n",
       "291              0.123699  ...  0.381738           0.588193     0.833040   \n",
       "294              0.303519  ...  0.032481           0.376428     0.768817   \n",
       "297              0.484083  ...  0.336756           0.190783     0.821505   \n",
       "300             -0.037902  ...  0.057295          -0.005386     0.667361   \n",
       "303              0.470665  ...  0.583809           0.304057     0.623612   \n",
       "306              0.458088  ...  0.178612           0.632651     0.871673   \n",
       "309              0.611516  ...  0.193343           0.274551     0.562545   \n",
       "312              0.226068  ...  0.278322           0.578974     0.577503   \n",
       "315              0.579302  ...  0.220226           0.545394     0.770331   \n",
       "318              0.167046  ...  0.058795           0.177501     0.871674   \n",
       "321              0.511945  ...  0.514703           0.504294     0.672576   \n",
       "324              0.114489  ...  0.357655           0.464276     0.748389   \n",
       "327              0.380639  ...  0.274660           0.394617     0.592142   \n",
       "330              0.150244  ...  0.426463           0.376010     0.822865   \n",
       "333              0.225211  ...  0.188132           0.222127     0.639183   \n",
       "336              0.473232  ...  0.485798           0.106177     0.721181   \n",
       "339              0.493497  ...  0.235000           0.345043     0.520483   \n",
       "\n",
       "                                          CLIP Two-way  \\\n",
       "282  [0.8601428270339966, 0.4621444642543793, 0.068...   \n",
       "285  [-0.035639554262161255, 0.9489609599113464, -0...   \n",
       "288  [0.06282173097133636, 1.1641817092895508, 0.18...   \n",
       "291  [0.20614571869373322, 1.1074206829071045, 0.73...   \n",
       "294  [0.9571543335914612, 0.9463894367218018, -0.13...   \n",
       "297  [0.616702675819397, -0.4651188254356384, -0.71...   \n",
       "300  [1.0949320793151855, 0.866348385810852, 0.2934...   \n",
       "303  [0.618984043598175, -0.5981809496879578, -0.49...   \n",
       "306  [0.03946657478809357, 0.8725806474685669, 0.33...   \n",
       "309  [0.2784273624420166, 0.23733465373516083, 1.01...   \n",
       "312  [-0.04233205318450928, 0.5397247672080994, -0....   \n",
       "315  [0.249669149518013, 0.1094132661819458, -0.593...   \n",
       "318  [-0.5869687795639038, 0.6962552070617676, 0.45...   \n",
       "321  [0.10049229860305786, 0.07620100677013397, 0.2...   \n",
       "324  [0.7994589805603027, 0.07811986654996872, -0.2...   \n",
       "327  [1.2743653059005737, -1.4894688129425049, -0.1...   \n",
       "330  [-0.10265639424324036, 1.1677250862121582, 0.6...   \n",
       "333  [0.6915091276168823, 0.6846891641616821, 0.118...   \n",
       "336  [-0.03830425441265106, 1.4775091409683228, 0.3...   \n",
       "339  [-0.38133615255355835, 0.4218408167362213, -0....   \n",
       "\n",
       "                                             AlexNet 2  \\\n",
       "282  [4.2238688468933105, 0.25726407766342163, 0.0,...   \n",
       "285  [0.0, 0.0, 5.173697471618652, 0.44474488496780...   \n",
       "288  [3.4371659755706787, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "291  [5.654211044311523, 3.1328423023223877, 0.0854...   \n",
       "294  [15.472354888916016, 25.573116302490234, 9.885...   \n",
       "297  [6.559354305267334, 0.7117111682891846, 0.0851...   \n",
       "300  [2.5267417430877686, 1.3142582178115845, 0.0, ...   \n",
       "303  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "306  [1.5147377252578735, 5.193026065826416, 0.8120...   \n",
       "309  [2.321463108062744, 1.7710672616958618, 1.2338...   \n",
       "312  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3894717097282...   \n",
       "315  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "318  [5.627917766571045, 0.8574362993240356, 0.0, 7...   \n",
       "321  [1.0180931091308594, 0.3849928379058838, 0.0, ...   \n",
       "324  [4.0040998458862305, 2.701425790786743, 0.0439...   \n",
       "327  [1.2974324226379395, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "330  [0.11189224570989609, 0.15599825978279114, 0.0...   \n",
       "333  [5.7689690589904785, 9.512104034423828, 6.5733...   \n",
       "336  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "339  [3.0698630809783936, 0.0, 0.0, 0.0, 0.0, 10.97...   \n",
       "\n",
       "                                             AlexNet 5  \\\n",
       "282  [0.0, 0.0, 1.757684588432312, 0.14867722988128...   \n",
       "285  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "288  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "291  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "294  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "297  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "300  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "303  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "306  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "309  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "312  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "315  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "318  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "321  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.987...   \n",
       "324  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "327  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "330  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "333  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "336  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "339  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "                                             AlexNet 7  \\\n",
       "282  [0.0, 0.0, 0.0, 0.0, 0.48669248819351196, 0.0,...   \n",
       "285  [0.0, 0.0, 0.0, 0.0, 0.3698512613773346, 0.0, ...   \n",
       "288  [0.0, 0.0, 1.2006441354751587, 0.0, 0.0, 0.0, ...   \n",
       "291  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "294  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "297  [0.0, 0.0, 0.0, 0.0, 0.0, 2.296313762664795, 0...   \n",
       "300  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.21564216...   \n",
       "303  [3.659572124481201, 0.0, 0.0, 0.0, 0.550447344...   \n",
       "306  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "309  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "312  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "315  [0.0, 0.0, 1.4636844396591187, 0.0, 0.0, 0.0, ...   \n",
       "318  [0.0, 0.0, 0.0, 3.1571764945983887, 0.0, 0.0, ...   \n",
       "321  [0.0, 1.5796780586242676, 0.1306583285331726, ...   \n",
       "324  [1.0952032804489136, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "327  [0.0, 0.0, 0.0, 0.9262102842330933, 0.0, 0.0, ...   \n",
       "330  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.183...   \n",
       "333  [0.0, 0.0, 0.0, 0.0, 0.6883434653282166, 0.0, ...   \n",
       "336  [0.0, 0.0, 0.0, 0.0, 1.1234784126281738, 1.496...   \n",
       "339  [0.15414564311504364, 0.0, 0.47813552618026733...   \n",
       "\n",
       "                                          Inception V3  \\\n",
       "282  [0.34756341576576233, 0.05925580486655235, 0.3...   \n",
       "285  [0.7240560054779053, 0.35163170099258423, 0.48...   \n",
       "288  [1.4704668521881104, 0.25028887391090393, 0.14...   \n",
       "291  [0.36313506960868835, 0.21247270703315735, 0.3...   \n",
       "294  [1.0989038944244385, 0.015583536587655544, 0.2...   \n",
       "297  [0.7964139580726624, 0.025477230548858643, 0.5...   \n",
       "300  [3.3017823696136475, 0.07054632157087326, 1.38...   \n",
       "303  [0.2670031189918518, 0.4547840654850006, 0.245...   \n",
       "306  [2.0597407817840576, 0.2124146968126297, 0.121...   \n",
       "309  [0.045937661081552505, 0.4585883915424347, 0.1...   \n",
       "312  [0.2853809893131256, 0.2863912284374237, 0.185...   \n",
       "315  [0.05344991385936737, 0.29405227303504944, 0.1...   \n",
       "318  [0.12484695762395859, 0.22987236082553864, 0.0...   \n",
       "321  [0.8256660103797913, 0.7809292674064636, 0.744...   \n",
       "324  [0.28174889087677, 0.41948074102401733, 0.1731...   \n",
       "327  [1.1879547834396362, 0.2042853832244873, 0.180...   \n",
       "330  [0.6420049667358398, 0.15556158125400543, 0.52...   \n",
       "333  [2.5478780269622803, 0.08086305111646652, 1.02...   \n",
       "336  [0.08426664024591446, 0.5267136693000793, 0.07...   \n",
       "339  [0.5047202706336975, 0.19584934413433075, 0.42...   \n",
       "\n",
       "                                              EffNet-B  \\\n",
       "282  [-0.08691135793924332, -0.2146623730659485, 0....   \n",
       "285  [-0.08289328962564468, -0.11956726759672165, -...   \n",
       "288  [-0.11759889125823975, -0.049544740468263626, ...   \n",
       "291  [-0.0610351637005806, -0.08393349498510361, -0...   \n",
       "294  [-0.022317521274089813, -0.20899473130702972, ...   \n",
       "297  [-0.06951962411403656, 0.7926462888717651, -0....   \n",
       "300  [-0.1269661784172058, -0.16990086436271667, -0...   \n",
       "303  [-0.08394108712673187, -0.10422228276729584, -...   \n",
       "306  [-0.04973549768328667, 0.0015072335954755545, ...   \n",
       "309  [-0.0634067952632904, -0.13620252907276154, -0...   \n",
       "312  [0.6702555418014526, 0.29507172107696533, 0.09...   \n",
       "315  [0.0082815857604146, -0.11184491962194443, -0....   \n",
       "318  [0.24519608914852142, -0.020434748381376266, 0...   \n",
       "321  [-0.09502176195383072, 0.2288413643836975, -0....   \n",
       "324  [1.3254244327545166, 0.012831226922571659, -0....   \n",
       "327  [0.5392148494720459, 1.6687936782836914, -0.11...   \n",
       "330  [-0.08922557532787323, -0.11901074647903442, -...   \n",
       "333  [-0.14103250205516815, 0.9586131572723389, -0....   \n",
       "336  [-0.15783673524856567, -0.045695312321186066, ...   \n",
       "339  [0.17814408242702484, 1.3887048959732056, 0.16...   \n",
       "\n",
       "                                                  SwAV  \n",
       "282  [0.0, 0.052054762840270996, 0.0, 0.19318062067...  \n",
       "285  [0.07443360984325409, 0.0, 0.0, 0.0, 0.0791304...  \n",
       "288  [0.0, 0.022066811099648476, 0.0087081892415881...  \n",
       "291  [0.05101518705487251, 0.0, 0.0, 0.0, 0.1382670...  \n",
       "294  [0.01967310719192028, 0.04778313636779785, 0.0...  \n",
       "297  [0.0, 0.01535372156649828, 0.04593706503510475...  \n",
       "300  [0.19225183129310608, 0.05766328051686287, 0.0...  \n",
       "303  [0.1629466414451599, 0.013671763241291046, 0.0...  \n",
       "306  [0.0009561810293234885, 0.09368328750133514, 0...  \n",
       "309  [0.10486996918916702, 0.014845172874629498, 0....  \n",
       "312  [0.043866802006959915, 0.48325690627098083, 0....  \n",
       "315  [0.0, 0.0, 0.09911888092756271, 0.0, 0.0661689...  \n",
       "318  [0.05119730532169342, 0.000348422589013353, 0....  \n",
       "321  [0.07734528928995132, 0.020817482843995094, 0....  \n",
       "324  [0.0, 0.02665386162698269, 0.01077952049672603...  \n",
       "327  [0.07210078835487366, 0.20833976566791534, 0.2...  \n",
       "330  [0.021995531395077705, 0.005936590954661369, 0...  \n",
       "333  [0.009228757582604885, 0.029635651037096977, 0...  \n",
       "336  [0.189242884516716, 0.004741324577480555, 0.0,...  \n",
       "339  [0.02644127421081066, 0.02242049016058445, 0.1...  \n",
       "\n",
       "[20 rows x 24 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test_idx = [20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 45, 46, 47, 48, 50, 51, 52, 53, 54, 55, 56, 58, 59, 60, 62, 63, 64, 65, 66, 67, 68, 69, 71, 72, 73, 74, 75, 79, 80, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 106, 107, 108, 109, 111, 113, 115, 116, 117, 118, 119, 120, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140]\n",
    "# test_idx = [20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 71, 72, 73, 74, 75, 77, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 106, 107, 108, 109, 110, 111, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140]\n",
    "# Paper Only\n",
    "# df_final_samples    = df.loc[(df['Sample Indicator'] == 11) & (df['ID'].isin(test_idx))]\n",
    "# df_final_samples.head()\n",
    "# print(df.keys())\n",
    "# df_final_samples    = df.loc[(df['Search Reconstruction'] == True)]\n",
    "df_final_samples    = df.loc[(df['Sample Indicator'] == 10)]\n",
    "# df_final_samples    = df.loc[(df['Search Reconstruction'] == True) & (df['ID'].isin(test_idx))]\n",
    "# print(len(df_final_samples), len(df_final_samples)/5)\n",
    "# print(np.unique(np.array(df_final_samples['ID'].tolist()), return_counts=True))\n",
    "# df_final_samples.head()\n",
    "\n",
    "\n",
    "print(\"------------------------------------------------ Brain Correlation V1 -----------------------------------------------------------------\")\n",
    "\n",
    "print(\"Brain Correlation V1: \", df_final_samples['Brain Correlation V1'].mean())\n",
    "\n",
    "print(\"------------------------------------------------ Brain Correlation V2 -----------------------------------------------------------------\")\n",
    "\n",
    "print(\"Brain Correlation V2: \", df_final_samples['Brain Correlation V2'].mean())\n",
    "\n",
    "print(\"------------------------------------------------ Brain Correlation V3 -----------------------------------------------------------------\")\n",
    "\n",
    "print(\"Brain Correlation V3: \", df_final_samples['Brain Correlation V3'].mean())\n",
    "\n",
    "print(\"------------------------------------------------ Brain Correlation V4 -----------------------------------------------------------------\")\n",
    "\n",
    "print(\"Brain Correlation V4: \", df_final_samples['Brain Correlation V4'].mean())\n",
    "\n",
    "print(\"------------------------------------------------ Brain Correlation Early Visual -------------------------------------------------------\")\n",
    "\n",
    "print(\"Brain Correlation Early Visual: \", df_final_samples['Brain Correlation Early Visual'].mean())\n",
    "\n",
    "print(\"------------------------------------------------ Brain Correlation Higher Visual -------------------------------------------------------\")\n",
    "\n",
    "print(\"Brain Correlation Higher Visual: \", df_final_samples['Brain Correlation Higher Visual'].mean())\n",
    "\n",
    "print(\"------------------------------------------------ Brain Correlation NSD General ---------------------------------------------------------\")\n",
    "\n",
    "print(\"Brain Correlation NSD General: \", df_final_samples['Brain Correlation NSD General'].mean())\n",
    "df_final_samples.tail(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average Iteration Brain Region Plot\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "brain_correlation_V1 = []\n",
    "brain_correlation_V2 = []\n",
    "brain_correlation_V3 = []\n",
    "brain_correlation_V4 = []\n",
    "brain_correlation_early_visual = []\n",
    "brain_correlation_higher_visual = []\n",
    "brain_correlation_unmasked = []\n",
    "brain_correlation_ground_truth = []\n",
    "\n",
    "folders = {\"vdvae_distribution\" : 2, \"clip_distribution\" : 1, \"clip+vdvae_distribution\" : 3, \"iter_0\" : 4, \"iter_1\" : 5 , \"iter_2\" : 6, \"iter_3\" : 7, \"iter_4\" : 8, \"iter_5\" : 9}\n",
    "x = [\"vdvae\", \"clip\", \"clip+\\nvdvae\", \"iter 0\", \"iter 1\", \"iter 2\", \"iter 3\", \"iter 4\", \"iter 5\"]\n",
    "\n",
    "for folder, sample_indicator in folders.items():\n",
    "    \n",
    "    iteration_val_v1 = df.loc[(df['Sample Indicator'] == sample_indicator)]['Brain Correlation V1'].mean()\n",
    "    iteration_val_v2 = df.loc[(df['Sample Indicator'] == sample_indicator)]['Brain Correlation V2'].mean()\n",
    "    iteration_val_v3 = df.loc[(df['Sample Indicator'] == sample_indicator)]['Brain Correlation V3'].mean()\n",
    "    iteration_val_v4 = df.loc[(df['Sample Indicator'] == sample_indicator)]['Brain Correlation V4'].mean()\n",
    "    iteration_val_ev = df.loc[(df['Sample Indicator'] == sample_indicator)]['Brain Correlation Early Visual'].mean()\n",
    "    iteration_val_hv = df.loc[(df['Sample Indicator'] == sample_indicator)]['Brain Correlation Higher Visual'].mean()\n",
    "    iteration_val_unmasked = df.loc[(df['Sample Indicator'] == sample_indicator)]['Brain Correlation NSD General'].mean()\n",
    "    \n",
    "    brain_correlation_V1.append(iteration_val_v1)\n",
    "    brain_correlation_V2.append(iteration_val_v2)\n",
    "    brain_correlation_V3.append(iteration_val_v3)\n",
    "    brain_correlation_V4.append(iteration_val_v4)\n",
    "    brain_correlation_early_visual.append(iteration_val_ev)\n",
    "    brain_correlation_higher_visual.append(iteration_val_hv)\n",
    "    brain_correlation_unmasked.append(iteration_val_unmasked)\n",
    "    \n",
    "\n",
    "# plt.axhline(y = df.loc[(df['Sample Indicator'] == 0.0)]['Brain Correlation V1'].mean(), color = 'blue', linestyle = 'dashed', linewidth=1)\n",
    "# plt.axhline(y = df.loc[(df['Sample Indicator'] == 0.0)]['Brain Correlation V2'].mean(), color = 'green', linestyle = 'dashed', linewidth=1)\n",
    "# plt.axhline(y = df.loc[(df['Sample Indicator'] == 0.0)]['Brain Correlation V3'].mean(), color = 'red',linestyle = 'dashed', linewidth=1)\n",
    "# plt.axhline(y = df.loc[(df['Sample Indicator'] == 0.0)]['Brain Correlation V4'].mean(), color = 'orange',linestyle = 'dashed', linewidth=1)\n",
    "# plt.axhline(y = df.loc[(df['Sample Indicator'] == 0.0)]['Brain Correlation Higher Visual'].mean(), color = 'brown', linestyle = 'dashed', linewidth=1)\n",
    "# plt.axhline(y = df.loc[(df['Sample Indicator'] == 0.0)]['Brain Correlation Early Visual'].mean(),  color = 'magenta',linestyle = 'dashed', linewidth=1)\n",
    "plt.axhline(y = df.loc[(df['Sample Indicator'] == 0.0)]['Brain Correlation NSD General'].mean(), color = 'black', linestyle = 'dashed', linewidth=1)\n",
    "\n",
    "plt.plot(brain_correlation_V1, marker='.', color = 'blue', label = 'V1', linewidth=1)\n",
    "plt.plot(brain_correlation_V2, marker='.', color = 'green',label = 'V2', linewidth=1)\n",
    "plt.plot(brain_correlation_V3, marker='.', color = 'red',  label = 'V3', linewidth=1)\n",
    "plt.plot(brain_correlation_V4, marker='.', color = 'orange', label = 'V4', linewidth=1)\n",
    "plt.plot(brain_correlation_higher_visual, marker='.', color = 'brown', label = 'Higher Visual', linewidth=1)\n",
    "plt.plot(brain_correlation_early_visual, marker='.',  color = 'magenta', label = 'Early Visual', linewidth=1)\n",
    "plt.plot(brain_correlation_unmasked, marker='.',  color = 'black', label = 'NSD General', linewidth=1)\n",
    "plt.xticks(range(len(x)), x,fontsize=9)\n",
    "\n",
    "plt.legend(fontsize = \"xx-small\")\n",
    "plt.xlabel(\"Search Iteration\")\n",
    "plt.ylabel(\"Avearge Brain Pearson Correlation\")\n",
    "plt.title(\"Encoded Brain Pearson Correlation\")\n",
    "mpl.rcParams['figure.dpi'] = 300\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average Iteration Brain Region Plot\n",
    "\n",
    "brain_correlation_V1 = []\n",
    "brain_correlation_V2 = []\n",
    "brain_correlation_V3 = []\n",
    "brain_correlation_V4 = []\n",
    "brain_correlation_early_visual = []\n",
    "brain_correlation_higher_visual = []\n",
    "brain_correlation_unmasked = []\n",
    "brain_correlation_ground_truth = []\n",
    "\n",
    "y_v1 = df.loc[(df['Sample Indicator'] == 0.0)]['Brain Correlation V1'].mean()\n",
    "y_v2 = df.loc[(df['Sample Indicator'] == 0.0)]['Brain Correlation V2'].mean()\n",
    "y_v3 = df.loc[(df['Sample Indicator'] == 0.0)]['Brain Correlation V3'].mean()\n",
    "y_v4 = df.loc[(df['Sample Indicator'] == 0.0)]['Brain Correlation V4'].mean()\n",
    "y_ev = df.loc[(df['Sample Indicator'] == 0.0)]['Brain Correlation Early Visual'].mean()\n",
    "y_hv = df.loc[(df['Sample Indicator'] == 0.0)]['Brain Correlation Higher Visual'].mean()\n",
    "y_unmasked = df.loc[(df['Sample Indicator'] == 0.0)]['Brain Correlation NSD General'].mean()\n",
    "\n",
    "v1_set = True\n",
    "v2_set = True\n",
    "v3_set = True\n",
    "v4_set = True\n",
    "ev_set = True\n",
    "hv_set = True\n",
    "unmasked_set = True\n",
    "\n",
    "x_v1 = 0 \n",
    "x_v2 = 0 \n",
    "x_v3 = 0 \n",
    "x_v4 = 0 \n",
    "x_ev = 0 \n",
    "x_hv = 0 \n",
    "x_umasked = 0 \n",
    "\n",
    "folders = {\"vdvae_distribution\" : 2, \"clip_distribution\" : 1, \"clip+vdvae_distribution\" : 3, \"iter_0\" : 4, \"iter_1\" : 5 , \"iter_2\" : 6, \"iter_3\" : 7, \"iter_4\" : 8, \"iter_5\" : 9}\n",
    "x = [\"vdvae\", \"clip\", \"clip+\\nvdvae\", \"iter 0\", \"iter 1\", \"iter 2\", \"iter 3\", \"iter 4\", \"iter 5\"]\n",
    "iteration = 0\n",
    "\n",
    "\n",
    "for folder, sample_indicator in folders.items():\n",
    "    \n",
    "    iteration_val_v1 = df.loc[(df['Sample Indicator'] == sample_indicator)]['Brain Correlation V1'].mean()\n",
    "    iteration_val_v2 = df.loc[(df['Sample Indicator'] == sample_indicator)]['Brain Correlation V2'].mean()\n",
    "    iteration_val_v3 = df.loc[(df['Sample Indicator'] == sample_indicator)]['Brain Correlation V3'].mean()\n",
    "    iteration_val_v4 = df.loc[(df['Sample Indicator'] == sample_indicator)]['Brain Correlation V4'].mean()\n",
    "    iteration_val_ev = df.loc[(df['Sample Indicator'] == sample_indicator)]['Brain Correlation Early Visual'].mean()\n",
    "    iteration_val_hv = df.loc[(df['Sample Indicator'] == sample_indicator)]['Brain Correlation Higher Visual'].mean()\n",
    "    iteration_val_unmasked = df.loc[(df['Sample Indicator'] == sample_indicator)]['Brain Correlation NSD General'].mean()\n",
    "    \n",
    "    brain_correlation_V1.append(iteration_val_v1)\n",
    "    brain_correlation_V2.append(iteration_val_v2)\n",
    "    brain_correlation_V3.append(iteration_val_v3)\n",
    "    brain_correlation_V4.append(iteration_val_v4)\n",
    "    brain_correlation_early_visual.append(iteration_val_ev)\n",
    "    brain_correlation_higher_visual.append(iteration_val_hv)\n",
    "    brain_correlation_unmasked.append(iteration_val_unmasked)\n",
    "    \n",
    "    if(iteration_val_v1 > y_v1 and v1_set):\n",
    "        x_v1 = iteration - 1\n",
    "        v1_set = False\n",
    "        \n",
    "    if(iteration_val_v2 > y_v2 and v2_set):\n",
    "        x_v2 = iteration - 1\n",
    "        v2_set = False\n",
    "        \n",
    "    if(iteration_val_v3 > y_v3 and v3_set):\n",
    "        x_v3 = iteration - 1\n",
    "        v3_set = False\n",
    "        \n",
    "    if(iteration_val_v4 > y_v4 and v4_set):\n",
    "        x_v4 = iteration - 1\n",
    "        v4_set = False\n",
    "        \n",
    "    if(iteration_val_ev > y_ev and ev_set):\n",
    "        x_ev = iteration - 1\n",
    "        ev_set = False\n",
    "        \n",
    "    if(iteration_val_hv > y_hv and hv_set):\n",
    "        x_hv = iteration - 1\n",
    "        hv_set = False\n",
    "        \n",
    "    if(iteration_val_unmasked > y_unmasked and unmasked_set):\n",
    "        x_unmasked = iteration - 1\n",
    "        unmasked_set = False\n",
    "        \n",
    "    iteration += 1\n",
    "    \n",
    "# print(df.loc[(df['Sample Indicator'] == 0.0)]['Brain Correlation Unmasked'].mean())\n",
    "# plt.axhline(y = df.loc[(df['Sample Indicator'] == 0.0)]['Brain Correlation Unmasked'].mean(), linestyle = 'dashed', label = 'Brain Correlation Unmasked')\n",
    "# plt.axhline(y = df.loc[(df['Sample Indicator'] == 0.0)]['Brain Correlation V1'].mean(), linestyle = '-', label = 'Brain Correlation V1')\n",
    "# plt.axhline(y = df.loc[(df['Sample Indicator'] == 0.0)]['Brain Correlation V2'].mean(), linestyle = '-', label = 'Brain Correlation V2')\n",
    "# plt.axhline(y = df.loc[(df['Sample Indicator'] == 0.0)]['Brain Correlation V3'].mean(), linestyle = '-', label = 'Brain Correlation V3')\n",
    "# plt.axhline(y = df.loc[(df['Sample Indicator'] == 0.0)]['Brain Correlation V4'].mean(), linestyle = '-', label = 'Brain Correlation V4')\n",
    "# plt.axhline(y = df.loc[(df['Sample Indicator'] == 0.0)]['Brain Correlation Higher Visual'].mean(), linestyle = '-', label = 'Brain Correlation Higher Visual')\n",
    "# plt.axhline(y = df.loc[(df['Sample Indicator'] == 0.0)]['Brain Correlation Early Visual'].mean(), linestyle = '-', label = 'Brain Correlation Higher Visual')\n",
    "\n",
    "\n",
    "N = 9\n",
    "#x = np.array([0,1,2,3,4,5,6,7,8,9])\n",
    "# y = np.array(brain_correlation_unmasked)\n",
    "# a, b = np.polyfit(x, brain_correlation_unmasked, deg=1)\n",
    "# y_est = a * x + b\n",
    "# y_err = st.t.interval(alpha=0.95, df=len(y)-1, loc=np.mean(y), scale=st.sem(y))\n",
    "# print(y_err[0])\n",
    "# print(y_err[1])\n",
    "\n",
    "y_un = np.array(brain_correlation_unmasked)\n",
    "ci_un = 0.95 * np.std(y_un) / math.sqrt(N)\n",
    "\n",
    "\n",
    "# def mean_confidence_interval(data, confidence=0.95):\n",
    "#     a = 1.0 * np.array(data)\n",
    "#     n = len(a)\n",
    "#     m, se = np.mean(a), scipy.stats.sem(a)\n",
    "#     h = se * scipy.stats.t.ppf((1 + confidence) / 2., n-1)\n",
    "#     return m, m-h, m+h\n",
    "\n",
    "# mean, lower, upper = [],[],[]\n",
    "# ci = 0.95\n",
    "\n",
    "# m, ml, mu = mean_confidence_interval(y, ci)\n",
    "# mean.append(m)\n",
    "# lower.append(ml)\n",
    "# upper.append(mu)\n",
    "\n",
    "\n",
    "plt.plot(brain_correlation_V1, marker='.', label = 'V1', linewidth=1, color = \"royalblue\")\n",
    "plt.plot(brain_correlation_V2, marker='.', label = 'V2', linewidth=1, color = \"darkviolet\")\n",
    "plt.plot(brain_correlation_V3, marker='.', label = 'V3', linewidth=1, color = \"red\")\n",
    "plt.plot(brain_correlation_V4, marker='.', label = 'V4', linewidth=1, color = \"forestgreen\")\n",
    "#plt.plot(brain_correlation_early_visual, marker='.', label = 'Early Visual', linewidth=1, color = \"red\")\n",
    "plt.plot(brain_correlation_higher_visual, marker='.', label = 'Higher Visual', linewidth=1, color = \"darkorange\")\n",
    "plt.plot(brain_correlation_unmasked, marker='.', label = 'NSD General', linewidth=1, color = \"black\")\n",
    "plt.xticks(range(len(x)), x,fontsize=9)\n",
    "# plt.fill_between(x, y_err[0], y_err[0], color='dimgray', alpha=0.2)\n",
    "# plt.fill_between(x, upper, lower, color='dimgray', alpha=0.2)\n",
    "plt.fill_between(x, (y_un-ci_un), (y_un+ci_un), color='black', alpha=.2)\n",
    "# plt.fill_between(x, (y_hi-ci_hi), (y_hi+ci_hi), color='darkorange', alpha=.2)\n",
    "# plt.fill_between(x, (y_er-ci_er), (y_er+ci_er), color='red', alpha=.2)\n",
    "# plt.fill_between(x, (y_vo-ci_vo), (y_vo+ci_vo), color='royalblue', alpha=.2)\n",
    "# plt.fill_between(x, (y_vt-ci_vt), (y_vt+ci_vt), color='darkviolet', alpha=.2)\n",
    "# plt.fill_between(x, (y_vth-ci_vth), (y_vth+ci_vth), color='violet', alpha=.2)\n",
    "# plt.fill_between(x, (y_vf-ci_vf), (y_vf+ci_vf), color='forestgreen', alpha=.2)\n",
    "\n",
    "# plt.plot([7.25, 7 + 1], [y_v1, y_v1] , color = \"royalblue\", linestyle=\"dashed\", linewidth=2)\n",
    "# plt.plot([7.25, 7 + 1], [y_v2, y_v2] , color = \"darkviolet\", linestyle=\"dashed\", linewidth=2)\n",
    "# plt.plot([7.25, 7 + 1], [y_v3, y_v3] , color = \"violet\", linestyle=\"dashed\", linewidth=2)\n",
    "# plt.plot([x_v4 + 0.25, x_v4 + 1], [y_v4, y_v4] , color = 'forestgreen', linestyle=\"dashed\", linewidth=2)\n",
    "# plt.plot([7.25, 7 + 1], [y_ev - 0.002, y_ev - 0.002] , color = 'red', linestyle=\"dashed\", linewidth=2)\n",
    "# plt.plot([x_hv - 0.25, x_hv + 0.50], [y_hv, y_hv] , color = \"darkorange\", linestyle=\"dashed\", linewidth=2)\n",
    "# plt.plot([x_unmasked + 0.5, x_unmasked + 1.25], [y_unmasked, y_unmasked] , color = 'black', linestyle=\"dashed\", linewidth=2, label=\"Ground Truth Image\")\n",
    "#plt.axhline(x = [1,3], y = df.loc[(df['Sample Indicator'] == 0.0)]['Brain Correlation Unmasked'].mean(), linestyle = 'dashed', label = 'Brain Correlation Unmasked')\n",
    "# plt.axhline(y = df.loc[(df['Sample Indicator'] == 0.0)]['Brain Correlation V1'].mean(), linestyle = '-', label = 'Brain Correlation V1')\n",
    "# plt.axhline(y = df.loc[(df['Sample Indicator'] == 0.0)]['Brain Correlation V2'].mean(), linestyle = '-', label = 'Brain Correlation V2')\n",
    "# plt.axhline(y = df.loc[(df['Sample Indicator'] == 0.0)]['Brain Correlation V3'].mean(), linestyle = '-', label = 'Brain Correlation V3')\n",
    "# plt.axhline(y = df.loc[(df['Sample Indicator'] == 0.0)]['Brain Correlation V4'].mean(), linestyle = '-', label = 'Brain Correlation V4')\n",
    "# plt.axhline(y = df.loc[(df['Sample Indicator'] == 0.0)]['Brain Correlation Higher Visual'].mean(), linestyle = '-', label = 'Brain Correlation Higher Visual')\n",
    "# plt.axhline(y = df.loc[(df['Sample Indicator'] == 0.0)]['Brain Correlation Early Visual'].mean(), linestyle = '-', label = 'Brain Correlation Higher Visual')\n",
    "leg = plt.legend(loc=\"upper left\", ncol = 2, fontsize = \"4.5\")\n",
    "# leg.legendHandles[7].set_color('silver')\n",
    "plt.xlabel(\"Search Iteration\")\n",
    "plt.ylabel(\"Avearge Brain Pearson Correlation\")\n",
    "plt.title(\"Encoded Brain Pearson Correlation\")\n",
    "mpl.rcParams['figure.dpi'] = 2500\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search iterations to Ground Truth\n",
    "\n",
    "x_iter_values = []\n",
    "\n",
    "x_iter_values.append(10)\n",
    "x_iter_values.append(10)\n",
    "x_iter_values.append(10)\n",
    "x_iter_values.append(9)\n",
    "x_iter_values.append(0)\n",
    "\n",
    "x_labels = ['V1', 'V2', 'V3', 'V4', 'Higher Visual']\n",
    "x_axis = np.arange(len(x_labels))\n",
    "# y_labels = [\"0\", \"2\", \"4\", \"6\", \"8\", \"10 >=\"]\n",
    "# y_axis = np.arange(len(y_labels))\n",
    "\n",
    "# x_iter_values.append(0)\n",
    "# x_iter_values.append(x_v4)\n",
    "# x_iter_values.append(x_v3)\n",
    "# x_iter_values.append(x_v2)\n",
    "# x_iter_values.append(9)\n",
    "\n",
    "# x_labels = ['Higher Visual', 'V4', 'V3', 'V2', 'V1']\n",
    "plt.xticks(x_axis, x_labels)\n",
    "# plt.yticks(y_axis, y_labels)\n",
    "plt.plot(x_iter_values, marker='o', linewidth=2, color = \"darkgray\")\n",
    "plt.xlabel(\"Brain Areas\", fontsize=18)\n",
    "plt.ylabel(\"Iterations to ground truth\", fontsize=18)\n",
    "plt.title(\"Search iterations to surpass ground truth\\n brain correlation score\", fontsize=20)\n",
    "mpl.rcParams['figure.dpi'] = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar Plot Sample Counts \n",
    "\n",
    "idx = [20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, \n",
    "        64, 65, 66, 67, 68, 69, 71, 72, 73, 74, 75, 77, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 106, 107, 108, \n",
    "        109, 110, 111, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145,\n",
    "        147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, \n",
    "        182, 183, 184, 185, 186, 188, 189, 190, 191, 192, 193, 194, 195, 196, 198, 199, 200, 201, 202, 203, 205, 206, 207, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, \n",
    "        221, 222, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 256, 257, \n",
    "        258, 259, 261, 262, 263, 264, 265, 266, 267, 268, 270, 272, 273, 274, 275, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, \n",
    "        297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, \n",
    "        333, 334, 335, 336, 337, 338, 339, 341, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 364, 365, 366, 367, 368, 369, 370, \n",
    "        371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 393, 394, 395, 396, 397, 398, 400, 401, 402, 403, 404, 406, 407, 408, \n",
    "        409, 410, 411, 412, 413, 414, 415, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, \n",
    "        447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 481, 482, \n",
    "        483, 484, 485, 486, 487, 488, 489, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, \n",
    "        521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 547, 548, 549, 551, 552, 553, 554, 555, 556, 557, \n",
    "        558, 559, 560, 561, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, \n",
    "        594, 595, 596, 597, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 616, 617, 618, 619, 620, 621, 622, 624, 625, 626, 627, 628, 629, 630, 631, 632, \n",
    "        633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 655, 656, 657, 659, 661, 662, 663, 664, 666, 667, 668, 669, 670, 671, \n",
    "        672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 694, 695, 696, 698, 699, 700, 701, 702, 703, 704, 705, 706, 708, 709, \n",
    "        710, 711, 712, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, \n",
    "        747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 782, 783, \n",
    "        784, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819,\n",
    "        820, 821, 822, 823, 824, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 838, 839, 840, 841, 842, 843, 844, 845, 847, 848, 849, 851, 852, 854, 855, 856, 857, 858, 859,\n",
    "        861, 862, 863, 864, 865, 866, 867, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 892, 893, 894, 895, 896, 897, \n",
    "        898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 911, 912, 913, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, \n",
    "        934, 936, 937, 938, 939, 940, 941, 942, 943, 944, 945, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961, 962, 963, 964, 965, 966, 967, 968, 969, 970, \n",
    "        971, 974, 976, 977, 978, 979, 980, 981]\n",
    "\n",
    "v1 = [0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "v2 = [0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "v3 = [0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "v4 = [0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "ev = [0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "hv = [0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "nsd = [0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "\n",
    "#folders = {\"vdvae_distribution\" : 0, \"clip_distribution\" : 1, \"clip+vdvae_distribution\" : 2, \"iter_0\" : 3, \"iter_1\" : 4, \"iter_2\" : 5, \"iter_3\" : 6, \"iter_4\" : 7 , \"iter_5\": 8}\n",
    "#folders = {\"clip_distribution\" : 1, \"vdvae_distribution\" : 2, \"clip+vdvae_distribution\" : 3, \"iter_0\" : 4, \"iter_1\" : 5 , \"iter_2\" : 6, \"iter_3\" : 7, \"iter_4\" : 8, \"iter_5\" : 9}\n",
    "folders = {\"vdvae_distribution\" : 2, \"clip_distribution\" : 1, \"clip+vdvae_distribution\" : 3, \"iter_0\" : 4, \"iter_1\" : 5 , \"iter_2\" : 6, \"iter_3\" : 7, \"iter_4\" : 8, \"iter_5\" : 9}\n",
    "list_indicator = {2 : 0, 1 : 1, 3 : 2, 4 : 3, 5 : 4 , 6 : 5, 7 : 6, 8 : 7, 9 : 8}\n",
    "\n",
    "ground_truth_samples = df.loc[(df['Sample Indicator'] == 0)]\n",
    "\n",
    "# Append rows to an empty DataFrame\n",
    "for i in tqdm(idx, desc=\"creating bar graph numbers\"):\n",
    "        \n",
    "    ground_truth_v1     = float(ground_truth_samples.loc[(ground_truth_samples['ID'] == i)]['Brain Correlation V1'])\n",
    "    ground_truth_v2     = float(ground_truth_samples.loc[(ground_truth_samples['ID'] == i)]['Brain Correlation V2'])\n",
    "    ground_truth_v3     = float(ground_truth_samples.loc[(ground_truth_samples['ID'] == i)]['Brain Correlation V3'])\n",
    "    ground_truth_v4     = float(ground_truth_samples.loc[(ground_truth_samples['ID'] == i)]['Brain Correlation V4'])\n",
    "    ground_truth_ev     = float(ground_truth_samples.loc[(ground_truth_samples['ID'] == i)]['Brain Correlation Early Visual'])\n",
    "    ground_truth_hv     = float(ground_truth_samples.loc[(ground_truth_samples['ID'] == i)]['Brain Correlation Higher Visual'])\n",
    "    ground_truth_nsd    = float(ground_truth_samples.loc[(ground_truth_samples['ID'] == i)]['Brain Correlation NSD General'])\n",
    "    \n",
    "    single_sample = df.loc[(df['ID'] == i)]\n",
    "    single_sample = single_sample[:-2]\n",
    "    \n",
    "    for folder, value in folders.items():\n",
    "    \n",
    "        v1_bc = single_sample.loc[(single_sample['Sample Indicator'] == value)]['Brain Correlation V1'].mean()\n",
    "        v2_bc = single_sample.loc[(single_sample['Sample Indicator'] == value)]['Brain Correlation V2'].mean()\n",
    "        v3_bc = single_sample.loc[(single_sample['Sample Indicator'] == value)]['Brain Correlation V3'].mean()\n",
    "        v4_bc = single_sample.loc[(single_sample['Sample Indicator'] == value)]['Brain Correlation V4'].mean()\n",
    "        ev_bc = single_sample.loc[(single_sample['Sample Indicator'] == value)]['Brain Correlation Early Visual'].mean()\n",
    "        hv_bc = single_sample.loc[(single_sample['Sample Indicator'] == value)]['Brain Correlation Higher Visual'].mean()\n",
    "        nsd_bc = single_sample.loc[(single_sample['Sample Indicator'] == value)]['Brain Correlation NSD General'].mean()\n",
    "\n",
    "        if(v1_bc > ground_truth_v1):\n",
    "            v1[list_indicator[value]] += 1\n",
    "            \n",
    "        if(v2_bc > ground_truth_v2):\n",
    "            v2[list_indicator[value]] += 1\n",
    "            \n",
    "        if(v3_bc > ground_truth_v3):\n",
    "            v3[list_indicator[value]] += 1\n",
    "            \n",
    "        if(v4_bc > ground_truth_v4):\n",
    "            v4[list_indicator[value]] += 1\n",
    "        \n",
    "        if(ev_bc > ground_truth_ev):\n",
    "            ev[list_indicator[value]] += 1\n",
    "            \n",
    "        if(hv_bc > ground_truth_hv):\n",
    "            hv[list_indicator[value]] += 1\n",
    "            \n",
    "        if(nsd_bc > ground_truth_nsd):\n",
    "            nsd[list_indicator[value]] += 1\n",
    "            \n",
    "print(v1)\n",
    "print(v2)\n",
    "print(v3)\n",
    "print(v4)\n",
    "print(ev)\n",
    "print(hv)\n",
    "print(nsd)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Bar Plots\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "\n",
    "\n",
    "# x = [\"vdvae\", \"clip\", \"clip+\\nvdvae\", \"iter 0\", \"iter 1\", \"iter 2\", \"iter 3\", \"iter 4\", \"iter 5\"]\n",
    "# x = [\"V1\", \"V2\", \"V3\", \"V4\", \"Early \\nVisual\", \"Higher \\nVisual\", \"NSD \\nGeneral\"]\n",
    "\n",
    "# vdvae       = [v1[0], v2[0], v3[0], v4[0], ev[0], hv[0], nsd[0]]\n",
    "# clip        = [v1[1], v2[1], v3[1], v4[1], ev[1], hv[1], nsd[1]]\n",
    "# clip_vdvae  = [v1[2], v2[2], v3[2], v4[2], ev[2], hv[2], nsd[2]]\n",
    "# iter_0      = [v1[3], v2[3], v3[3], v4[3], ev[3], hv[3], nsd[3]]\n",
    "# iter_1      = [v1[4], v2[4], v3[4], v4[4], ev[4], hv[4], nsd[4]]\n",
    "# iter_2      = [v1[5], v2[5], v3[5], v4[5], ev[5], hv[5], nsd[5]]\n",
    "# iter_3      = [v1[6], v2[6], v3[6], v4[6], ev[6], hv[6], nsd[6]]\n",
    "# iter_4      = [v1[7], v2[7], v3[7], v4[7], ev[7], hv[7], nsd[7]]\n",
    "# iter_5      = [v1[8], v2[8], v3[8], v4[8], ev[8], hv[8], nsd[8]]\n",
    "\n",
    "\n",
    "x = [\"V1\", \"V2\", \"V3\", \"V4\", \"Higher \\nVisual\", \"NSD \\nGeneral\"]\n",
    "\n",
    "vdvae       = [v1[0], v2[0], v3[0], v4[0], hv[0], nsd[0]]\n",
    "clip        = [v1[1], v2[1], v3[1], v4[1], hv[1], nsd[1]]\n",
    "clip_vdvae  = [v1[2], v2[2], v3[2], v4[2], hv[2], nsd[2]]\n",
    "iter_0      = [v1[3], v2[3], v3[3], v4[3], hv[3], nsd[3]]\n",
    "iter_1      = [v1[4], v2[4], v3[4], v4[4], hv[4], nsd[4]]\n",
    "iter_2      = [v1[5], v2[5], v3[5], v4[5], hv[5], nsd[5]]\n",
    "iter_3      = [v1[6], v2[6], v3[6], v4[6], hv[6], nsd[6]]\n",
    "iter_4      = [v1[7], v2[7], v3[7], v4[7], hv[7], nsd[7]]\n",
    "iter_5      = [v1[8], v2[8], v3[8], v4[8], hv[8], nsd[8]]\n",
    "\n",
    "\n",
    "x_axis = np.arange(len(x))\n",
    "\n",
    "n = 6\n",
    "r = np.arange(n)\n",
    "width = 0.10\n",
    "\n",
    "\n",
    "plt.bar(r - width * 4, vdvae, color = '#e3342f',\n",
    "        width = width, edgecolor = 'black',\n",
    "        label='VDVAE')\n",
    "plt.bar(r - width * 3, clip, color = '#f6993f',\n",
    "        width = width, edgecolor = 'black',\n",
    "        label='CLIP')\n",
    "plt.bar(r - width * 2, clip_vdvae, color = '#ffed4a',\n",
    "        width = width, edgecolor = 'black',\n",
    "        label='CLIP+VDVAE')\n",
    "plt.bar(r - width, iter_0, color = '#38c172',\n",
    "        width = width, edgecolor = 'black',\n",
    "        label='Iteration 0')\n",
    "plt.bar(r, iter_1, color = '#4dc0b5',\n",
    "        width = width, edgecolor = 'black',\n",
    "        label='Iteration 1')\n",
    "plt.bar(r + width, iter_2, color = '#3490dc',\n",
    "        width = width, edgecolor = 'black',\n",
    "        label='Iteration 2')\n",
    "plt.bar(r + width * 2, iter_3, color = '#6574cd',\n",
    "        width = width, edgecolor = 'black',\n",
    "        label='Iteration 3')\n",
    "plt.bar(r + width * 3, iter_4, color = '#9561e2',\n",
    "        width = width, edgecolor = 'black',\n",
    "        label='Iteration 4')\n",
    "plt.bar(r + width * 4, iter_5, color = '#f66d9b',\n",
    "        width = width, edgecolor = 'black',\n",
    "        label='Iteration 5')\n",
    "\n",
    "plt.xticks(x_axis, x)\n",
    "plt.xlabel(\"Brain Areas\")\n",
    "plt.ylabel(\"Percentage of samples aligned to brain activity\")\n",
    "plt.title(\"Sample Distributions Alighned to Brain Activity (N = 897)\")\n",
    "plt.gca().yaxis.set_major_formatter(ticker.PercentFormatter(897))\n",
    "#plt.xlim(897)\n",
    "plt.legend(fontsize = \"x-small\")\n",
    "mpl.rcParams['figure.dpi'] = 500\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN to brain correlation plot\n",
    "arrays = []\n",
    "for sample in range(5):\n",
    "    arrays.append(np.load(\"/home/naxos2-raid25/kneel027/home/kneel027/Second-Sight-Archive/reconstructions/subject1/dataframes/swav_sample_{}.npy\".format(sample)))\n",
    "arrays = np.mean(np.stack(arrays), 0)\n",
    "print(arrays.shape)\n",
    "df_final_samples = df_final_samples.groupby('ID', as_index=False).mean()\n",
    "x = df_final_samples['Brain Correlation NSD General'].values.tolist()\n",
    "y = list(arrays)\n",
    "print(len(x), len(y))\n",
    "plt.scatter(x, y)\n",
    "plt.xlabel(\"Brain Correlation\", fontsize=18)\n",
    "plt.ylabel(\"SwAV\", fontsize=18)\n",
    "plt.title(\"CNN to brain correlation plot\", fontsize=20)\n",
    "mpl.rcParams['figure.dpi'] = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_iter_values = []\n",
    "\n",
    "x_iter_values.append(.701)\n",
    "x_iter_values.append(.822)\n",
    "x_iter_values.append(.830)\n",
    "x_iter_values.append(.828)\n",
    "x_iter_values.append(.831)\n",
    "x_iter_values.append(.831)\n",
    "x_iter_values.append(.833)\n",
    "x_iter_values.append(.838)\n",
    "x_iter_values.append(.758)\n",
    "\n",
    "x_labels = ['Only VDVAE', 'Only CLIP', 'CLIP+VDVAE', 'Iter 0', 'Iter 1','Iter 2','Iter 3','Iter 4','Iter 5']\n",
    "x_axis = np.arange(len(x_labels))\n",
    "# y_labels = [\"0\", \"2\", \"4\", \"6\", \"8\", \"10 >=\"]\n",
    "# y_axis = np.arange(len(y_labels))\n",
    "\n",
    "# x_iter_values.append(0)\n",
    "# x_iter_values.append(x_v4)\n",
    "# x_iter_values.append(x_v3)\n",
    "# x_iter_values.append(x_v2)\n",
    "# x_iter_values.append(9)\n",
    "\n",
    "# x_labels = ['Higher Visual', 'V4', 'V3', 'V2', 'V1']\n",
    "plt.xticks(x_axis, x_labels)\n",
    "# plt.yticks(y_axis, y_labels)\n",
    "plt.plot(x_iter_values, marker='o', linewidth=2, color = \"darkgray\")\n",
    "plt.xlabel(\"Search Iterations\", fontsize=18)\n",
    "plt.ylabel(\"Inception V3\", fontsize=18)\n",
    "mpl.rcParams['figure.dpi'] = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average Iteration Brain Region Plot\n",
    "\n",
    "idx = [20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, \n",
    "        64, 65, 66, 67, 68, 69, 71, 72, 73, 74, 75, 77, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 106, 107, 108, \n",
    "        109, 110, 111, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145,\n",
    "        147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, \n",
    "        182, 183, 184, 185, 186, 188, 189, 190, 191, 192, 193, 194, 195, 196, 198, 199, 200, 201, 202, 203, 205, 206, 207, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, \n",
    "        221, 222, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 256, 257, \n",
    "        258, 259, 261, 262, 263, 264, 265, 266, 267, 268, 270, 272, 273, 274, 275, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, \n",
    "        297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, \n",
    "        333, 334, 335, 336, 337, 338, 339, 341, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 364, 365, 366, 367, 368, 369, 370, \n",
    "        371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 393, 394, 395, 396, 397, 398, 400, 401, 402, 403, 404, 406, 407, 408, \n",
    "        409, 410, 411, 412, 413, 414, 415, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, \n",
    "        447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 481, 482, \n",
    "        483, 484, 485, 486, 487, 488, 489, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, \n",
    "        521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 547, 548, 549, 551, 552, 553, 554, 555, 556, 557, \n",
    "        558, 559, 560, 561, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, \n",
    "        594, 595, 596, 597, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 616, 617, 618, 619, 620, 621, 622, 624, 625, 626, 627, 628, 629, 630, 631, 632, \n",
    "        633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 655, 656, 657, 659, 661, 662, 663, 664, 666, 667, 668, 669, 670, 671, \n",
    "        672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 694, 695, 696, 698, 699, 700, 701, 702, 703, 704, 705, 706, 708, 709, \n",
    "        710, 711, 712, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, \n",
    "        747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 782, 783, \n",
    "        784, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819,\n",
    "        820, 821, 822, 823, 824, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 838, 839, 840, 841, 842, 843, 844, 845, 847, 848, 849, 851, 852, 854, 855, 856, 857, 858, 859,\n",
    "        861, 862, 863, 864, 865, 866, 867, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 892, 893, 894, 895, 896, 897, \n",
    "        898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 911, 912, 913, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, \n",
    "        934, 936, 937, 938, 939, 940, 941, 942, 943, 944, 945, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961, 962, 963, 964, 965, 966, 967, 968, 969, 970, \n",
    "        971, 974, 976, 977, 978, 979, 980, 981]\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.cm as cmx\n",
    "import seaborn as sns\n",
    "\n",
    "brain_correlation_V1 = []\n",
    "brain_correlation_V2 = []\n",
    "brain_correlation_V3 = []\n",
    "brain_correlation_V4 = []\n",
    "brain_correlation_HV = []\n",
    "brain_correlation_NSD = []\n",
    "\n",
    "folders = {\"vdvae_distribution\" : 2, \"clip_distribution\" : 1, \"clip+vdvae_distribution\" : 3, \"iter_0\" : 4, \"iter_1\" : 5 , \"iter_2\" : 6, \"iter_3\" : 7, \"iter_4\" : 8, \"iter_5\" : 9}\n",
    "x = [\"vdvae\", \"clip\", \"clip+\\nvdvae\", \"iter 0\", \"iter 1\", \"iter 2\", \"iter 3\", \"iter 4\", \"iter 5\"]\n",
    "\n",
    "v1 = {2 : [], 1: [], 3: [], 4 : [], 5 : [], 6: [], 7: [], 8: [], 9: []}\n",
    "v2 = {2 : [], 1: [], 3: [], 4 : [], 5 : [], 6: [], 7: [], 8: [], 9: []}\n",
    "v3 = {2 : [], 1: [], 3: [], 4 : [], 5 : [], 6: [], 7: [], 8: [], 9: []}\n",
    "v4 = {2 : [], 1: [], 3: [], 4 : [], 5 : [], 6: [], 7: [], 8: [], 9: []}\n",
    "hv = {2 : [], 1: [], 3: [], 4 : [], 5 : [], 6: [], 7: [], 8: [], 9: []}\n",
    "nsd = {2 : [], 1: [], 3: [], 4 : [], 5 : [], 6: [], 7: [], 8: [], 9: []}\n",
    "\n",
    "\n",
    "for i in idx:\n",
    "    \n",
    "    sample = df.loc[(df['ID'] == i)]\n",
    "        \n",
    "    for folder, sample_indicator in folders.items():\n",
    "\n",
    "        iteration_val_v1 = sample[(df['Sample Indicator'] == sample_indicator)]['Brain Correlation V1'].var()\n",
    "        iteration_val_v2 = sample[(df['Sample Indicator'] == sample_indicator)]['Brain Correlation V2'].var()\n",
    "        iteration_val_v3 = sample[(df['Sample Indicator'] == sample_indicator)]['Brain Correlation V3'].var()\n",
    "        iteration_val_v4 = sample[(df['Sample Indicator'] == sample_indicator)]['Brain Correlation V4'].var()\n",
    "        iteration_val_hv = sample[(df['Sample Indicator'] == sample_indicator)]['Brain Correlation Higher Visual'].var()\n",
    "        iteration_val_nsd = sample[(df['Sample Indicator'] == sample_indicator)]['Brain Correlation NSD General'].var()\n",
    "        \n",
    "        v1[sample_indicator].append(iteration_val_v1)\n",
    "        v2[sample_indicator].append(iteration_val_v2)\n",
    "        v3[sample_indicator].append(iteration_val_v3)\n",
    "        v4[sample_indicator].append(iteration_val_v4)\n",
    "        hv[sample_indicator].append(iteration_val_hv)\n",
    "        nsd[sample_indicator].append(iteration_val_nsd)\n",
    "    \n",
    "# for sample_indicator, variance_list in v1.items():\n",
    "#         brain_correlation_V1.append(sum(variance_list) / len(variance_list))\n",
    "#         brain_correlation_V2.append(sum(v2[sample_indicator]) / len(v2[sample_indicator]))\n",
    "#         brain_correlation_V3.append(sum(v3[sample_indicator]) / len(v3[sample_indicator]))\n",
    "#         brain_correlation_V4.append(sum(v4[sample_indicator]) / len(v4[sample_indicator]))\n",
    "#         brain_correlation_HV.append(sum(hv[sample_indicator]) / len(hv[sample_indicator]))\n",
    "#         brain_correlation_NSD.append(sum(nsd[sample_indicator]) / len(nsd[sample_indicator]))\n",
    "\n",
    "for sample_indicator, variance_list in v1.items():\n",
    "        brain_correlation_V1.append(variance_list)\n",
    "        brain_correlation_V2.append(v2[sample_indicator])\n",
    "        brain_correlation_V3.append(v3[sample_indicator])\n",
    "        brain_correlation_V4.append(v4[sample_indicator])\n",
    "        brain_correlation_HV.append(hv[sample_indicator])\n",
    "        brain_correlation_NSD.append(nsd[sample_indicator])\n",
    "        \n",
    "# fig, axs = plt.subplots()\n",
    "\n",
    "\n",
    "\n",
    "# axs.scatter(x, brain_correlation_V1)\n",
    "# scatter_nsd = { \"labels\": [\"vdvae\", \"clip\", \"clip+\\nvdvae\", \"iter 0\", \"iter 1\", \"iter 2\", \"iter 3\", \"iter 4\", \"iter 5\"], \n",
    "#                 \"correlation\":  brain_correlation_NSD}\n",
    "\n",
    "df_data = pd.DataFrame(columns = ['Search Iterations', 'Brain Area', 'Variance Of Brain Correlation'])\n",
    "\n",
    "stage_labels = [\"VDVAE\", \"CLIP\", \"CLIP+VDVAE\", \"Iteration 0\", \"Iteration 1\", \"Iteration 2\", \"Iteration 3\", \"Iteration 4\", \"Iteration 5\", ]\n",
    "brain_areas = [v1, v2, v3, v4, hv, nsd]\n",
    "brain_area_labels = [\"V1\", \"V2\", \"V3\", \"V4\", \"Higher\\nVisual\", \"NSD\\nGeneral\"]\n",
    "\n",
    "df_row_num = 0\n",
    "for brain_area, label in zip(brain_areas, brain_area_labels):\n",
    "        for s, stage in enumerate([2, 1, 3, 4, 5, 6, 7, 8, 9]):\n",
    "                # print(brain_area[stage])\n",
    "                for i in tqdm(range(len(brain_area[stage]))):\n",
    "                        row = pd.DataFrame({'Search Iterations' : stage_labels[s], 'Brain Area' : label, 'Variance Of Brain Correlation' : brain_area[stage][i]}, index=[df_row_num])\n",
    "                        df_data = pd.concat([df_data, row])\n",
    "                        df_row_num += 1\n",
    "df_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(df_data.tail())\n",
    "custom_palette = [\"#e3342f\", \"#f6993f\", \"#ffed4a\", \"#38c172\", \"#4dc0b5\", \"#3490dc\", \"#6574cd\", \"#9561e2\", \"#f66d9b\"]\n",
    "\n",
    "# sns.set_palette(custom_palette)\n",
    "# sns.catplot(data=df_data, x=\"Brain Area\", y=\"Variance Of Brain Correlation\", hue=\"Search Iterations\", s=5).set(title='Variance Of Brain Correlation Across Iterations')\n",
    "# sns.barplot(data=df_data, x=\"Brain Area\", y=\"Variance Of Brain Correlation\", hue=\"Search Iterations\").set(title='Variance Of Brain Correlation Across Iterations')\n",
    "x = brain_area_labels\n",
    "x_axis = np.arange(len(x))\n",
    "\n",
    "n = 6\n",
    "r = np.arange(n)\n",
    "width = 0.10\n",
    "print(df_data.loc[df_data[\"Search Iterations\"] == \"VDVAE\"].groupby([\"Brain Area\"]).mean())\n",
    "vdvae = df_data.loc[df_data[\"Search Iterations\"] == \"VDVAE\"].groupby([\"Brain Area\"]).mean()[\"Variance Of Brain Correlation\"]\n",
    "plt.bar(r - width * 4, vdvae[2:].append(vdvae[0:2]), color = '#e3342f',\n",
    "        width = width, edgecolor = 'black',\n",
    "        label='VDVAE')\n",
    "clip = df_data.loc[df_data[\"Search Iterations\"] == \"CLIP\"].groupby([\"Brain Area\"]).mean()[\"Variance Of Brain Correlation\"]\n",
    "plt.bar(r - width * 3, clip[2:].append(clip[0:2]), color = '#f6993f',\n",
    "        width = width, edgecolor = 'black',\n",
    "        label='CLIP')\n",
    "cv = df_data.loc[df_data[\"Search Iterations\"] == \"CLIP+VDVAE\"].groupby([\"Brain Area\"]).mean()[\"Variance Of Brain Correlation\"]\n",
    "plt.bar(r - width * 2, cv[2:].append(cv[0:2]), color = '#ffed4a',\n",
    "        width = width, edgecolor = 'black',\n",
    "        label='CLIP+VDVAE')\n",
    "i0 = df_data.loc[df_data[\"Search Iterations\"] == \"Iteration 0\"].groupby([\"Brain Area\"]).mean()[\"Variance Of Brain Correlation\"]\n",
    "plt.bar(r - width, i0[2:].append(i0[0:2]), color = '#38c172',\n",
    "        width = width, edgecolor = 'black',\n",
    "        label='Iteration 0')\n",
    "i1 = df_data.loc[df_data[\"Search Iterations\"] == \"Iteration 1\"].groupby([\"Brain Area\"]).mean()[\"Variance Of Brain Correlation\"]\n",
    "plt.bar(r, i1[2:].append(i1[0:2]), color = '#4dc0b5',\n",
    "        width = width, edgecolor = 'black',\n",
    "        label='Iteration 1')\n",
    "i2 = df_data.loc[df_data[\"Search Iterations\"] == \"Iteration 2\"].groupby([\"Brain Area\"]).mean()[\"Variance Of Brain Correlation\"]\n",
    "plt.bar(r + width, i2[2:].append(i2[0:2]), color = '#3490dc',\n",
    "        width = width, edgecolor = 'black',\n",
    "        label='Iteration 2')\n",
    "i3 = df_data.loc[df_data[\"Search Iterations\"] == \"Iteration 3\"].groupby([\"Brain Area\"]).mean()[\"Variance Of Brain Correlation\"]\n",
    "plt.bar(r + width * 2, i3[2:].append(i3[0:2]), color = '#6574cd',\n",
    "        width = width, edgecolor = 'black',\n",
    "        label='Iteration 3')\n",
    "i4 = df_data.loc[df_data[\"Search Iterations\"] == \"Iteration 4\"].groupby([\"Brain Area\"]).mean()[\"Variance Of Brain Correlation\"]\n",
    "plt.bar(r + width * 3, i4[2:].append(i4[0:2]), color = '#9561e2',\n",
    "        width = width, edgecolor = 'black',\n",
    "        label='Iteration 4')\n",
    "i5 = df_data.loc[df_data[\"Search Iterations\"] == \"Iteration 5\"].groupby([\"Brain Area\"]).mean()[\"Variance Of Brain Correlation\"]\n",
    "plt.bar(r + width * 4, i5[2:].append(i5[0:2]), color = '#f66d9b',\n",
    "        width = width, edgecolor = 'black',\n",
    "        label='Iteration 5')\n",
    "\n",
    "plt.xticks(x_axis, x)\n",
    "plt.xlabel(\"Brain Areas\")\n",
    "plt.ylabel(\"Variance Of Brain Correlation Across Sample Distributions\")\n",
    "plt.title(\"Convergence of Image Distribution Variance Across Iterations\")\n",
    "#plt.xlim(897)\n",
    "plt.legend(fontsize = \"x-small\")\n",
    "mpl.rcParams['figure.dpi'] = 500\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SS_vd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
