{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"3\"\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "from PIL import Image\n",
    "sys.path.append('../src')\n",
    "from utils import *\n",
    "from matplotlib.lines import Line2D\n",
    "import matplotlib as mpl\n",
    "import math\n",
    "import matplotlib.image as mpimg\n",
    "import scipy.stats as stats\n",
    "import scipy as sp\n",
    "from scipy.stats import pearsonr,binom,linregress\n",
    "from ast import literal_eval\n",
    "import json\n",
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/export/raid1/home/kneel027/SS_release_test/Second-Sight\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ID</th>\n",
       "      <th>Sample Count</th>\n",
       "      <th>Batch Number</th>\n",
       "      <th>Search Reconstruction</th>\n",
       "      <th>Sample Indicator</th>\n",
       "      <th>Strength</th>\n",
       "      <th>Brain Correlation V1</th>\n",
       "      <th>Brain Correlation V2</th>\n",
       "      <th>Brain Correlation V3</th>\n",
       "      <th>...</th>\n",
       "      <th>SSIM</th>\n",
       "      <th>Pixel Correlation</th>\n",
       "      <th>CLIP Cosine</th>\n",
       "      <th>CLIP Two-way</th>\n",
       "      <th>AlexNet 2</th>\n",
       "      <th>AlexNet 5</th>\n",
       "      <th>AlexNet 7</th>\n",
       "      <th>Inception V3</th>\n",
       "      <th>EffNet-B</th>\n",
       "      <th>SwAV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>0.918611</td>\n",
       "      <td>0.373894</td>\n",
       "      <td>0.428574</td>\n",
       "      <td>0.522060</td>\n",
       "      <td>...</td>\n",
       "      <td>0.181485</td>\n",
       "      <td>0.115508</td>\n",
       "      <td>0.652058</td>\n",
       "      <td>[0.43661755323410034, -1.005650520324707, -0.5...</td>\n",
       "      <td>[2.872708797454834, 8.253482818603516, 0.0, 0....</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.91883397...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.3690766096115112, 0.0, ...</td>\n",
       "      <td>[0.46338289976119995, 0.7589036226272583, 0.18...</td>\n",
       "      <td>[0.021151425316929817, -0.14677444100379944, 0...</td>\n",
       "      <td>[0.043018847703933716, 0.0, 0.0865664333105087...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>0.908889</td>\n",
       "      <td>0.422158</td>\n",
       "      <td>0.430566</td>\n",
       "      <td>0.504478</td>\n",
       "      <td>...</td>\n",
       "      <td>0.172833</td>\n",
       "      <td>0.089730</td>\n",
       "      <td>0.661864</td>\n",
       "      <td>[0.19772468507289886, -0.32778337597846985, -0...</td>\n",
       "      <td>[5.443624019622803, 13.570717811584473, 4.5498...</td>\n",
       "      <td>[0.0, 1.4836602210998535, 1.5460149049758911, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.9203693866729736, 0.0, ...</td>\n",
       "      <td>[0.9685760140419006, 3.4280145168304443, 0.001...</td>\n",
       "      <td>[-0.044859036803245544, 0.11381707340478897, 0...</td>\n",
       "      <td>[0.014033572748303413, 0.012402824126183987, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>0.882500</td>\n",
       "      <td>0.388780</td>\n",
       "      <td>0.450544</td>\n",
       "      <td>0.510724</td>\n",
       "      <td>...</td>\n",
       "      <td>0.175452</td>\n",
       "      <td>0.105054</td>\n",
       "      <td>0.612023</td>\n",
       "      <td>[0.34995734691619873, -0.7877557277679443, -0....</td>\n",
       "      <td>[6.258691310882568, 6.027541637420654, 0.45524...</td>\n",
       "      <td>[1.861871600151062, 0.0, 0.0, 0.0, 0.074773885...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.6498057842254639, 0.0, ...</td>\n",
       "      <td>[0.28058287501335144, 1.0047184228897095, 0.60...</td>\n",
       "      <td>[-0.13359783589839935, 0.19642072916030884, -0...</td>\n",
       "      <td>[0.023465173318982124, 0.04109741747379303, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>0.831111</td>\n",
       "      <td>0.411638</td>\n",
       "      <td>0.459068</td>\n",
       "      <td>0.536323</td>\n",
       "      <td>...</td>\n",
       "      <td>0.182714</td>\n",
       "      <td>0.128794</td>\n",
       "      <td>0.574789</td>\n",
       "      <td>[0.23754540085792542, -1.1037744283676147, -0....</td>\n",
       "      <td>[11.881891250610352, 16.826887130737305, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.3526086807250...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.8773117065429688, 0.0, ...</td>\n",
       "      <td>[0.7504903078079224, 1.346362829208374, 1.0472...</td>\n",
       "      <td>[0.003517379518598318, 0.5518969893455505, -0....</td>\n",
       "      <td>[0.02298925817012787, 0.00690658763051033, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>0.746389</td>\n",
       "      <td>0.394691</td>\n",
       "      <td>0.434261</td>\n",
       "      <td>0.527971</td>\n",
       "      <td>...</td>\n",
       "      <td>0.182186</td>\n",
       "      <td>0.122617</td>\n",
       "      <td>0.598386</td>\n",
       "      <td>[0.5632207989692688, -0.48410147428512573, -0....</td>\n",
       "      <td>[3.2003591060638428, 8.982330322265625, 0.0, 0...</td>\n",
       "      <td>[0.0, 0.0, 0.029324963688850403, 0.0, 0.0, 0.0...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 2.4448952674865723, 0.0, ...</td>\n",
       "      <td>[0.3949286639690399, 3.3462138175964355, 0.909...</td>\n",
       "      <td>[-0.014685362577438354, 0.365490585565567, 0.0...</td>\n",
       "      <td>[0.019222676753997803, 0.022652314975857735, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>95</td>\n",
       "      <td>31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.381314</td>\n",
       "      <td>0.352266</td>\n",
       "      <td>0.164377</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[0.48707830905914307, -0.19986167550086975, 0....</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.3090217411518097, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.33104971051216125, 0.31409916281700134, 1.0...</td>\n",
       "      <td>[0.17818030714988708, -0.1290467083454132, -0....</td>\n",
       "      <td>[0.000877094513271004, 0.1436905711889267, 0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>96</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>0.918611</td>\n",
       "      <td>0.336596</td>\n",
       "      <td>0.251304</td>\n",
       "      <td>0.404760</td>\n",
       "      <td>...</td>\n",
       "      <td>0.248908</td>\n",
       "      <td>0.169997</td>\n",
       "      <td>0.747890</td>\n",
       "      <td>[0.0036671534180641174, 0.4536561667919159, -0...</td>\n",
       "      <td>[1.0629273653030396, 0.0, 0.0, 3.7116885185241...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.5056215524673462, 0.1692430078983307, 0.682...</td>\n",
       "      <td>[0.20980405807495117, -0.1476096361875534, 0.7...</td>\n",
       "      <td>[0.02666434645652771, 0.14612677693367004, 0.2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>97</td>\n",
       "      <td>32</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>0.908889</td>\n",
       "      <td>0.324132</td>\n",
       "      <td>0.281900</td>\n",
       "      <td>0.395840</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247311</td>\n",
       "      <td>0.160058</td>\n",
       "      <td>0.747920</td>\n",
       "      <td>[0.3544885516166687, 0.45907852053642273, -0.3...</td>\n",
       "      <td>[1.501020908355713, 1.0521879196166992, 0.4385...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.6064406633377075, 0.3948753774166107, 0.577...</td>\n",
       "      <td>[0.2717445194721222, -0.1022711917757988, 0.53...</td>\n",
       "      <td>[0.006357258651405573, 0.10711143910884857, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>98</td>\n",
       "      <td>32</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>0.882500</td>\n",
       "      <td>0.305529</td>\n",
       "      <td>0.263049</td>\n",
       "      <td>0.369766</td>\n",
       "      <td>...</td>\n",
       "      <td>0.236683</td>\n",
       "      <td>0.170535</td>\n",
       "      <td>0.763308</td>\n",
       "      <td>[0.09962234646081924, -0.06865456700325012, -0...</td>\n",
       "      <td>[1.3539286851882935, 1.3700554370880127, 0.486...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 2.469965934753418, 0.0, 0.0, 0.0, 0...</td>\n",
       "      <td>[0.6843758225440979, 0.08326787501573563, 0.33...</td>\n",
       "      <td>[0.23927615582942963, -0.12482064962387085, 0....</td>\n",
       "      <td>[0.0, 0.1217353492975235, 0.08148746937513351,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>99</td>\n",
       "      <td>32</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>0.831111</td>\n",
       "      <td>0.383745</td>\n",
       "      <td>0.334639</td>\n",
       "      <td>0.429346</td>\n",
       "      <td>...</td>\n",
       "      <td>0.240052</td>\n",
       "      <td>0.142930</td>\n",
       "      <td>0.774534</td>\n",
       "      <td>[0.1426590532064438, -0.10130319744348526, -0....</td>\n",
       "      <td>[0.5698928236961365, 0.5994055867195129, 0.171...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.7075230479240417, 0.23054617643356323, 0.32...</td>\n",
       "      <td>[0.2465817779302597, -0.10121909528970718, 0.7...</td>\n",
       "      <td>[0.0, 0.16727447509765625, 0.2211829572916031,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0  ID  Sample Count  Batch Number  Search Reconstruction  \\\n",
       "0            0  20           0.0           NaN                    NaN   \n",
       "1            1  20           1.0           NaN                    NaN   \n",
       "2            2  20           2.0           NaN                    NaN   \n",
       "3            3  20           3.0           NaN                    NaN   \n",
       "4            4  20           4.0           NaN                    NaN   \n",
       "..         ...  ..           ...           ...                    ...   \n",
       "95          95  31           NaN           NaN                    NaN   \n",
       "96          96  32           0.0           NaN                    NaN   \n",
       "97          97  32           1.0           NaN                    NaN   \n",
       "98          98  32           2.0           NaN                    NaN   \n",
       "99          99  32           3.0           NaN                    NaN   \n",
       "\n",
       "    Sample Indicator  Strength  Brain Correlation V1  Brain Correlation V2  \\\n",
       "0                 10  0.918611              0.373894              0.428574   \n",
       "1                 10  0.908889              0.422158              0.430566   \n",
       "2                 10  0.882500              0.388780              0.450544   \n",
       "3                 10  0.831111              0.411638              0.459068   \n",
       "4                 10  0.746389              0.394691              0.434261   \n",
       "..               ...       ...                   ...                   ...   \n",
       "95                 0       NaN              0.381314              0.352266   \n",
       "96                10  0.918611              0.336596              0.251304   \n",
       "97                10  0.908889              0.324132              0.281900   \n",
       "98                10  0.882500              0.305529              0.263049   \n",
       "99                10  0.831111              0.383745              0.334639   \n",
       "\n",
       "    Brain Correlation V3  ...      SSIM  Pixel Correlation  CLIP Cosine  \\\n",
       "0               0.522060  ...  0.181485           0.115508     0.652058   \n",
       "1               0.504478  ...  0.172833           0.089730     0.661864   \n",
       "2               0.510724  ...  0.175452           0.105054     0.612023   \n",
       "3               0.536323  ...  0.182714           0.128794     0.574789   \n",
       "4               0.527971  ...  0.182186           0.122617     0.598386   \n",
       "..                   ...  ...       ...                ...          ...   \n",
       "95              0.164377  ...       NaN                NaN     1.000000   \n",
       "96              0.404760  ...  0.248908           0.169997     0.747890   \n",
       "97              0.395840  ...  0.247311           0.160058     0.747920   \n",
       "98              0.369766  ...  0.236683           0.170535     0.763308   \n",
       "99              0.429346  ...  0.240052           0.142930     0.774534   \n",
       "\n",
       "                                         CLIP Two-way  \\\n",
       "0   [0.43661755323410034, -1.005650520324707, -0.5...   \n",
       "1   [0.19772468507289886, -0.32778337597846985, -0...   \n",
       "2   [0.34995734691619873, -0.7877557277679443, -0....   \n",
       "3   [0.23754540085792542, -1.1037744283676147, -0....   \n",
       "4   [0.5632207989692688, -0.48410147428512573, -0....   \n",
       "..                                                ...   \n",
       "95  [0.48707830905914307, -0.19986167550086975, 0....   \n",
       "96  [0.0036671534180641174, 0.4536561667919159, -0...   \n",
       "97  [0.3544885516166687, 0.45907852053642273, -0.3...   \n",
       "98  [0.09962234646081924, -0.06865456700325012, -0...   \n",
       "99  [0.1426590532064438, -0.10130319744348526, -0....   \n",
       "\n",
       "                                            AlexNet 2  \\\n",
       "0   [2.872708797454834, 8.253482818603516, 0.0, 0....   \n",
       "1   [5.443624019622803, 13.570717811584473, 4.5498...   \n",
       "2   [6.258691310882568, 6.027541637420654, 0.45524...   \n",
       "3   [11.881891250610352, 16.826887130737305, 0.0, ...   \n",
       "4   [3.2003591060638428, 8.982330322265625, 0.0, 0...   \n",
       "..                                                ...   \n",
       "95  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "96  [1.0629273653030396, 0.0, 0.0, 3.7116885185241...   \n",
       "97  [1.501020908355713, 1.0521879196166992, 0.4385...   \n",
       "98  [1.3539286851882935, 1.3700554370880127, 0.486...   \n",
       "99  [0.5698928236961365, 0.5994055867195129, 0.171...   \n",
       "\n",
       "                                            AlexNet 5  \\\n",
       "0   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.91883397...   \n",
       "1   [0.0, 1.4836602210998535, 1.5460149049758911, ...   \n",
       "2   [1.861871600151062, 0.0, 0.0, 0.0, 0.074773885...   \n",
       "3   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.3526086807250...   \n",
       "4   [0.0, 0.0, 0.029324963688850403, 0.0, 0.0, 0.0...   \n",
       "..                                                ...   \n",
       "95  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "96  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "97  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "98  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "99  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "                                            AlexNet 7  \\\n",
       "0   [0.0, 0.0, 0.0, 0.0, 1.3690766096115112, 0.0, ...   \n",
       "1   [0.0, 0.0, 0.0, 0.0, 1.9203693866729736, 0.0, ...   \n",
       "2   [0.0, 0.0, 0.0, 0.0, 1.6498057842254639, 0.0, ...   \n",
       "3   [0.0, 0.0, 0.0, 0.0, 1.8773117065429688, 0.0, ...   \n",
       "4   [0.0, 0.0, 0.0, 0.0, 2.4448952674865723, 0.0, ...   \n",
       "..                                                ...   \n",
       "95  [0.0, 0.0, 0.3090217411518097, 0.0, 0.0, 0.0, ...   \n",
       "96  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "97  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "98  [0.0, 0.0, 2.469965934753418, 0.0, 0.0, 0.0, 0...   \n",
       "99  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "                                         Inception V3  \\\n",
       "0   [0.46338289976119995, 0.7589036226272583, 0.18...   \n",
       "1   [0.9685760140419006, 3.4280145168304443, 0.001...   \n",
       "2   [0.28058287501335144, 1.0047184228897095, 0.60...   \n",
       "3   [0.7504903078079224, 1.346362829208374, 1.0472...   \n",
       "4   [0.3949286639690399, 3.3462138175964355, 0.909...   \n",
       "..                                                ...   \n",
       "95  [0.33104971051216125, 0.31409916281700134, 1.0...   \n",
       "96  [0.5056215524673462, 0.1692430078983307, 0.682...   \n",
       "97  [0.6064406633377075, 0.3948753774166107, 0.577...   \n",
       "98  [0.6843758225440979, 0.08326787501573563, 0.33...   \n",
       "99  [0.7075230479240417, 0.23054617643356323, 0.32...   \n",
       "\n",
       "                                             EffNet-B  \\\n",
       "0   [0.021151425316929817, -0.14677444100379944, 0...   \n",
       "1   [-0.044859036803245544, 0.11381707340478897, 0...   \n",
       "2   [-0.13359783589839935, 0.19642072916030884, -0...   \n",
       "3   [0.003517379518598318, 0.5518969893455505, -0....   \n",
       "4   [-0.014685362577438354, 0.365490585565567, 0.0...   \n",
       "..                                                ...   \n",
       "95  [0.17818030714988708, -0.1290467083454132, -0....   \n",
       "96  [0.20980405807495117, -0.1476096361875534, 0.7...   \n",
       "97  [0.2717445194721222, -0.1022711917757988, 0.53...   \n",
       "98  [0.23927615582942963, -0.12482064962387085, 0....   \n",
       "99  [0.2465817779302597, -0.10121909528970718, 0.7...   \n",
       "\n",
       "                                                 SwAV  \n",
       "0   [0.043018847703933716, 0.0, 0.0865664333105087...  \n",
       "1   [0.014033572748303413, 0.012402824126183987, 0...  \n",
       "2   [0.023465173318982124, 0.04109741747379303, 0....  \n",
       "3   [0.02298925817012787, 0.00690658763051033, 0.0...  \n",
       "4   [0.019222676753997803, 0.022652314975857735, 0...  \n",
       "..                                                ...  \n",
       "95  [0.000877094513271004, 0.1436905711889267, 0.1...  \n",
       "96  [0.02666434645652771, 0.14612677693367004, 0.2...  \n",
       "97  [0.006357258651405573, 0.10711143910884857, 0....  \n",
       "98  [0.0, 0.1217353492975235, 0.08148746937513351,...  \n",
       "99  [0.0, 0.16727447509765625, 0.2211829572916031,...  \n",
       "\n",
       "[100 rows x 24 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Used in CCN\n",
    "# folder   = \"SCS UC 10:250:5 0.6 Exp3 AE Fixed copy\"\n",
    "# log_path = \"/export/raid1/home/kneel027/Second-Sight/logs/\" + folder + \"/statistics_df_60.csv\"\n",
    "\n",
    "print(os.getcwd())\n",
    "# Second Sight\n",
    "subject = 1\n",
    "folder = \"dataframes\"\n",
    "# experiment = \"Brain Diffuser regen\"\n",
    "# experiment = \"Cortical Convolutions\"\n",
    "# experiment = \"Mind Diffuser\"\n",
    "# experiment = \"Tagaki\"\n",
    "# experiment = \"Final Run: SCS UC LD 6:100:4 Dual Guided clip_iter_only_brain_correlation\"\n",
    "# experiment = \"Final Run: SCS UC LD 6:100:4 Dual Guided clip_iter\"\n",
    "# experiment = \"iter_5\"\n",
    "# directory_path = \"/export/raid1/home/ojeda040/Second-Sight-Archive/reconstructions/subject\" + str(subject) + \"/\" + folder + \"/statistics_df_\" + experiment + \"_only_brain_correlation_897.csv\"\n",
    "experiment = \"noae_3\"\n",
    "directory_path = \"output/dataframes/{}/subject{}/statistics_df_{}_897.csv\".format(experiment, subject, experiment)\n",
    "# directory_path = \"output/dataframes/{}/subject{}/statistics_df_{}_105_new_bp.csv\".format(experiment, subject, experiment)\n",
    "# pd.set_option(\"display.max_columns\", None)\n",
    "# pd.set_option(\"display.max_rows\", None)\n",
    "# pd.set_option('display.max_seq_items', None)\n",
    "df = pd.read_csv(directory_path)\n",
    "df.head(100)\n",
    "\n",
    "# experiment = \"Final Run: SCS UC LD 6:100:4 Dual Guided clip_iter_done\"\n",
    "# directory_path2 = \"/export/raid1/home/ojeda040/Second-Sight-Archive/reconstructions/subject\" + str(subject) + \"/\" + folder + \"/statistics_df_\" + experiment2 + \"_897.csv\"\n",
    "\n",
    "# df2 = pd.read_csv(directory_path2)\n",
    "\n",
    "#   0 --> Ground Truth\n",
    "#   1 --> VDVAE Distribution        (Decoded Distribution)\n",
    "#   2 --> Clip Distrubituon         (Decoded CLIP Only)\n",
    "#   3 --> Clip Distrubituon + VDVAE (Decoded CLIP + VDVAE)\n",
    "#   4 --> iter_0\n",
    "#   5 --> iter_1\n",
    "#   6 --> iter_2\n",
    "#   7 --> iter_3\n",
    "#   8 --> iter_4\n",
    "#   9 --> iter_5\n",
    "#  10 --> Search Reconstruction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "creating lists: 7176it [03:55, 30.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Create CNN metric columns into lists (Only run if computing CNN Metrics)\n",
    "\n",
    "def column_string_to_list(df):\n",
    "    df_new = df\n",
    "    \n",
    "    for index, row in tqdm(df.iterrows(), \"creating lists\"):\n",
    "        \n",
    "        df_new.at[index, 'CLIP Two-way']    = json.loads(row['CLIP Two-way'])\n",
    "        df_new.at[index, 'AlexNet 2']       = json.loads(row['AlexNet 2'])\n",
    "        df_new.at[index, 'AlexNet 5']       = json.loads(row['AlexNet 5'])\n",
    "        df_new.at[index, 'AlexNet 7']       = json.loads(row['AlexNet 7'])\n",
    "        df_new.at[index, 'Inception V3']    = json.loads(row['Inception V3'])\n",
    "        df_new.at[index, 'EffNet-B']        = json.loads(row['EffNet-B'])\n",
    "        df_new.at[index, 'SwAV']            = json.loads(row['SwAV'])\n",
    "        \n",
    "    return df_new\n",
    "\n",
    "new_df = column_string_to_list(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 7\n",
      "897 897 897\n",
      "897 897 897\n",
      "897 897 897\n",
      "897 897 897\n",
      "897 897 897\n",
      "7 7\n",
      "897 897 897\n",
      "897 897 897\n",
      "897 897 897\n",
      "897 897 897\n",
      "897 897 897\n",
      "7 7\n",
      "897 897 897\n",
      "897 897 897\n",
      "897 897 897\n",
      "897 897 897\n",
      "897 897 897\n",
      "7 7\n",
      "897 897 897\n",
      "897 897 897\n",
      "897 897 897\n",
      "897 897 897\n",
      "897 897 897\n",
      "7 7\n",
      "897 897 897\n",
      "897 897 897\n",
      "897 897 897\n",
      "897 897 897\n",
      "897 897 897\n",
      "------------------------------------------------ SSIM -----------------------------------------------------------------\n",
      "SSIM:  0.28016341675696765\n",
      "Confidence Interval SSIM:  0.004333365435317979\n",
      "------------------------------------------------ Pixel Correlation -----------------------------------------------------------------\n",
      "Pixel Correlation:  0.17752551614787068\n",
      "Confidence Interval Pixel Correlation:  0.005650835419457728\n",
      "------------------------------------------------ CLIP Cosine -----------------------------------------------------------------\n",
      "CLIP Cosine:  0.6440945146836566\n",
      "Confidence Interval CLIP Cosine:  0.003593675852161938\n",
      "------------------------------------------------ CLIP Two-way -----------------------------------------------------------------\n",
      "CLIP Two-way:  0.8554079073100812\n",
      "------------------------------------------------ AlexNet 2 -----------------------------------------------------------------\n",
      "AlexNet 2:  0.9147085025481765\n",
      "------------------------------------------------ AlexNet 5 -----------------------------------------------------------------\n",
      "AlexNet 5:  0.9305935459468069\n",
      "------------------------------------------------ AlexNet 7 -----------------------------------------------------------------\n",
      "AlexNet 7:  0.9136847527472527\n",
      "------------------------------------------------ Inception V3 -----------------------------------------------------------------\n",
      "Inception V3:  0.8088982122949513\n",
      "------------------------------------------------ EffNet-B -----------------------------------------------------------------\n",
      "EffNet-B:  0.797999624139293\n",
      "------------------------------------------------ SwAV -----------------------------------------------------------------\n",
      "SwAV:  0.4421338886305074\n",
      "0.804362756808409\n"
     ]
    }
   ],
   "source": [
    "# Statistical Analysis Second Sight\n",
    "\n",
    "# Input: Dataframe containing the samples one type of image\n",
    "def create_cnn_numpy_array(df):\n",
    "    cnn_dict = {}\n",
    "    df = df.reset_index()\n",
    "    \n",
    "    alexnet_2       = []\n",
    "    alexnet_5       = []\n",
    "    alexnet_7       = []\n",
    "    clip_two_way    = []\n",
    "    inception_v3    = []\n",
    "    effnet_b        = []\n",
    "    swav            = []\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        \n",
    "        alexnet_2.append(row['AlexNet 2'])\n",
    "        alexnet_5.append(np.array(row['AlexNet 5']))\n",
    "        alexnet_7.append(np.array(row['AlexNet 7']))\n",
    "        clip_two_way.append(np.array(row['CLIP Two-way']))\n",
    "        inception_v3.append(np.array(row['Inception V3']))\n",
    "        effnet_b.append(np.array(row['EffNet-B']))\n",
    "        swav.append(np.array(row['SwAV']))\n",
    "    \n",
    "    cnn_dict['AlexNet 2']      = np.concatenate([alexnet_2])\n",
    "    cnn_dict['AlexNet 5']      = np.concatenate([alexnet_5])\n",
    "    cnn_dict['AlexNet 7']      = np.concatenate([alexnet_7])\n",
    "    cnn_dict['CLIP Two-way']   = np.concatenate([clip_two_way])\n",
    "    cnn_dict['Inception V3']   = np.concatenate([inception_v3])\n",
    "    cnn_dict['EffNet-B']       = np.concatenate([effnet_b])\n",
    "    cnn_dict['SwAV']           = np.concatenate([swav])\n",
    "    # print(cnn_dict['AlexNet 2'])\n",
    "    return cnn_dict\n",
    "\n",
    "def pairwise_corr_all(ground_truth, predictions):\n",
    "    r = np.corrcoef(ground_truth, predictions)      #cosine_similarity(ground_truth, predictions)#\n",
    "    r = r[:len(ground_truth), len(ground_truth):]   # rows: groundtruth, columns: predicitons\n",
    "    \n",
    "    # congruent pairs are on diagonal\n",
    "    congruents = np.diag(r)\n",
    "    \n",
    "    # for each column (predicition) we should count the number of rows (groundtruth) \n",
    "    # that the value is lower than the congruent (e.g. success).\n",
    "    success = r < congruents\n",
    "    success_cnt = np.sum(success, 0)\n",
    "    \n",
    "    # note: diagonal of 'success' is always zero so we can discard it. That's why we divide by len-1\n",
    "    perf = np.mean(success_cnt) / (len(ground_truth)-1)\n",
    "    p = 1 - binom.cdf(perf*len(ground_truth)*(len(ground_truth)-1), len(ground_truth)*(len(ground_truth)-1), 0.5)\n",
    "    \n",
    "    return perf, p\n",
    "\n",
    "def compute_cnn_metrics(cnn_metrics_ground_truth, cnn_metrics_reconstructions):\n",
    "    distance_fn = sp.spatial.distance.correlation\n",
    "    pairwise_corrs = []\n",
    "    cnn_metrics = {}\n",
    "    # print(cnn_metrics_reconstructions)\n",
    "    for net_name, predictions_np in cnn_metrics_reconstructions.items():\n",
    "        \n",
    "        gt_feat = cnn_metrics_ground_truth[net_name]\n",
    "        \n",
    "        eval_feat = predictions_np\n",
    "        num_test = predictions_np.shape[0]\n",
    "        # print(net_name, predictions_np.shape)\n",
    "        if net_name == 'EffNet-B' or net_name == 'SwAV':\n",
    "            cnn_metrics[net_name] = np.array([distance_fn(gt_feat[i],eval_feat[i]) for i in range(num_test)]).mean()\n",
    "            \n",
    "        else:\n",
    "            cnn_metrics[net_name] = pairwise_corr_all(gt_feat[:num_test],eval_feat[:num_test])[0]\n",
    "            \n",
    "    return cnn_metrics \n",
    "\n",
    "df_final_samples    = new_df.loc[(new_df['Sample Indicator'] == 10)]\n",
    "df_ground_truth     = new_df.loc[(new_df['Sample Indicator'] == 0)]\n",
    "df_final_samples_0  = df_final_samples.loc[(df_final_samples['Sample Count'] == 0)]\n",
    "df_final_samples_1  = df_final_samples.loc[(df_final_samples['Sample Count'] == 1)]\n",
    "df_final_samples_2  = df_final_samples.loc[(df_final_samples['Sample Count'] == 2)]\n",
    "df_final_samples_3  = df_final_samples.loc[(df_final_samples['Sample Count'] == 3)]\n",
    "df_final_samples_4  = df_final_samples.loc[(df_final_samples['Sample Count'] == 4)]\n",
    "\n",
    "\n",
    "cnn_metrics_0 = compute_cnn_metrics(create_cnn_numpy_array(df_ground_truth), create_cnn_numpy_array(df_final_samples_0))\n",
    "cnn_metrics_1 = compute_cnn_metrics(create_cnn_numpy_array(df_ground_truth), create_cnn_numpy_array(df_final_samples_1))\n",
    "cnn_metrics_2 = compute_cnn_metrics(create_cnn_numpy_array(df_ground_truth), create_cnn_numpy_array(df_final_samples_2))\n",
    "cnn_metrics_3 = compute_cnn_metrics(create_cnn_numpy_array(df_ground_truth), create_cnn_numpy_array(df_final_samples_3))\n",
    "cnn_metrics_4 = compute_cnn_metrics(create_cnn_numpy_array(df_ground_truth), create_cnn_numpy_array(df_final_samples_4))\n",
    "\n",
    "print(\"------------------------------------------------ SSIM -----------------------------------------------------------------\")\n",
    "\n",
    "print(\"SSIM: \", df_final_samples['SSIM'].mean())\n",
    "\n",
    "print(\"Confidence Interval SSIM: \", ((df_final_samples['SSIM'].std() * 1.96) / math.sqrt(len(df_final_samples.index))))\n",
    "\n",
    "print(\"------------------------------------------------ Pixel Correlation -----------------------------------------------------------------\")\n",
    "\n",
    "print(\"Pixel Correlation: \", df_final_samples['Pixel Correlation'].mean())\n",
    "\n",
    "print(\"Confidence Interval Pixel Correlation: \", ((df_final_samples['Pixel Correlation'].std() * 1.96) / math.sqrt(len(df_final_samples.index))))\n",
    "\n",
    "print(\"------------------------------------------------ CLIP Cosine -----------------------------------------------------------------\")\n",
    "\n",
    "print(\"CLIP Cosine: \", df_final_samples['CLIP Cosine'].mean())\n",
    "\n",
    "print(\"Confidence Interval CLIP Cosine: \", ((df_final_samples['CLIP Cosine'].std() * 1.96) / math.sqrt(len(df_final_samples.index))))\n",
    "\n",
    "print(\"------------------------------------------------ CLIP Two-way -----------------------------------------------------------------\")\n",
    "\n",
    "print(\"CLIP Two-way: \", ((cnn_metrics_0['CLIP Two-way'] + cnn_metrics_1['CLIP Two-way'] + cnn_metrics_2['CLIP Two-way'] + cnn_metrics_3['CLIP Two-way'] + cnn_metrics_4['CLIP Two-way']) / 5))\n",
    "\n",
    "print(\"------------------------------------------------ AlexNet 2 -----------------------------------------------------------------\")\n",
    "\n",
    "print(\"AlexNet 2: \", ((cnn_metrics_0['AlexNet 2'] + cnn_metrics_1['AlexNet 2'] + cnn_metrics_2['AlexNet 2'] + cnn_metrics_3['AlexNet 2'] + cnn_metrics_4['AlexNet 2']) / 5))\n",
    "\n",
    "print(\"------------------------------------------------ AlexNet 5 -----------------------------------------------------------------\")\n",
    "\n",
    "print(\"AlexNet 5: \", ((cnn_metrics_0['AlexNet 5'] + cnn_metrics_1['AlexNet 5'] + cnn_metrics_2['AlexNet 5'] + cnn_metrics_3['AlexNet 5'] + cnn_metrics_4['AlexNet 5']) / 5))\n",
    "\n",
    "print(\"------------------------------------------------ AlexNet 7 -----------------------------------------------------------------\")\n",
    "\n",
    "print(\"AlexNet 7: \", ((cnn_metrics_0['AlexNet 7'] + cnn_metrics_1['AlexNet 7'] + cnn_metrics_2['AlexNet 7'] + cnn_metrics_3['AlexNet 7'] + cnn_metrics_4['AlexNet 7']) / 5))\n",
    "\n",
    "print(\"------------------------------------------------ Inception V3 -----------------------------------------------------------------\")\n",
    "\n",
    "print(\"Inception V3: \", ((cnn_metrics_0['Inception V3'] + cnn_metrics_1['Inception V3'] + cnn_metrics_2['Inception V3'] + cnn_metrics_3['Inception V3'] + cnn_metrics_4['Inception V3']) / 5))\n",
    "\n",
    "print(\"------------------------------------------------ EffNet-B -----------------------------------------------------------------\")\n",
    "\n",
    "print(\"EffNet-B: \", ((cnn_metrics_0['EffNet-B'] + cnn_metrics_1['EffNet-B'] + cnn_metrics_2['EffNet-B'] + cnn_metrics_3['EffNet-B'] + cnn_metrics_4['EffNet-B']) / 5))\n",
    "\n",
    "print(\"------------------------------------------------ SwAV -----------------------------------------------------------------\")\n",
    "\n",
    "print(\"SwAV: \", ((cnn_metrics_0['SwAV'] + cnn_metrics_1['SwAV'] + cnn_metrics_2['SwAV'] + cnn_metrics_3['SwAV'] + cnn_metrics_4['SwAV']) / 5))\n",
    "\n",
    "print(cnn_metrics_0['Inception V3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = create_cnn_numpy_array(df_final_samples_2)\n",
    "gt = create_cnn_numpy_array(df_ground_truth)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(897,) (897,)\n"
     ]
    }
   ],
   "source": [
    "cnn = create_cnn_numpy_array(df_final_samples_0)\n",
    "gt = create_cnn_numpy_array(df_ground_truth)\n",
    "distance_fn = sp.spatial.distance.correlation\n",
    "\n",
    "effnet = np.array([distance_fn(gt['EffNet-B'][i],cnn['EffNet-B'][i]) for i in range(897)])\n",
    "swav = np.array([distance_fn(gt['SwAV'][i],cnn['SwAV'][i]) for i in range(897)])\n",
    "print(effnet.shape, swav.shape)\n",
    "# np.save(\"/home/naxos2-raid25/ojeda040/local/ojeda040/Second-Sight-Archive/reconstructions/subject1/dataframes/effnet_sample_0.npy\", effnet)\n",
    "# np.save(\"/home/naxos2-raid25/ojeda040/local/ojeda040/Second-Sight-Archive/reconstructions/subject1/dataframes/swav_sample_0.npy\", swav)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 7\n",
      "4485 897 4485\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (897,4485) (897,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/naxos2-raid25/kneel027/home/kneel027/SS_release_test/Second-Sight/src/prepare_figures.ipynb Cell 7\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bhypatia.cmrr.umn.edu/home/naxos2-raid25/kneel027/home/kneel027/SS_release_test/Second-Sight/src/prepare_figures.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m df_final_samples    \u001b[39m=\u001b[39m new_df\u001b[39m.\u001b[39mloc[(new_df[\u001b[39m'\u001b[39m\u001b[39mSample Indicator\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m10\u001b[39m)]\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bhypatia.cmrr.umn.edu/home/naxos2-raid25/kneel027/home/kneel027/SS_release_test/Second-Sight/src/prepare_figures.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m df_ground_truth     \u001b[39m=\u001b[39m new_df\u001b[39m.\u001b[39mloc[(new_df[\u001b[39m'\u001b[39m\u001b[39mSample Indicator\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m)]\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bhypatia.cmrr.umn.edu/home/naxos2-raid25/kneel027/home/kneel027/SS_release_test/Second-Sight/src/prepare_figures.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m cnn_metrics_0 \u001b[39m=\u001b[39m compute_cnn_metrics(create_cnn_numpy_array(df_ground_truth), create_cnn_numpy_array(df_final_samples))\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bhypatia.cmrr.umn.edu/home/naxos2-raid25/kneel027/home/kneel027/SS_release_test/Second-Sight/src/prepare_figures.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m------------------------------------------------ SSIM -----------------------------------------------------------------\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bhypatia.cmrr.umn.edu/home/naxos2-raid25/kneel027/home/kneel027/SS_release_test/Second-Sight/src/prepare_figures.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mSSIM: \u001b[39m\u001b[39m\"\u001b[39m, df_final_samples[\u001b[39m'\u001b[39m\u001b[39mSSIM\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mmean())\n",
      "\u001b[1;32m/home/naxos2-raid25/kneel027/home/kneel027/SS_release_test/Second-Sight/src/prepare_figures.ipynb Cell 7\u001b[0m line \u001b[0;36m7\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bhypatia.cmrr.umn.edu/home/naxos2-raid25/kneel027/home/kneel027/SS_release_test/Second-Sight/src/prepare_figures.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=69'>70</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bhypatia.cmrr.umn.edu/home/naxos2-raid25/kneel027/home/kneel027/SS_release_test/Second-Sight/src/prepare_figures.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=70'>71</a>\u001b[0m         \u001b[39mprint\u001b[39m(num_test, \u001b[39mlen\u001b[39m(gt_feat), \u001b[39mlen\u001b[39m(eval_feat))\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bhypatia.cmrr.umn.edu/home/naxos2-raid25/kneel027/home/kneel027/SS_release_test/Second-Sight/src/prepare_figures.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=71'>72</a>\u001b[0m         cnn_metrics[net_name] \u001b[39m=\u001b[39m pairwise_corr_all(gt_feat[:num_test],eval_feat[:num_test])[\u001b[39m0\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bhypatia.cmrr.umn.edu/home/naxos2-raid25/kneel027/home/kneel027/SS_release_test/Second-Sight/src/prepare_figures.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=73'>74</a>\u001b[0m \u001b[39mreturn\u001b[39;00m cnn_metrics\n",
      "\u001b[1;32m/home/naxos2-raid25/kneel027/home/kneel027/SS_release_test/Second-Sight/src/prepare_figures.ipynb Cell 7\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bhypatia.cmrr.umn.edu/home/naxos2-raid25/kneel027/home/kneel027/SS_release_test/Second-Sight/src/prepare_figures.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=40'>41</a>\u001b[0m congruents \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mdiag(r)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bhypatia.cmrr.umn.edu/home/naxos2-raid25/kneel027/home/kneel027/SS_release_test/Second-Sight/src/prepare_figures.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=42'>43</a>\u001b[0m \u001b[39m# for each column (predicition) we should count the number of rows (groundtruth) \u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bhypatia.cmrr.umn.edu/home/naxos2-raid25/kneel027/home/kneel027/SS_release_test/Second-Sight/src/prepare_figures.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=43'>44</a>\u001b[0m \u001b[39m# that the value is lower than the congruent (e.g. success).\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bhypatia.cmrr.umn.edu/home/naxos2-raid25/kneel027/home/kneel027/SS_release_test/Second-Sight/src/prepare_figures.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=44'>45</a>\u001b[0m success \u001b[39m=\u001b[39m r \u001b[39m<\u001b[39;49m congruents\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bhypatia.cmrr.umn.edu/home/naxos2-raid25/kneel027/home/kneel027/SS_release_test/Second-Sight/src/prepare_figures.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=45'>46</a>\u001b[0m success_cnt \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39msum(success, \u001b[39m0\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bhypatia.cmrr.umn.edu/home/naxos2-raid25/kneel027/home/kneel027/SS_release_test/Second-Sight/src/prepare_figures.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=47'>48</a>\u001b[0m \u001b[39m# note: diagonal of 'success' is always zero so we can discard it. That's why we divide by len-1\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (897,4485) (897,) "
     ]
    }
   ],
   "source": [
    "df_final_samples    = new_df.loc[(new_df['Sample Indicator'] == 10)]\n",
    "df_ground_truth     = new_df.loc[(new_df['Sample Indicator'] == 0)]\n",
    "\n",
    "cnn_metrics_0 = compute_cnn_metrics(create_cnn_numpy_array(df_ground_truth), create_cnn_numpy_array(df_final_samples))\n",
    "\n",
    "print(\"------------------------------------------------ SSIM -----------------------------------------------------------------\")\n",
    "\n",
    "print(\"SSIM: \", df_final_samples['SSIM'].mean())\n",
    "\n",
    "print(\"Confidence Interval SSIM: \", ((df_final_samples['SSIM'].std() * 1.96) / math.sqrt(len(df_final_samples.index))))\n",
    "\n",
    "print(\"------------------------------------------------ Pixel Correlation ----------------------------------------------------\")\n",
    "\n",
    "print(\"Pixel Correlation: \", df_final_samples['Pixel Correlation'].mean())\n",
    "\n",
    "print(\"Confidence Interval Pixel Correlation: \", ((df_final_samples['Pixel Correlation'].std() * 1.96) / math.sqrt(len(df_final_samples.index))))\n",
    "\n",
    "print(\"------------------------------------------------ CLIP Cosine ----------------------------------------------------------\")\n",
    "\n",
    "print(\"CLIP Cosine: \", df_final_samples['CLIP Cosine'].mean())\n",
    "\n",
    "print(\"Confidence Interval CLIP Cosine: \", ((df_final_samples['CLIP Cosine'].std() * 1.96) / math.sqrt(len(df_final_samples.index))))\n",
    "\n",
    "print(\"------------------------------------------------ CLIP Two-way ---------------------------------------------------------\")\n",
    "\n",
    "print(\"CLIP Two-way: \", ((cnn_metrics_0['CLIP Two-way'])))\n",
    "\n",
    "print(\"------------------------------------------------ AlexNet 2 ------------------------------------------------------------\")\n",
    "\n",
    "print(\"AlexNet 2: \", ((cnn_metrics_0['AlexNet 2'])))\n",
    "\n",
    "print(\"------------------------------------------------ AlexNet 5 ------------------------------------------------------------\")\n",
    "\n",
    "print(\"AlexNet 5: \", ((cnn_metrics_0['AlexNet 5'])))\n",
    "\n",
    "print(\"------------------------------------------------ AlexNet 7 ------------------------------------------------------------\")\n",
    "\n",
    "print(\"AlexNet 7: \", ((cnn_metrics_0['AlexNet 7'])))\n",
    "\n",
    "print(\"------------------------------------------------ Inception V3 ---------------------------------------------------------\")\n",
    "\n",
    "print(\"Inception V3: \", ((cnn_metrics_0['Inception V3'])))\n",
    "\n",
    "print(\"------------------------------------------------ EffNet-B -------------------------------------------------------------\")\n",
    "\n",
    "print(\"EffNet-B: \", ((cnn_metrics_0['EffNet-B'])))\n",
    "\n",
    "print(\"------------------------------------------------ SwAV -----------------------------------------------------------------\")\n",
    "\n",
    "print(\"SwAV: \", ((cnn_metrics_0['SwAV'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------ Brain Correlation V1 -----------------------------------------------------------------\n",
      "Brain Correlation V1:  0.411422317725485\n",
      "------------------------------------------------ Brain Correlation V2 -----------------------------------------------------------------\n",
      "Brain Correlation V2:  0.4221400028099665\n",
      "------------------------------------------------ Brain Correlation V3 -----------------------------------------------------------------\n",
      "Brain Correlation V3:  0.4290449373245931\n",
      "------------------------------------------------ Brain Correlation V4 -----------------------------------------------------------------\n",
      "Brain Correlation V4:  0.38279208359099215\n",
      "------------------------------------------------ Brain Correlation Early Visual -------------------------------------------------------\n",
      "Brain Correlation Early Visual:  0.42533246954231885\n",
      "------------------------------------------------ Brain Correlation Higher Visual -------------------------------------------------------\n",
      "Brain Correlation Higher Visual:  0.43019863714086953\n",
      "------------------------------------------------ Brain Correlation NSD General ---------------------------------------------------------\n",
      "Brain Correlation NSD General:  0.4478343396041025\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ID</th>\n",
       "      <th>Sample Count</th>\n",
       "      <th>Batch Number</th>\n",
       "      <th>Search Reconstruction</th>\n",
       "      <th>Sample Indicator</th>\n",
       "      <th>Strength</th>\n",
       "      <th>Brain Correlation V1</th>\n",
       "      <th>Brain Correlation V2</th>\n",
       "      <th>Brain Correlation V3</th>\n",
       "      <th>...</th>\n",
       "      <th>SSIM</th>\n",
       "      <th>Pixel Correlation</th>\n",
       "      <th>CLIP Cosine</th>\n",
       "      <th>CLIP Two-way</th>\n",
       "      <th>AlexNet 2</th>\n",
       "      <th>AlexNet 5</th>\n",
       "      <th>AlexNet 7</th>\n",
       "      <th>Inception V3</th>\n",
       "      <th>EffNet-B</th>\n",
       "      <th>SwAV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7144</th>\n",
       "      <td>7144</td>\n",
       "      <td>978</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>0.918611</td>\n",
       "      <td>0.697852</td>\n",
       "      <td>0.601204</td>\n",
       "      <td>0.590434</td>\n",
       "      <td>...</td>\n",
       "      <td>0.418114</td>\n",
       "      <td>0.694385</td>\n",
       "      <td>0.797669</td>\n",
       "      <td>[0.6176179051399231, 0.40136244893074036, -0.2...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.4665712118148804, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 1.4618737697601318, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.5133019685745239, 0.3083895146846771, 0.127...</td>\n",
       "      <td>[0.47903746366500854, -0.11704962700605392, 0....</td>\n",
       "      <td>[0.012201203964650631, 0.03682749718427658, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7145</th>\n",
       "      <td>7145</td>\n",
       "      <td>978</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>0.908889</td>\n",
       "      <td>0.679702</td>\n",
       "      <td>0.629572</td>\n",
       "      <td>0.572091</td>\n",
       "      <td>...</td>\n",
       "      <td>0.410238</td>\n",
       "      <td>0.709497</td>\n",
       "      <td>0.771735</td>\n",
       "      <td>[0.3076856732368469, 0.33915239572525024, -0.2...</td>\n",
       "      <td>[0.6485033631324768, 0.0, 0.0, 0.0, 0.0, 0.831...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 2.5993759632110596, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.25076383352279663, 0.2883766293525696, 0.01...</td>\n",
       "      <td>[0.008627716451883316, -0.1392345279455185, -0...</td>\n",
       "      <td>[0.0018427814356982708, 0.08204822987318039, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7146</th>\n",
       "      <td>7146</td>\n",
       "      <td>978</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>0.882500</td>\n",
       "      <td>0.710844</td>\n",
       "      <td>0.670913</td>\n",
       "      <td>0.585448</td>\n",
       "      <td>...</td>\n",
       "      <td>0.413547</td>\n",
       "      <td>0.732770</td>\n",
       "      <td>0.761996</td>\n",
       "      <td>[0.3415769040584564, 0.2298131287097931, 0.172...</td>\n",
       "      <td>[2.854987382888794, 1.653757929801941, 0.0, 1....</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 1.5158584117889404, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.5988375544548035, 0.49265187978744507, 0.47...</td>\n",
       "      <td>[-0.10010838508605957, -0.14901290833950043, -...</td>\n",
       "      <td>[0.005790903232991695, 0.19102318584918976, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7147</th>\n",
       "      <td>7147</td>\n",
       "      <td>978</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>0.831111</td>\n",
       "      <td>0.676744</td>\n",
       "      <td>0.601361</td>\n",
       "      <td>0.546082</td>\n",
       "      <td>...</td>\n",
       "      <td>0.417936</td>\n",
       "      <td>0.735371</td>\n",
       "      <td>0.823320</td>\n",
       "      <td>[0.48286956548690796, 0.11095590144395828, 0.1...</td>\n",
       "      <td>[1.1171984672546387, 0.0, 0.8008405566215515, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 2.4964704513549805, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.36786434054374695, 0.16114407777786255, 0.1...</td>\n",
       "      <td>[0.15536214411258698, -0.11582586169242859, -0...</td>\n",
       "      <td>[0.005720560438930988, 0.18248318135738373, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7148</th>\n",
       "      <td>7148</td>\n",
       "      <td>978</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>0.746389</td>\n",
       "      <td>0.700868</td>\n",
       "      <td>0.633899</td>\n",
       "      <td>0.571227</td>\n",
       "      <td>...</td>\n",
       "      <td>0.438841</td>\n",
       "      <td>0.734774</td>\n",
       "      <td>0.782487</td>\n",
       "      <td>[0.5468528270721436, 0.046814605593681335, 0.1...</td>\n",
       "      <td>[2.323309898376465, 0.39934027194976807, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 1.4566391706466675, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.2481999546289444, 0.3061738610267639, 0.126...</td>\n",
       "      <td>[0.0411347933113575, -0.13752640783786774, -0....</td>\n",
       "      <td>[0.0020285334903746843, 0.06923013925552368, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7152</th>\n",
       "      <td>7152</td>\n",
       "      <td>979</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>0.918611</td>\n",
       "      <td>0.621395</td>\n",
       "      <td>0.556997</td>\n",
       "      <td>0.534074</td>\n",
       "      <td>...</td>\n",
       "      <td>0.404265</td>\n",
       "      <td>0.527663</td>\n",
       "      <td>0.921468</td>\n",
       "      <td>[-0.8803311586380005, 0.177943155169487, 0.263...</td>\n",
       "      <td>[0.5660234689712524, 0.030195869505405426, 0.0...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 4.796745300292969, 0.0, 0.0, 0...</td>\n",
       "      <td>[0.36886462569236755, 0.1002252995967865, 0.02...</td>\n",
       "      <td>[-0.1549503356218338, -0.009874165989458561, 0...</td>\n",
       "      <td>[0.03400035575032234, 0.07987703382968903, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7153</th>\n",
       "      <td>7153</td>\n",
       "      <td>979</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>0.908889</td>\n",
       "      <td>0.648300</td>\n",
       "      <td>0.588521</td>\n",
       "      <td>0.521875</td>\n",
       "      <td>...</td>\n",
       "      <td>0.388970</td>\n",
       "      <td>0.526293</td>\n",
       "      <td>0.914171</td>\n",
       "      <td>[-0.7698924541473389, -0.015166983008384705, 0...</td>\n",
       "      <td>[0.11375615745782852, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 3.8804473876953125, 0.0, 0.0, ...</td>\n",
       "      <td>[0.256834477186203, 0.20883648097515106, 0.209...</td>\n",
       "      <td>[-0.12558771669864655, 0.052642013877630234, 0...</td>\n",
       "      <td>[0.045670002698898315, 0.21106137335300446, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7154</th>\n",
       "      <td>7154</td>\n",
       "      <td>979</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>0.882500</td>\n",
       "      <td>0.629464</td>\n",
       "      <td>0.567255</td>\n",
       "      <td>0.550871</td>\n",
       "      <td>...</td>\n",
       "      <td>0.407262</td>\n",
       "      <td>0.535423</td>\n",
       "      <td>0.906449</td>\n",
       "      <td>[-1.057005763053894, 0.36363929510116577, -0.0...</td>\n",
       "      <td>[0.10567610710859299, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.209...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 2.8315927982330322, 0.0, 0.0, ...</td>\n",
       "      <td>[0.5276980400085449, 0.29840975999832153, 0.11...</td>\n",
       "      <td>[-0.10627216100692749, 0.024435723200440407, 0...</td>\n",
       "      <td>[0.05265887826681137, 0.11743561178445816, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7155</th>\n",
       "      <td>7155</td>\n",
       "      <td>979</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>0.831111</td>\n",
       "      <td>0.467021</td>\n",
       "      <td>0.411795</td>\n",
       "      <td>0.441940</td>\n",
       "      <td>...</td>\n",
       "      <td>0.252621</td>\n",
       "      <td>0.368689</td>\n",
       "      <td>0.900056</td>\n",
       "      <td>[-0.6111729741096497, 0.4078267514705658, -0.0...</td>\n",
       "      <td>[7.4650492668151855, 0.0, 0.0, 4.2746124267578...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 4.436276912689209, 0.0, 0.0, 0...</td>\n",
       "      <td>[0.3424797058105469, 0.4358689486980438, 0.121...</td>\n",
       "      <td>[-0.08834826946258545, -0.07931111007928848, 0...</td>\n",
       "      <td>[0.016364941373467445, 0.16124537587165833, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7156</th>\n",
       "      <td>7156</td>\n",
       "      <td>979</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>0.746389</td>\n",
       "      <td>0.515019</td>\n",
       "      <td>0.465634</td>\n",
       "      <td>0.489105</td>\n",
       "      <td>...</td>\n",
       "      <td>0.345893</td>\n",
       "      <td>0.512173</td>\n",
       "      <td>0.910195</td>\n",
       "      <td>[-0.7578554153442383, 0.145307257771492, 0.172...</td>\n",
       "      <td>[0.19229495525360107, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.24897721...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 9.669496536254883, 0.0, 0.0, 0...</td>\n",
       "      <td>[0.46286869049072266, 0.11441261321306229, 0.1...</td>\n",
       "      <td>[-0.17179863154888153, 0.08993590623140335, 0....</td>\n",
       "      <td>[0.029598038643598557, 0.1180773600935936, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7160</th>\n",
       "      <td>7160</td>\n",
       "      <td>980</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>0.918611</td>\n",
       "      <td>0.446082</td>\n",
       "      <td>0.382821</td>\n",
       "      <td>0.433601</td>\n",
       "      <td>...</td>\n",
       "      <td>0.396707</td>\n",
       "      <td>0.114132</td>\n",
       "      <td>0.599402</td>\n",
       "      <td>[-0.2313670963048935, 1.3234683275222778, -0.0...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.2567324936389923, 1.344...</td>\n",
       "      <td>[0.029727034270763397, 0.14830653369426727, 0....</td>\n",
       "      <td>[-0.1294478327035904, -0.16118986904621124, -0...</td>\n",
       "      <td>[0.21316470205783844, 0.007851962931454182, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7161</th>\n",
       "      <td>7161</td>\n",
       "      <td>980</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>0.908889</td>\n",
       "      <td>0.430770</td>\n",
       "      <td>0.250071</td>\n",
       "      <td>0.408742</td>\n",
       "      <td>...</td>\n",
       "      <td>0.390872</td>\n",
       "      <td>0.031184</td>\n",
       "      <td>0.618165</td>\n",
       "      <td>[-0.10539974272251129, 1.4847898483276367, 0.0...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.214...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.1946776658296585, 1.669...</td>\n",
       "      <td>[0.031561993062496185, 0.1539851576089859, 0.3...</td>\n",
       "      <td>[-0.09115365892648697, -0.1642124354839325, -0...</td>\n",
       "      <td>[0.43393874168395996, 0.0, 0.0, 0.0, 0.0034888...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7162</th>\n",
       "      <td>7162</td>\n",
       "      <td>980</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>0.882500</td>\n",
       "      <td>0.460037</td>\n",
       "      <td>0.356039</td>\n",
       "      <td>0.460117</td>\n",
       "      <td>...</td>\n",
       "      <td>0.394629</td>\n",
       "      <td>0.073483</td>\n",
       "      <td>0.607763</td>\n",
       "      <td>[-0.1138879656791687, 1.5103586912155151, 0.08...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.08246175199747086, 0.0, 0.1827126...</td>\n",
       "      <td>[0.13378429412841797, 0.368118554353714, 0.234...</td>\n",
       "      <td>[-0.10963036864995956, -0.13251374661922455, -...</td>\n",
       "      <td>[0.4307763874530792, 0.00023221939045470208, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7163</th>\n",
       "      <td>7163</td>\n",
       "      <td>980</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>0.831111</td>\n",
       "      <td>0.436918</td>\n",
       "      <td>0.355892</td>\n",
       "      <td>0.449652</td>\n",
       "      <td>...</td>\n",
       "      <td>0.393793</td>\n",
       "      <td>0.108309</td>\n",
       "      <td>0.606332</td>\n",
       "      <td>[-0.197564959526062, 1.5285674333572388, 0.021...</td>\n",
       "      <td>[0.0, 0.0, 1.1173779964447021, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.7116710543632507, ...</td>\n",
       "      <td>[0.02029545232653618, 0.19186893105506897, 0.0...</td>\n",
       "      <td>[0.12868385016918182, -0.1763574779033661, -0....</td>\n",
       "      <td>[0.2138545662164688, 0.0, 0.0, 0.0, 0.01330905...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7164</th>\n",
       "      <td>7164</td>\n",
       "      <td>980</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>0.746389</td>\n",
       "      <td>0.489079</td>\n",
       "      <td>0.363646</td>\n",
       "      <td>0.470762</td>\n",
       "      <td>...</td>\n",
       "      <td>0.399306</td>\n",
       "      <td>0.108543</td>\n",
       "      <td>0.596929</td>\n",
       "      <td>[0.024333104491233826, 1.472827672958374, -0.0...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.15791180729866028, 2.60...</td>\n",
       "      <td>[0.014992407523095608, 0.31477898359298706, 0....</td>\n",
       "      <td>[-0.15419156849384308, -0.15890242159366608, -...</td>\n",
       "      <td>[0.37533482909202576, 0.0030570582021027803, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7168</th>\n",
       "      <td>7168</td>\n",
       "      <td>981</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>0.918611</td>\n",
       "      <td>0.382032</td>\n",
       "      <td>0.296401</td>\n",
       "      <td>0.263244</td>\n",
       "      <td>...</td>\n",
       "      <td>0.346250</td>\n",
       "      <td>0.336952</td>\n",
       "      <td>0.799178</td>\n",
       "      <td>[0.06449690461158752, 1.469265103340149, -0.42...</td>\n",
       "      <td>[0.06495075672864914, 0.14232444763183594, 0.0...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 1.4330557584762573, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[1.432977557182312, 0.02081163600087166, 0.701...</td>\n",
       "      <td>[-0.10495661199092865, 0.16865558922290802, 0....</td>\n",
       "      <td>[0.0, 0.05436476692557335, 0.05025557428598404...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7169</th>\n",
       "      <td>7169</td>\n",
       "      <td>981</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>0.908889</td>\n",
       "      <td>0.444604</td>\n",
       "      <td>0.383446</td>\n",
       "      <td>0.370710</td>\n",
       "      <td>...</td>\n",
       "      <td>0.331815</td>\n",
       "      <td>0.336344</td>\n",
       "      <td>0.795902</td>\n",
       "      <td>[0.21392753720283508, 1.7037107944488525, -0.3...</td>\n",
       "      <td>[0.143360435962677, 0.11467412859201431, 0.078...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.5507462620735168, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[2.178285837173462, 0.15363872051239014, 0.842...</td>\n",
       "      <td>[-0.12599441409111023, 0.024993525817990303, -...</td>\n",
       "      <td>[0.0, 0.009711218997836113, 0.0504488162696361...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7170</th>\n",
       "      <td>7170</td>\n",
       "      <td>981</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>0.882500</td>\n",
       "      <td>0.432653</td>\n",
       "      <td>0.336102</td>\n",
       "      <td>0.321678</td>\n",
       "      <td>...</td>\n",
       "      <td>0.318577</td>\n",
       "      <td>0.283287</td>\n",
       "      <td>0.833311</td>\n",
       "      <td>[0.020550444722175598, 1.1093775033950806, -0....</td>\n",
       "      <td>[0.1908726990222931, 0.167339026927948, 0.0342...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 2.0124623775482178, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[1.9007409811019897, 0.10356398671865463, 0.56...</td>\n",
       "      <td>[-0.1480986773967743, -0.11667642742395401, -0...</td>\n",
       "      <td>[0.0, 0.0010618967935442924, 0.034366574138402...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7171</th>\n",
       "      <td>7171</td>\n",
       "      <td>981</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>0.831111</td>\n",
       "      <td>0.408449</td>\n",
       "      <td>0.319473</td>\n",
       "      <td>0.256391</td>\n",
       "      <td>...</td>\n",
       "      <td>0.342887</td>\n",
       "      <td>0.321170</td>\n",
       "      <td>0.779851</td>\n",
       "      <td>[-0.008073423057794571, 1.3436847925186157, -0...</td>\n",
       "      <td>[0.281202495098114, 0.32981422543525696, 0.077...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.6499465107917786, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[1.4528334140777588, 0.07511655986309052, 1.03...</td>\n",
       "      <td>[-0.08569467812776566, -0.04974865913391113, -...</td>\n",
       "      <td>[0.0, 0.014826386235654354, 0.0312345456331968...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7172</th>\n",
       "      <td>7172</td>\n",
       "      <td>981</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>0.746389</td>\n",
       "      <td>0.471886</td>\n",
       "      <td>0.366790</td>\n",
       "      <td>0.348952</td>\n",
       "      <td>...</td>\n",
       "      <td>0.325438</td>\n",
       "      <td>0.314762</td>\n",
       "      <td>0.854543</td>\n",
       "      <td>[0.19545015692710876, 1.1832606792449951, -0.1...</td>\n",
       "      <td>[0.3172508180141449, 0.09058254212141037, 0.05...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 2.074547052383423, 0.0, 0.0, 0.0, 0...</td>\n",
       "      <td>[0.9524770975112915, 0.1285523623228073, 0.882...</td>\n",
       "      <td>[-0.013729872182011604, -0.0960138663649559, -...</td>\n",
       "      <td>[0.0, 0.08133440464735031, 0.04457243159413338...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0   ID  Sample Count  Batch Number  Search Reconstruction  \\\n",
       "7144        7144  978           0.0           NaN                    NaN   \n",
       "7145        7145  978           1.0           NaN                    NaN   \n",
       "7146        7146  978           2.0           NaN                    NaN   \n",
       "7147        7147  978           3.0           NaN                    NaN   \n",
       "7148        7148  978           4.0           NaN                    NaN   \n",
       "7152        7152  979           0.0           NaN                    NaN   \n",
       "7153        7153  979           1.0           NaN                    NaN   \n",
       "7154        7154  979           2.0           NaN                    NaN   \n",
       "7155        7155  979           3.0           NaN                    NaN   \n",
       "7156        7156  979           4.0           NaN                    NaN   \n",
       "7160        7160  980           0.0           NaN                    NaN   \n",
       "7161        7161  980           1.0           NaN                    NaN   \n",
       "7162        7162  980           2.0           NaN                    NaN   \n",
       "7163        7163  980           3.0           NaN                    NaN   \n",
       "7164        7164  980           4.0           NaN                    NaN   \n",
       "7168        7168  981           0.0           NaN                    NaN   \n",
       "7169        7169  981           1.0           NaN                    NaN   \n",
       "7170        7170  981           2.0           NaN                    NaN   \n",
       "7171        7171  981           3.0           NaN                    NaN   \n",
       "7172        7172  981           4.0           NaN                    NaN   \n",
       "\n",
       "      Sample Indicator  Strength  Brain Correlation V1  Brain Correlation V2  \\\n",
       "7144                10  0.918611              0.697852              0.601204   \n",
       "7145                10  0.908889              0.679702              0.629572   \n",
       "7146                10  0.882500              0.710844              0.670913   \n",
       "7147                10  0.831111              0.676744              0.601361   \n",
       "7148                10  0.746389              0.700868              0.633899   \n",
       "7152                10  0.918611              0.621395              0.556997   \n",
       "7153                10  0.908889              0.648300              0.588521   \n",
       "7154                10  0.882500              0.629464              0.567255   \n",
       "7155                10  0.831111              0.467021              0.411795   \n",
       "7156                10  0.746389              0.515019              0.465634   \n",
       "7160                10  0.918611              0.446082              0.382821   \n",
       "7161                10  0.908889              0.430770              0.250071   \n",
       "7162                10  0.882500              0.460037              0.356039   \n",
       "7163                10  0.831111              0.436918              0.355892   \n",
       "7164                10  0.746389              0.489079              0.363646   \n",
       "7168                10  0.918611              0.382032              0.296401   \n",
       "7169                10  0.908889              0.444604              0.383446   \n",
       "7170                10  0.882500              0.432653              0.336102   \n",
       "7171                10  0.831111              0.408449              0.319473   \n",
       "7172                10  0.746389              0.471886              0.366790   \n",
       "\n",
       "      Brain Correlation V3  ...      SSIM  Pixel Correlation  CLIP Cosine  \\\n",
       "7144              0.590434  ...  0.418114           0.694385     0.797669   \n",
       "7145              0.572091  ...  0.410238           0.709497     0.771735   \n",
       "7146              0.585448  ...  0.413547           0.732770     0.761996   \n",
       "7147              0.546082  ...  0.417936           0.735371     0.823320   \n",
       "7148              0.571227  ...  0.438841           0.734774     0.782487   \n",
       "7152              0.534074  ...  0.404265           0.527663     0.921468   \n",
       "7153              0.521875  ...  0.388970           0.526293     0.914171   \n",
       "7154              0.550871  ...  0.407262           0.535423     0.906449   \n",
       "7155              0.441940  ...  0.252621           0.368689     0.900056   \n",
       "7156              0.489105  ...  0.345893           0.512173     0.910195   \n",
       "7160              0.433601  ...  0.396707           0.114132     0.599402   \n",
       "7161              0.408742  ...  0.390872           0.031184     0.618165   \n",
       "7162              0.460117  ...  0.394629           0.073483     0.607763   \n",
       "7163              0.449652  ...  0.393793           0.108309     0.606332   \n",
       "7164              0.470762  ...  0.399306           0.108543     0.596929   \n",
       "7168              0.263244  ...  0.346250           0.336952     0.799178   \n",
       "7169              0.370710  ...  0.331815           0.336344     0.795902   \n",
       "7170              0.321678  ...  0.318577           0.283287     0.833311   \n",
       "7171              0.256391  ...  0.342887           0.321170     0.779851   \n",
       "7172              0.348952  ...  0.325438           0.314762     0.854543   \n",
       "\n",
       "                                           CLIP Two-way  \\\n",
       "7144  [0.6176179051399231, 0.40136244893074036, -0.2...   \n",
       "7145  [0.3076856732368469, 0.33915239572525024, -0.2...   \n",
       "7146  [0.3415769040584564, 0.2298131287097931, 0.172...   \n",
       "7147  [0.48286956548690796, 0.11095590144395828, 0.1...   \n",
       "7148  [0.5468528270721436, 0.046814605593681335, 0.1...   \n",
       "7152  [-0.8803311586380005, 0.177943155169487, 0.263...   \n",
       "7153  [-0.7698924541473389, -0.015166983008384705, 0...   \n",
       "7154  [-1.057005763053894, 0.36363929510116577, -0.0...   \n",
       "7155  [-0.6111729741096497, 0.4078267514705658, -0.0...   \n",
       "7156  [-0.7578554153442383, 0.145307257771492, 0.172...   \n",
       "7160  [-0.2313670963048935, 1.3234683275222778, -0.0...   \n",
       "7161  [-0.10539974272251129, 1.4847898483276367, 0.0...   \n",
       "7162  [-0.1138879656791687, 1.5103586912155151, 0.08...   \n",
       "7163  [-0.197564959526062, 1.5285674333572388, 0.021...   \n",
       "7164  [0.024333104491233826, 1.472827672958374, -0.0...   \n",
       "7168  [0.06449690461158752, 1.469265103340149, -0.42...   \n",
       "7169  [0.21392753720283508, 1.7037107944488525, -0.3...   \n",
       "7170  [0.020550444722175598, 1.1093775033950806, -0....   \n",
       "7171  [-0.008073423057794571, 1.3436847925186157, -0...   \n",
       "7172  [0.19545015692710876, 1.1832606792449951, -0.1...   \n",
       "\n",
       "                                              AlexNet 2  \\\n",
       "7144  [0.0, 0.0, 0.0, 0.0, 0.0, 1.4665712118148804, ...   \n",
       "7145  [0.6485033631324768, 0.0, 0.0, 0.0, 0.0, 0.831...   \n",
       "7146  [2.854987382888794, 1.653757929801941, 0.0, 1....   \n",
       "7147  [1.1171984672546387, 0.0, 0.8008405566215515, ...   \n",
       "7148  [2.323309898376465, 0.39934027194976807, 0.0, ...   \n",
       "7152  [0.5660234689712524, 0.030195869505405426, 0.0...   \n",
       "7153  [0.11375615745782852, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "7154  [0.10567610710859299, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "7155  [7.4650492668151855, 0.0, 0.0, 4.2746124267578...   \n",
       "7156  [0.19229495525360107, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "7160  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "7161  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.214...   \n",
       "7162  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "7163  [0.0, 0.0, 1.1173779964447021, 0.0, 0.0, 0.0, ...   \n",
       "7164  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "7168  [0.06495075672864914, 0.14232444763183594, 0.0...   \n",
       "7169  [0.143360435962677, 0.11467412859201431, 0.078...   \n",
       "7170  [0.1908726990222931, 0.167339026927948, 0.0342...   \n",
       "7171  [0.281202495098114, 0.32981422543525696, 0.077...   \n",
       "7172  [0.3172508180141449, 0.09058254212141037, 0.05...   \n",
       "\n",
       "                                              AlexNet 5  \\\n",
       "7144  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "7145  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "7146  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "7147  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "7148  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "7152  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "7153  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "7154  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.209...   \n",
       "7155  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "7156  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.24897721...   \n",
       "7160  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "7161  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "7162  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "7163  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "7164  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "7168  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "7169  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "7170  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "7171  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "7172  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "                                              AlexNet 7  \\\n",
       "7144  [0.0, 0.0, 1.4618737697601318, 0.0, 0.0, 0.0, ...   \n",
       "7145  [0.0, 0.0, 2.5993759632110596, 0.0, 0.0, 0.0, ...   \n",
       "7146  [0.0, 0.0, 1.5158584117889404, 0.0, 0.0, 0.0, ...   \n",
       "7147  [0.0, 0.0, 2.4964704513549805, 0.0, 0.0, 0.0, ...   \n",
       "7148  [0.0, 0.0, 1.4566391706466675, 0.0, 0.0, 0.0, ...   \n",
       "7152  [0.0, 0.0, 0.0, 4.796745300292969, 0.0, 0.0, 0...   \n",
       "7153  [0.0, 0.0, 0.0, 3.8804473876953125, 0.0, 0.0, ...   \n",
       "7154  [0.0, 0.0, 0.0, 2.8315927982330322, 0.0, 0.0, ...   \n",
       "7155  [0.0, 0.0, 0.0, 4.436276912689209, 0.0, 0.0, 0...   \n",
       "7156  [0.0, 0.0, 0.0, 9.669496536254883, 0.0, 0.0, 0...   \n",
       "7160  [0.0, 0.0, 0.0, 0.0, 0.2567324936389923, 1.344...   \n",
       "7161  [0.0, 0.0, 0.0, 0.0, 0.1946776658296585, 1.669...   \n",
       "7162  [0.0, 0.0, 0.08246175199747086, 0.0, 0.1827126...   \n",
       "7163  [0.0, 0.0, 0.0, 0.0, 0.0, 0.7116710543632507, ...   \n",
       "7164  [0.0, 0.0, 0.0, 0.0, 0.15791180729866028, 2.60...   \n",
       "7168  [0.0, 0.0, 1.4330557584762573, 0.0, 0.0, 0.0, ...   \n",
       "7169  [0.0, 0.0, 0.5507462620735168, 0.0, 0.0, 0.0, ...   \n",
       "7170  [0.0, 0.0, 2.0124623775482178, 0.0, 0.0, 0.0, ...   \n",
       "7171  [0.0, 0.0, 0.6499465107917786, 0.0, 0.0, 0.0, ...   \n",
       "7172  [0.0, 0.0, 2.074547052383423, 0.0, 0.0, 0.0, 0...   \n",
       "\n",
       "                                           Inception V3  \\\n",
       "7144  [0.5133019685745239, 0.3083895146846771, 0.127...   \n",
       "7145  [0.25076383352279663, 0.2883766293525696, 0.01...   \n",
       "7146  [0.5988375544548035, 0.49265187978744507, 0.47...   \n",
       "7147  [0.36786434054374695, 0.16114407777786255, 0.1...   \n",
       "7148  [0.2481999546289444, 0.3061738610267639, 0.126...   \n",
       "7152  [0.36886462569236755, 0.1002252995967865, 0.02...   \n",
       "7153  [0.256834477186203, 0.20883648097515106, 0.209...   \n",
       "7154  [0.5276980400085449, 0.29840975999832153, 0.11...   \n",
       "7155  [0.3424797058105469, 0.4358689486980438, 0.121...   \n",
       "7156  [0.46286869049072266, 0.11441261321306229, 0.1...   \n",
       "7160  [0.029727034270763397, 0.14830653369426727, 0....   \n",
       "7161  [0.031561993062496185, 0.1539851576089859, 0.3...   \n",
       "7162  [0.13378429412841797, 0.368118554353714, 0.234...   \n",
       "7163  [0.02029545232653618, 0.19186893105506897, 0.0...   \n",
       "7164  [0.014992407523095608, 0.31477898359298706, 0....   \n",
       "7168  [1.432977557182312, 0.02081163600087166, 0.701...   \n",
       "7169  [2.178285837173462, 0.15363872051239014, 0.842...   \n",
       "7170  [1.9007409811019897, 0.10356398671865463, 0.56...   \n",
       "7171  [1.4528334140777588, 0.07511655986309052, 1.03...   \n",
       "7172  [0.9524770975112915, 0.1285523623228073, 0.882...   \n",
       "\n",
       "                                               EffNet-B  \\\n",
       "7144  [0.47903746366500854, -0.11704962700605392, 0....   \n",
       "7145  [0.008627716451883316, -0.1392345279455185, -0...   \n",
       "7146  [-0.10010838508605957, -0.14901290833950043, -...   \n",
       "7147  [0.15536214411258698, -0.11582586169242859, -0...   \n",
       "7148  [0.0411347933113575, -0.13752640783786774, -0....   \n",
       "7152  [-0.1549503356218338, -0.009874165989458561, 0...   \n",
       "7153  [-0.12558771669864655, 0.052642013877630234, 0...   \n",
       "7154  [-0.10627216100692749, 0.024435723200440407, 0...   \n",
       "7155  [-0.08834826946258545, -0.07931111007928848, 0...   \n",
       "7156  [-0.17179863154888153, 0.08993590623140335, 0....   \n",
       "7160  [-0.1294478327035904, -0.16118986904621124, -0...   \n",
       "7161  [-0.09115365892648697, -0.1642124354839325, -0...   \n",
       "7162  [-0.10963036864995956, -0.13251374661922455, -...   \n",
       "7163  [0.12868385016918182, -0.1763574779033661, -0....   \n",
       "7164  [-0.15419156849384308, -0.15890242159366608, -...   \n",
       "7168  [-0.10495661199092865, 0.16865558922290802, 0....   \n",
       "7169  [-0.12599441409111023, 0.024993525817990303, -...   \n",
       "7170  [-0.1480986773967743, -0.11667642742395401, -0...   \n",
       "7171  [-0.08569467812776566, -0.04974865913391113, -...   \n",
       "7172  [-0.013729872182011604, -0.0960138663649559, -...   \n",
       "\n",
       "                                                   SwAV  \n",
       "7144  [0.012201203964650631, 0.03682749718427658, 0....  \n",
       "7145  [0.0018427814356982708, 0.08204822987318039, 0...  \n",
       "7146  [0.005790903232991695, 0.19102318584918976, 0....  \n",
       "7147  [0.005720560438930988, 0.18248318135738373, 0....  \n",
       "7148  [0.0020285334903746843, 0.06923013925552368, 0...  \n",
       "7152  [0.03400035575032234, 0.07987703382968903, 0.0...  \n",
       "7153  [0.045670002698898315, 0.21106137335300446, 0....  \n",
       "7154  [0.05265887826681137, 0.11743561178445816, 0.0...  \n",
       "7155  [0.016364941373467445, 0.16124537587165833, 0....  \n",
       "7156  [0.029598038643598557, 0.1180773600935936, 0.0...  \n",
       "7160  [0.21316470205783844, 0.007851962931454182, 0....  \n",
       "7161  [0.43393874168395996, 0.0, 0.0, 0.0, 0.0034888...  \n",
       "7162  [0.4307763874530792, 0.00023221939045470208, 0...  \n",
       "7163  [0.2138545662164688, 0.0, 0.0, 0.0, 0.01330905...  \n",
       "7164  [0.37533482909202576, 0.0030570582021027803, 0...  \n",
       "7168  [0.0, 0.05436476692557335, 0.05025557428598404...  \n",
       "7169  [0.0, 0.009711218997836113, 0.0504488162696361...  \n",
       "7170  [0.0, 0.0010618967935442924, 0.034366574138402...  \n",
       "7171  [0.0, 0.014826386235654354, 0.0312345456331968...  \n",
       "7172  [0.0, 0.08133440464735031, 0.04457243159413338...  \n",
       "\n",
       "[20 rows x 24 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test_idx = [20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 45, 46, 47, 48, 50, 51, 52, 53, 54, 55, 56, 58, 59, 60, 62, 63, 64, 65, 66, 67, 68, 69, 71, 72, 73, 74, 75, 79, 80, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 106, 107, 108, 109, 111, 113, 115, 116, 117, 118, 119, 120, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140]\n",
    "# test_idx = [20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 71, 72, 73, 74, 75, 77, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 106, 107, 108, 109, 110, 111, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140]\n",
    "# Paper Only\n",
    "# df_final_samples    = df.loc[(df['Sample Indicator'] == 11) & (df['ID'].isin(test_idx))]\n",
    "# df_final_samples.head()\n",
    "# print(df.keys())\n",
    "# df_final_samples    = df.loc[(df['Search Reconstruction'] == True)]\n",
    "df_final_samples    = df.loc[(df['Sample Indicator'] == 10)]\n",
    "# df_final_samples    = df.loc[(df['Search Reconstruction'] == True) & (df['ID'].isin(test_idx))]\n",
    "# print(len(df_final_samples), len(df_final_samples)/5)\n",
    "# print(np.unique(np.array(df_final_samples['ID'].tolist()), return_counts=True))\n",
    "# df_final_samples.head()\n",
    "\n",
    "\n",
    "print(\"------------------------------------------------ Brain Correlation V1 -----------------------------------------------------------------\")\n",
    "\n",
    "print(\"Brain Correlation V1: \", df_final_samples['Brain Correlation V1'].mean())\n",
    "\n",
    "print(\"------------------------------------------------ Brain Correlation V2 -----------------------------------------------------------------\")\n",
    "\n",
    "print(\"Brain Correlation V2: \", df_final_samples['Brain Correlation V2'].mean())\n",
    "\n",
    "print(\"------------------------------------------------ Brain Correlation V3 -----------------------------------------------------------------\")\n",
    "\n",
    "print(\"Brain Correlation V3: \", df_final_samples['Brain Correlation V3'].mean())\n",
    "\n",
    "print(\"------------------------------------------------ Brain Correlation V4 -----------------------------------------------------------------\")\n",
    "\n",
    "print(\"Brain Correlation V4: \", df_final_samples['Brain Correlation V4'].mean())\n",
    "\n",
    "print(\"------------------------------------------------ Brain Correlation Early Visual -------------------------------------------------------\")\n",
    "\n",
    "print(\"Brain Correlation Early Visual: \", df_final_samples['Brain Correlation Early Visual'].mean())\n",
    "\n",
    "print(\"------------------------------------------------ Brain Correlation Higher Visual -------------------------------------------------------\")\n",
    "\n",
    "print(\"Brain Correlation Higher Visual: \", df_final_samples['Brain Correlation Higher Visual'].mean())\n",
    "\n",
    "print(\"------------------------------------------------ Brain Correlation NSD General ---------------------------------------------------------\")\n",
    "\n",
    "print(\"Brain Correlation NSD General: \", df_final_samples['Brain Correlation NSD General'].mean())\n",
    "df_final_samples.tail(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average Iteration Brain Region Plot\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "brain_correlation_V1 = []\n",
    "brain_correlation_V2 = []\n",
    "brain_correlation_V3 = []\n",
    "brain_correlation_V4 = []\n",
    "brain_correlation_early_visual = []\n",
    "brain_correlation_higher_visual = []\n",
    "brain_correlation_unmasked = []\n",
    "brain_correlation_ground_truth = []\n",
    "\n",
    "folders = {\"vdvae_distribution\" : 2, \"clip_distribution\" : 1, \"clip+vdvae_distribution\" : 3, \"iter_0\" : 4, \"iter_1\" : 5 , \"iter_2\" : 6, \"iter_3\" : 7, \"iter_4\" : 8, \"iter_5\" : 9}\n",
    "x = [\"vdvae\", \"clip\", \"clip+\\nvdvae\", \"iter 0\", \"iter 1\", \"iter 2\", \"iter 3\", \"iter 4\", \"iter 5\"]\n",
    "\n",
    "for folder, sample_indicator in folders.items():\n",
    "    \n",
    "    iteration_val_v1 = df.loc[(df['Sample Indicator'] == sample_indicator)]['Brain Correlation V1'].mean()\n",
    "    iteration_val_v2 = df.loc[(df['Sample Indicator'] == sample_indicator)]['Brain Correlation V2'].mean()\n",
    "    iteration_val_v3 = df.loc[(df['Sample Indicator'] == sample_indicator)]['Brain Correlation V3'].mean()\n",
    "    iteration_val_v4 = df.loc[(df['Sample Indicator'] == sample_indicator)]['Brain Correlation V4'].mean()\n",
    "    iteration_val_ev = df.loc[(df['Sample Indicator'] == sample_indicator)]['Brain Correlation Early Visual'].mean()\n",
    "    iteration_val_hv = df.loc[(df['Sample Indicator'] == sample_indicator)]['Brain Correlation Higher Visual'].mean()\n",
    "    iteration_val_unmasked = df.loc[(df['Sample Indicator'] == sample_indicator)]['Brain Correlation NSD General'].mean()\n",
    "    \n",
    "    brain_correlation_V1.append(iteration_val_v1)\n",
    "    brain_correlation_V2.append(iteration_val_v2)\n",
    "    brain_correlation_V3.append(iteration_val_v3)\n",
    "    brain_correlation_V4.append(iteration_val_v4)\n",
    "    brain_correlation_early_visual.append(iteration_val_ev)\n",
    "    brain_correlation_higher_visual.append(iteration_val_hv)\n",
    "    brain_correlation_unmasked.append(iteration_val_unmasked)\n",
    "    \n",
    "\n",
    "# plt.axhline(y = df.loc[(df['Sample Indicator'] == 0.0)]['Brain Correlation V1'].mean(), color = 'blue', linestyle = 'dashed', linewidth=1)\n",
    "# plt.axhline(y = df.loc[(df['Sample Indicator'] == 0.0)]['Brain Correlation V2'].mean(), color = 'green', linestyle = 'dashed', linewidth=1)\n",
    "# plt.axhline(y = df.loc[(df['Sample Indicator'] == 0.0)]['Brain Correlation V3'].mean(), color = 'red',linestyle = 'dashed', linewidth=1)\n",
    "# plt.axhline(y = df.loc[(df['Sample Indicator'] == 0.0)]['Brain Correlation V4'].mean(), color = 'orange',linestyle = 'dashed', linewidth=1)\n",
    "# plt.axhline(y = df.loc[(df['Sample Indicator'] == 0.0)]['Brain Correlation Higher Visual'].mean(), color = 'brown', linestyle = 'dashed', linewidth=1)\n",
    "# plt.axhline(y = df.loc[(df['Sample Indicator'] == 0.0)]['Brain Correlation Early Visual'].mean(),  color = 'magenta',linestyle = 'dashed', linewidth=1)\n",
    "plt.axhline(y = df.loc[(df['Sample Indicator'] == 0.0)]['Brain Correlation NSD General'].mean(), color = 'black', linestyle = 'dashed', linewidth=1)\n",
    "\n",
    "plt.plot(brain_correlation_V1, marker='.', color = 'blue', label = 'V1', linewidth=1)\n",
    "plt.plot(brain_correlation_V2, marker='.', color = 'green',label = 'V2', linewidth=1)\n",
    "plt.plot(brain_correlation_V3, marker='.', color = 'red',  label = 'V3', linewidth=1)\n",
    "plt.plot(brain_correlation_V4, marker='.', color = 'orange', label = 'V4', linewidth=1)\n",
    "plt.plot(brain_correlation_higher_visual, marker='.', color = 'brown', label = 'Higher Visual', linewidth=1)\n",
    "plt.plot(brain_correlation_early_visual, marker='.',  color = 'magenta', label = 'Early Visual', linewidth=1)\n",
    "plt.plot(brain_correlation_unmasked, marker='.',  color = 'black', label = 'NSD General', linewidth=1)\n",
    "plt.xticks(range(len(x)), x,fontsize=9)\n",
    "\n",
    "plt.legend(fontsize = \"xx-small\")\n",
    "plt.xlabel(\"Search Iteration\")\n",
    "plt.ylabel(\"Avearge Brain Pearson Correlation\")\n",
    "plt.title(\"Encoded Brain Pearson Correlation\")\n",
    "mpl.rcParams['figure.dpi'] = 300\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average Iteration Brain Region Plot\n",
    "\n",
    "brain_correlation_V1 = []\n",
    "brain_correlation_V2 = []\n",
    "brain_correlation_V3 = []\n",
    "brain_correlation_V4 = []\n",
    "brain_correlation_early_visual = []\n",
    "brain_correlation_higher_visual = []\n",
    "brain_correlation_unmasked = []\n",
    "brain_correlation_ground_truth = []\n",
    "\n",
    "y_v1 = df.loc[(df['Sample Indicator'] == 0.0)]['Brain Correlation V1'].mean()\n",
    "y_v2 = df.loc[(df['Sample Indicator'] == 0.0)]['Brain Correlation V2'].mean()\n",
    "y_v3 = df.loc[(df['Sample Indicator'] == 0.0)]['Brain Correlation V3'].mean()\n",
    "y_v4 = df.loc[(df['Sample Indicator'] == 0.0)]['Brain Correlation V4'].mean()\n",
    "y_ev = df.loc[(df['Sample Indicator'] == 0.0)]['Brain Correlation Early Visual'].mean()\n",
    "y_hv = df.loc[(df['Sample Indicator'] == 0.0)]['Brain Correlation Higher Visual'].mean()\n",
    "y_unmasked = df.loc[(df['Sample Indicator'] == 0.0)]['Brain Correlation NSD General'].mean()\n",
    "\n",
    "v1_set = True\n",
    "v2_set = True\n",
    "v3_set = True\n",
    "v4_set = True\n",
    "ev_set = True\n",
    "hv_set = True\n",
    "unmasked_set = True\n",
    "\n",
    "x_v1 = 0 \n",
    "x_v2 = 0 \n",
    "x_v3 = 0 \n",
    "x_v4 = 0 \n",
    "x_ev = 0 \n",
    "x_hv = 0 \n",
    "x_umasked = 0 \n",
    "\n",
    "folders = {\"vdvae_distribution\" : 2, \"clip_distribution\" : 1, \"clip+vdvae_distribution\" : 3, \"iter_0\" : 4, \"iter_1\" : 5 , \"iter_2\" : 6, \"iter_3\" : 7, \"iter_4\" : 8, \"iter_5\" : 9}\n",
    "x = [\"vdvae\", \"clip\", \"clip+\\nvdvae\", \"iter 0\", \"iter 1\", \"iter 2\", \"iter 3\", \"iter 4\", \"iter 5\"]\n",
    "iteration = 0\n",
    "\n",
    "\n",
    "for folder, sample_indicator in folders.items():\n",
    "    \n",
    "    iteration_val_v1 = df.loc[(df['Sample Indicator'] == sample_indicator)]['Brain Correlation V1'].mean()\n",
    "    iteration_val_v2 = df.loc[(df['Sample Indicator'] == sample_indicator)]['Brain Correlation V2'].mean()\n",
    "    iteration_val_v3 = df.loc[(df['Sample Indicator'] == sample_indicator)]['Brain Correlation V3'].mean()\n",
    "    iteration_val_v4 = df.loc[(df['Sample Indicator'] == sample_indicator)]['Brain Correlation V4'].mean()\n",
    "    iteration_val_ev = df.loc[(df['Sample Indicator'] == sample_indicator)]['Brain Correlation Early Visual'].mean()\n",
    "    iteration_val_hv = df.loc[(df['Sample Indicator'] == sample_indicator)]['Brain Correlation Higher Visual'].mean()\n",
    "    iteration_val_unmasked = df.loc[(df['Sample Indicator'] == sample_indicator)]['Brain Correlation NSD General'].mean()\n",
    "    \n",
    "    brain_correlation_V1.append(iteration_val_v1)\n",
    "    brain_correlation_V2.append(iteration_val_v2)\n",
    "    brain_correlation_V3.append(iteration_val_v3)\n",
    "    brain_correlation_V4.append(iteration_val_v4)\n",
    "    brain_correlation_early_visual.append(iteration_val_ev)\n",
    "    brain_correlation_higher_visual.append(iteration_val_hv)\n",
    "    brain_correlation_unmasked.append(iteration_val_unmasked)\n",
    "    \n",
    "    if(iteration_val_v1 > y_v1 and v1_set):\n",
    "        x_v1 = iteration - 1\n",
    "        v1_set = False\n",
    "        \n",
    "    if(iteration_val_v2 > y_v2 and v2_set):\n",
    "        x_v2 = iteration - 1\n",
    "        v2_set = False\n",
    "        \n",
    "    if(iteration_val_v3 > y_v3 and v3_set):\n",
    "        x_v3 = iteration - 1\n",
    "        v3_set = False\n",
    "        \n",
    "    if(iteration_val_v4 > y_v4 and v4_set):\n",
    "        x_v4 = iteration - 1\n",
    "        v4_set = False\n",
    "        \n",
    "    if(iteration_val_ev > y_ev and ev_set):\n",
    "        x_ev = iteration - 1\n",
    "        ev_set = False\n",
    "        \n",
    "    if(iteration_val_hv > y_hv and hv_set):\n",
    "        x_hv = iteration - 1\n",
    "        hv_set = False\n",
    "        \n",
    "    if(iteration_val_unmasked > y_unmasked and unmasked_set):\n",
    "        x_unmasked = iteration - 1\n",
    "        unmasked_set = False\n",
    "        \n",
    "    iteration += 1\n",
    "    \n",
    "# print(df.loc[(df['Sample Indicator'] == 0.0)]['Brain Correlation Unmasked'].mean())\n",
    "# plt.axhline(y = df.loc[(df['Sample Indicator'] == 0.0)]['Brain Correlation Unmasked'].mean(), linestyle = 'dashed', label = 'Brain Correlation Unmasked')\n",
    "# plt.axhline(y = df.loc[(df['Sample Indicator'] == 0.0)]['Brain Correlation V1'].mean(), linestyle = '-', label = 'Brain Correlation V1')\n",
    "# plt.axhline(y = df.loc[(df['Sample Indicator'] == 0.0)]['Brain Correlation V2'].mean(), linestyle = '-', label = 'Brain Correlation V2')\n",
    "# plt.axhline(y = df.loc[(df['Sample Indicator'] == 0.0)]['Brain Correlation V3'].mean(), linestyle = '-', label = 'Brain Correlation V3')\n",
    "# plt.axhline(y = df.loc[(df['Sample Indicator'] == 0.0)]['Brain Correlation V4'].mean(), linestyle = '-', label = 'Brain Correlation V4')\n",
    "# plt.axhline(y = df.loc[(df['Sample Indicator'] == 0.0)]['Brain Correlation Higher Visual'].mean(), linestyle = '-', label = 'Brain Correlation Higher Visual')\n",
    "# plt.axhline(y = df.loc[(df['Sample Indicator'] == 0.0)]['Brain Correlation Early Visual'].mean(), linestyle = '-', label = 'Brain Correlation Higher Visual')\n",
    "\n",
    "\n",
    "N = 9\n",
    "#x = np.array([0,1,2,3,4,5,6,7,8,9])\n",
    "# y = np.array(brain_correlation_unmasked)\n",
    "# a, b = np.polyfit(x, brain_correlation_unmasked, deg=1)\n",
    "# y_est = a * x + b\n",
    "# y_err = st.t.interval(alpha=0.95, df=len(y)-1, loc=np.mean(y), scale=st.sem(y))\n",
    "# print(y_err[0])\n",
    "# print(y_err[1])\n",
    "\n",
    "y_un = np.array(brain_correlation_unmasked)\n",
    "ci_un = 0.95 * np.std(y_un) / math.sqrt(N)\n",
    "\n",
    "\n",
    "# def mean_confidence_interval(data, confidence=0.95):\n",
    "#     a = 1.0 * np.array(data)\n",
    "#     n = len(a)\n",
    "#     m, se = np.mean(a), scipy.stats.sem(a)\n",
    "#     h = se * scipy.stats.t.ppf((1 + confidence) / 2., n-1)\n",
    "#     return m, m-h, m+h\n",
    "\n",
    "# mean, lower, upper = [],[],[]\n",
    "# ci = 0.95\n",
    "\n",
    "# m, ml, mu = mean_confidence_interval(y, ci)\n",
    "# mean.append(m)\n",
    "# lower.append(ml)\n",
    "# upper.append(mu)\n",
    "\n",
    "\n",
    "plt.plot(brain_correlation_V1, marker='.', label = 'V1', linewidth=1, color = \"royalblue\")\n",
    "plt.plot(brain_correlation_V2, marker='.', label = 'V2', linewidth=1, color = \"darkviolet\")\n",
    "plt.plot(brain_correlation_V3, marker='.', label = 'V3', linewidth=1, color = \"red\")\n",
    "plt.plot(brain_correlation_V4, marker='.', label = 'V4', linewidth=1, color = \"forestgreen\")\n",
    "#plt.plot(brain_correlation_early_visual, marker='.', label = 'Early Visual', linewidth=1, color = \"red\")\n",
    "plt.plot(brain_correlation_higher_visual, marker='.', label = 'Higher Visual', linewidth=1, color = \"darkorange\")\n",
    "plt.plot(brain_correlation_unmasked, marker='.', label = 'NSD General', linewidth=1, color = \"black\")\n",
    "plt.xticks(range(len(x)), x,fontsize=9)\n",
    "# plt.fill_between(x, y_err[0], y_err[0], color='dimgray', alpha=0.2)\n",
    "# plt.fill_between(x, upper, lower, color='dimgray', alpha=0.2)\n",
    "plt.fill_between(x, (y_un-ci_un), (y_un+ci_un), color='black', alpha=.2)\n",
    "# plt.fill_between(x, (y_hi-ci_hi), (y_hi+ci_hi), color='darkorange', alpha=.2)\n",
    "# plt.fill_between(x, (y_er-ci_er), (y_er+ci_er), color='red', alpha=.2)\n",
    "# plt.fill_between(x, (y_vo-ci_vo), (y_vo+ci_vo), color='royalblue', alpha=.2)\n",
    "# plt.fill_between(x, (y_vt-ci_vt), (y_vt+ci_vt), color='darkviolet', alpha=.2)\n",
    "# plt.fill_between(x, (y_vth-ci_vth), (y_vth+ci_vth), color='violet', alpha=.2)\n",
    "# plt.fill_between(x, (y_vf-ci_vf), (y_vf+ci_vf), color='forestgreen', alpha=.2)\n",
    "\n",
    "# plt.plot([7.25, 7 + 1], [y_v1, y_v1] , color = \"royalblue\", linestyle=\"dashed\", linewidth=2)\n",
    "# plt.plot([7.25, 7 + 1], [y_v2, y_v2] , color = \"darkviolet\", linestyle=\"dashed\", linewidth=2)\n",
    "# plt.plot([7.25, 7 + 1], [y_v3, y_v3] , color = \"violet\", linestyle=\"dashed\", linewidth=2)\n",
    "# plt.plot([x_v4 + 0.25, x_v4 + 1], [y_v4, y_v4] , color = 'forestgreen', linestyle=\"dashed\", linewidth=2)\n",
    "# plt.plot([7.25, 7 + 1], [y_ev - 0.002, y_ev - 0.002] , color = 'red', linestyle=\"dashed\", linewidth=2)\n",
    "# plt.plot([x_hv - 0.25, x_hv + 0.50], [y_hv, y_hv] , color = \"darkorange\", linestyle=\"dashed\", linewidth=2)\n",
    "# plt.plot([x_unmasked + 0.5, x_unmasked + 1.25], [y_unmasked, y_unmasked] , color = 'black', linestyle=\"dashed\", linewidth=2, label=\"Ground Truth Image\")\n",
    "#plt.axhline(x = [1,3], y = df.loc[(df['Sample Indicator'] == 0.0)]['Brain Correlation Unmasked'].mean(), linestyle = 'dashed', label = 'Brain Correlation Unmasked')\n",
    "# plt.axhline(y = df.loc[(df['Sample Indicator'] == 0.0)]['Brain Correlation V1'].mean(), linestyle = '-', label = 'Brain Correlation V1')\n",
    "# plt.axhline(y = df.loc[(df['Sample Indicator'] == 0.0)]['Brain Correlation V2'].mean(), linestyle = '-', label = 'Brain Correlation V2')\n",
    "# plt.axhline(y = df.loc[(df['Sample Indicator'] == 0.0)]['Brain Correlation V3'].mean(), linestyle = '-', label = 'Brain Correlation V3')\n",
    "# plt.axhline(y = df.loc[(df['Sample Indicator'] == 0.0)]['Brain Correlation V4'].mean(), linestyle = '-', label = 'Brain Correlation V4')\n",
    "# plt.axhline(y = df.loc[(df['Sample Indicator'] == 0.0)]['Brain Correlation Higher Visual'].mean(), linestyle = '-', label = 'Brain Correlation Higher Visual')\n",
    "# plt.axhline(y = df.loc[(df['Sample Indicator'] == 0.0)]['Brain Correlation Early Visual'].mean(), linestyle = '-', label = 'Brain Correlation Higher Visual')\n",
    "leg = plt.legend(loc=\"upper left\", ncol = 2, fontsize = \"4.5\")\n",
    "# leg.legendHandles[7].set_color('silver')\n",
    "plt.xlabel(\"Search Iteration\")\n",
    "plt.ylabel(\"Avearge Brain Pearson Correlation\")\n",
    "plt.title(\"Encoded Brain Pearson Correlation\")\n",
    "mpl.rcParams['figure.dpi'] = 2500\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search iterations to Ground Truth\n",
    "\n",
    "x_iter_values = []\n",
    "\n",
    "x_iter_values.append(10)\n",
    "x_iter_values.append(10)\n",
    "x_iter_values.append(10)\n",
    "x_iter_values.append(9)\n",
    "x_iter_values.append(0)\n",
    "\n",
    "x_labels = ['V1', 'V2', 'V3', 'V4', 'Higher Visual']\n",
    "x_axis = np.arange(len(x_labels))\n",
    "# y_labels = [\"0\", \"2\", \"4\", \"6\", \"8\", \"10 >=\"]\n",
    "# y_axis = np.arange(len(y_labels))\n",
    "\n",
    "# x_iter_values.append(0)\n",
    "# x_iter_values.append(x_v4)\n",
    "# x_iter_values.append(x_v3)\n",
    "# x_iter_values.append(x_v2)\n",
    "# x_iter_values.append(9)\n",
    "\n",
    "# x_labels = ['Higher Visual', 'V4', 'V3', 'V2', 'V1']\n",
    "plt.xticks(x_axis, x_labels)\n",
    "# plt.yticks(y_axis, y_labels)\n",
    "plt.plot(x_iter_values, marker='o', linewidth=2, color = \"darkgray\")\n",
    "plt.xlabel(\"Brain Areas\", fontsize=18)\n",
    "plt.ylabel(\"Iterations to ground truth\", fontsize=18)\n",
    "plt.title(\"Search iterations to surpass ground truth\\n brain correlation score\", fontsize=20)\n",
    "mpl.rcParams['figure.dpi'] = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar Plot Sample Counts \n",
    "\n",
    "idx = [20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, \n",
    "        64, 65, 66, 67, 68, 69, 71, 72, 73, 74, 75, 77, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 106, 107, 108, \n",
    "        109, 110, 111, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145,\n",
    "        147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, \n",
    "        182, 183, 184, 185, 186, 188, 189, 190, 191, 192, 193, 194, 195, 196, 198, 199, 200, 201, 202, 203, 205, 206, 207, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, \n",
    "        221, 222, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 256, 257, \n",
    "        258, 259, 261, 262, 263, 264, 265, 266, 267, 268, 270, 272, 273, 274, 275, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, \n",
    "        297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, \n",
    "        333, 334, 335, 336, 337, 338, 339, 341, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 364, 365, 366, 367, 368, 369, 370, \n",
    "        371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 393, 394, 395, 396, 397, 398, 400, 401, 402, 403, 404, 406, 407, 408, \n",
    "        409, 410, 411, 412, 413, 414, 415, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, \n",
    "        447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 481, 482, \n",
    "        483, 484, 485, 486, 487, 488, 489, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, \n",
    "        521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 547, 548, 549, 551, 552, 553, 554, 555, 556, 557, \n",
    "        558, 559, 560, 561, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, \n",
    "        594, 595, 596, 597, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 616, 617, 618, 619, 620, 621, 622, 624, 625, 626, 627, 628, 629, 630, 631, 632, \n",
    "        633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 655, 656, 657, 659, 661, 662, 663, 664, 666, 667, 668, 669, 670, 671, \n",
    "        672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 694, 695, 696, 698, 699, 700, 701, 702, 703, 704, 705, 706, 708, 709, \n",
    "        710, 711, 712, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, \n",
    "        747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 782, 783, \n",
    "        784, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819,\n",
    "        820, 821, 822, 823, 824, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 838, 839, 840, 841, 842, 843, 844, 845, 847, 848, 849, 851, 852, 854, 855, 856, 857, 858, 859,\n",
    "        861, 862, 863, 864, 865, 866, 867, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 892, 893, 894, 895, 896, 897, \n",
    "        898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 911, 912, 913, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, \n",
    "        934, 936, 937, 938, 939, 940, 941, 942, 943, 944, 945, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961, 962, 963, 964, 965, 966, 967, 968, 969, 970, \n",
    "        971, 974, 976, 977, 978, 979, 980, 981]\n",
    "\n",
    "v1 = [0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "v2 = [0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "v3 = [0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "v4 = [0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "ev = [0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "hv = [0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "nsd = [0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "\n",
    "#folders = {\"vdvae_distribution\" : 0, \"clip_distribution\" : 1, \"clip+vdvae_distribution\" : 2, \"iter_0\" : 3, \"iter_1\" : 4, \"iter_2\" : 5, \"iter_3\" : 6, \"iter_4\" : 7 , \"iter_5\": 8}\n",
    "#folders = {\"clip_distribution\" : 1, \"vdvae_distribution\" : 2, \"clip+vdvae_distribution\" : 3, \"iter_0\" : 4, \"iter_1\" : 5 , \"iter_2\" : 6, \"iter_3\" : 7, \"iter_4\" : 8, \"iter_5\" : 9}\n",
    "folders = {\"vdvae_distribution\" : 2, \"clip_distribution\" : 1, \"clip+vdvae_distribution\" : 3, \"iter_0\" : 4, \"iter_1\" : 5 , \"iter_2\" : 6, \"iter_3\" : 7, \"iter_4\" : 8, \"iter_5\" : 9}\n",
    "list_indicator = {2 : 0, 1 : 1, 3 : 2, 4 : 3, 5 : 4 , 6 : 5, 7 : 6, 8 : 7, 9 : 8}\n",
    "\n",
    "ground_truth_samples = df.loc[(df['Sample Indicator'] == 0)]\n",
    "\n",
    "# Append rows to an empty DataFrame\n",
    "for i in tqdm(idx, desc=\"creating bar graph numbers\"):\n",
    "        \n",
    "    ground_truth_v1     = float(ground_truth_samples.loc[(ground_truth_samples['ID'] == i)]['Brain Correlation V1'])\n",
    "    ground_truth_v2     = float(ground_truth_samples.loc[(ground_truth_samples['ID'] == i)]['Brain Correlation V2'])\n",
    "    ground_truth_v3     = float(ground_truth_samples.loc[(ground_truth_samples['ID'] == i)]['Brain Correlation V3'])\n",
    "    ground_truth_v4     = float(ground_truth_samples.loc[(ground_truth_samples['ID'] == i)]['Brain Correlation V4'])\n",
    "    ground_truth_ev     = float(ground_truth_samples.loc[(ground_truth_samples['ID'] == i)]['Brain Correlation Early Visual'])\n",
    "    ground_truth_hv     = float(ground_truth_samples.loc[(ground_truth_samples['ID'] == i)]['Brain Correlation Higher Visual'])\n",
    "    ground_truth_nsd    = float(ground_truth_samples.loc[(ground_truth_samples['ID'] == i)]['Brain Correlation NSD General'])\n",
    "    \n",
    "    single_sample = df.loc[(df['ID'] == i)]\n",
    "    single_sample = single_sample[:-2]\n",
    "    \n",
    "    for folder, value in folders.items():\n",
    "    \n",
    "        v1_bc = single_sample.loc[(single_sample['Sample Indicator'] == value)]['Brain Correlation V1'].mean()\n",
    "        v2_bc = single_sample.loc[(single_sample['Sample Indicator'] == value)]['Brain Correlation V2'].mean()\n",
    "        v3_bc = single_sample.loc[(single_sample['Sample Indicator'] == value)]['Brain Correlation V3'].mean()\n",
    "        v4_bc = single_sample.loc[(single_sample['Sample Indicator'] == value)]['Brain Correlation V4'].mean()\n",
    "        ev_bc = single_sample.loc[(single_sample['Sample Indicator'] == value)]['Brain Correlation Early Visual'].mean()\n",
    "        hv_bc = single_sample.loc[(single_sample['Sample Indicator'] == value)]['Brain Correlation Higher Visual'].mean()\n",
    "        nsd_bc = single_sample.loc[(single_sample['Sample Indicator'] == value)]['Brain Correlation NSD General'].mean()\n",
    "\n",
    "        if(v1_bc > ground_truth_v1):\n",
    "            v1[list_indicator[value]] += 1\n",
    "            \n",
    "        if(v2_bc > ground_truth_v2):\n",
    "            v2[list_indicator[value]] += 1\n",
    "            \n",
    "        if(v3_bc > ground_truth_v3):\n",
    "            v3[list_indicator[value]] += 1\n",
    "            \n",
    "        if(v4_bc > ground_truth_v4):\n",
    "            v4[list_indicator[value]] += 1\n",
    "        \n",
    "        if(ev_bc > ground_truth_ev):\n",
    "            ev[list_indicator[value]] += 1\n",
    "            \n",
    "        if(hv_bc > ground_truth_hv):\n",
    "            hv[list_indicator[value]] += 1\n",
    "            \n",
    "        if(nsd_bc > ground_truth_nsd):\n",
    "            nsd[list_indicator[value]] += 1\n",
    "            \n",
    "print(v1)\n",
    "print(v2)\n",
    "print(v3)\n",
    "print(v4)\n",
    "print(ev)\n",
    "print(hv)\n",
    "print(nsd)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Bar Plots\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "\n",
    "\n",
    "# x = [\"vdvae\", \"clip\", \"clip+\\nvdvae\", \"iter 0\", \"iter 1\", \"iter 2\", \"iter 3\", \"iter 4\", \"iter 5\"]\n",
    "# x = [\"V1\", \"V2\", \"V3\", \"V4\", \"Early \\nVisual\", \"Higher \\nVisual\", \"NSD \\nGeneral\"]\n",
    "\n",
    "# vdvae       = [v1[0], v2[0], v3[0], v4[0], ev[0], hv[0], nsd[0]]\n",
    "# clip        = [v1[1], v2[1], v3[1], v4[1], ev[1], hv[1], nsd[1]]\n",
    "# clip_vdvae  = [v1[2], v2[2], v3[2], v4[2], ev[2], hv[2], nsd[2]]\n",
    "# iter_0      = [v1[3], v2[3], v3[3], v4[3], ev[3], hv[3], nsd[3]]\n",
    "# iter_1      = [v1[4], v2[4], v3[4], v4[4], ev[4], hv[4], nsd[4]]\n",
    "# iter_2      = [v1[5], v2[5], v3[5], v4[5], ev[5], hv[5], nsd[5]]\n",
    "# iter_3      = [v1[6], v2[6], v3[6], v4[6], ev[6], hv[6], nsd[6]]\n",
    "# iter_4      = [v1[7], v2[7], v3[7], v4[7], ev[7], hv[7], nsd[7]]\n",
    "# iter_5      = [v1[8], v2[8], v3[8], v4[8], ev[8], hv[8], nsd[8]]\n",
    "\n",
    "\n",
    "x = [\"V1\", \"V2\", \"V3\", \"V4\", \"Higher \\nVisual\", \"NSD \\nGeneral\"]\n",
    "\n",
    "vdvae       = [v1[0], v2[0], v3[0], v4[0], hv[0], nsd[0]]\n",
    "clip        = [v1[1], v2[1], v3[1], v4[1], hv[1], nsd[1]]\n",
    "clip_vdvae  = [v1[2], v2[2], v3[2], v4[2], hv[2], nsd[2]]\n",
    "iter_0      = [v1[3], v2[3], v3[3], v4[3], hv[3], nsd[3]]\n",
    "iter_1      = [v1[4], v2[4], v3[4], v4[4], hv[4], nsd[4]]\n",
    "iter_2      = [v1[5], v2[5], v3[5], v4[5], hv[5], nsd[5]]\n",
    "iter_3      = [v1[6], v2[6], v3[6], v4[6], hv[6], nsd[6]]\n",
    "iter_4      = [v1[7], v2[7], v3[7], v4[7], hv[7], nsd[7]]\n",
    "iter_5      = [v1[8], v2[8], v3[8], v4[8], hv[8], nsd[8]]\n",
    "\n",
    "\n",
    "x_axis = np.arange(len(x))\n",
    "\n",
    "n = 6\n",
    "r = np.arange(n)\n",
    "width = 0.10\n",
    "\n",
    "\n",
    "plt.bar(r - width * 4, vdvae, color = '#e3342f',\n",
    "        width = width, edgecolor = 'black',\n",
    "        label='VDVAE')\n",
    "plt.bar(r - width * 3, clip, color = '#f6993f',\n",
    "        width = width, edgecolor = 'black',\n",
    "        label='CLIP')\n",
    "plt.bar(r - width * 2, clip_vdvae, color = '#ffed4a',\n",
    "        width = width, edgecolor = 'black',\n",
    "        label='CLIP+VDVAE')\n",
    "plt.bar(r - width, iter_0, color = '#38c172',\n",
    "        width = width, edgecolor = 'black',\n",
    "        label='Iteration 0')\n",
    "plt.bar(r, iter_1, color = '#4dc0b5',\n",
    "        width = width, edgecolor = 'black',\n",
    "        label='Iteration 1')\n",
    "plt.bar(r + width, iter_2, color = '#3490dc',\n",
    "        width = width, edgecolor = 'black',\n",
    "        label='Iteration 2')\n",
    "plt.bar(r + width * 2, iter_3, color = '#6574cd',\n",
    "        width = width, edgecolor = 'black',\n",
    "        label='Iteration 3')\n",
    "plt.bar(r + width * 3, iter_4, color = '#9561e2',\n",
    "        width = width, edgecolor = 'black',\n",
    "        label='Iteration 4')\n",
    "plt.bar(r + width * 4, iter_5, color = '#f66d9b',\n",
    "        width = width, edgecolor = 'black',\n",
    "        label='Iteration 5')\n",
    "\n",
    "plt.xticks(x_axis, x)\n",
    "plt.xlabel(\"Brain Areas\")\n",
    "plt.ylabel(\"Percentage of samples aligned to brain activity\")\n",
    "plt.title(\"Sample Distributions Alighned to Brain Activity (N = 897)\")\n",
    "plt.gca().yaxis.set_major_formatter(ticker.PercentFormatter(897))\n",
    "#plt.xlim(897)\n",
    "plt.legend(fontsize = \"x-small\")\n",
    "mpl.rcParams['figure.dpi'] = 500\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN to brain correlation plot\n",
    "arrays = []\n",
    "for sample in range(5):\n",
    "    arrays.append(np.load(\"/home/naxos2-raid25/kneel027/home/kneel027/Second-Sight-Archive/reconstructions/subject1/dataframes/swav_sample_{}.npy\".format(sample)))\n",
    "arrays = np.mean(np.stack(arrays), 0)\n",
    "print(arrays.shape)\n",
    "df_final_samples = df_final_samples.groupby('ID', as_index=False).mean()\n",
    "x = df_final_samples['Brain Correlation NSD General'].values.tolist()\n",
    "y = list(arrays)\n",
    "print(len(x), len(y))\n",
    "plt.scatter(x, y)\n",
    "plt.xlabel(\"Brain Correlation\", fontsize=18)\n",
    "plt.ylabel(\"SwAV\", fontsize=18)\n",
    "plt.title(\"CNN to brain correlation plot\", fontsize=20)\n",
    "mpl.rcParams['figure.dpi'] = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_iter_values = []\n",
    "\n",
    "x_iter_values.append(.701)\n",
    "x_iter_values.append(.822)\n",
    "x_iter_values.append(.830)\n",
    "x_iter_values.append(.828)\n",
    "x_iter_values.append(.831)\n",
    "x_iter_values.append(.831)\n",
    "x_iter_values.append(.833)\n",
    "x_iter_values.append(.838)\n",
    "x_iter_values.append(.758)\n",
    "\n",
    "x_labels = ['Only VDVAE', 'Only CLIP', 'CLIP+VDVAE', 'Iter 0', 'Iter 1','Iter 2','Iter 3','Iter 4','Iter 5']\n",
    "x_axis = np.arange(len(x_labels))\n",
    "# y_labels = [\"0\", \"2\", \"4\", \"6\", \"8\", \"10 >=\"]\n",
    "# y_axis = np.arange(len(y_labels))\n",
    "\n",
    "# x_iter_values.append(0)\n",
    "# x_iter_values.append(x_v4)\n",
    "# x_iter_values.append(x_v3)\n",
    "# x_iter_values.append(x_v2)\n",
    "# x_iter_values.append(9)\n",
    "\n",
    "# x_labels = ['Higher Visual', 'V4', 'V3', 'V2', 'V1']\n",
    "plt.xticks(x_axis, x_labels)\n",
    "# plt.yticks(y_axis, y_labels)\n",
    "plt.plot(x_iter_values, marker='o', linewidth=2, color = \"darkgray\")\n",
    "plt.xlabel(\"Search Iterations\", fontsize=18)\n",
    "plt.ylabel(\"Inception V3\", fontsize=18)\n",
    "mpl.rcParams['figure.dpi'] = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average Iteration Brain Region Plot\n",
    "\n",
    "idx = [20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, \n",
    "        64, 65, 66, 67, 68, 69, 71, 72, 73, 74, 75, 77, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 106, 107, 108, \n",
    "        109, 110, 111, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145,\n",
    "        147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, \n",
    "        182, 183, 184, 185, 186, 188, 189, 190, 191, 192, 193, 194, 195, 196, 198, 199, 200, 201, 202, 203, 205, 206, 207, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, \n",
    "        221, 222, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 256, 257, \n",
    "        258, 259, 261, 262, 263, 264, 265, 266, 267, 268, 270, 272, 273, 274, 275, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, \n",
    "        297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, \n",
    "        333, 334, 335, 336, 337, 338, 339, 341, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 364, 365, 366, 367, 368, 369, 370, \n",
    "        371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 393, 394, 395, 396, 397, 398, 400, 401, 402, 403, 404, 406, 407, 408, \n",
    "        409, 410, 411, 412, 413, 414, 415, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, \n",
    "        447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 481, 482, \n",
    "        483, 484, 485, 486, 487, 488, 489, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, \n",
    "        521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 547, 548, 549, 551, 552, 553, 554, 555, 556, 557, \n",
    "        558, 559, 560, 561, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, \n",
    "        594, 595, 596, 597, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 616, 617, 618, 619, 620, 621, 622, 624, 625, 626, 627, 628, 629, 630, 631, 632, \n",
    "        633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 655, 656, 657, 659, 661, 662, 663, 664, 666, 667, 668, 669, 670, 671, \n",
    "        672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 694, 695, 696, 698, 699, 700, 701, 702, 703, 704, 705, 706, 708, 709, \n",
    "        710, 711, 712, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, \n",
    "        747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 782, 783, \n",
    "        784, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819,\n",
    "        820, 821, 822, 823, 824, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 838, 839, 840, 841, 842, 843, 844, 845, 847, 848, 849, 851, 852, 854, 855, 856, 857, 858, 859,\n",
    "        861, 862, 863, 864, 865, 866, 867, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 892, 893, 894, 895, 896, 897, \n",
    "        898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 911, 912, 913, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, \n",
    "        934, 936, 937, 938, 939, 940, 941, 942, 943, 944, 945, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961, 962, 963, 964, 965, 966, 967, 968, 969, 970, \n",
    "        971, 974, 976, 977, 978, 979, 980, 981]\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.cm as cmx\n",
    "import seaborn as sns\n",
    "\n",
    "brain_correlation_V1 = []\n",
    "brain_correlation_V2 = []\n",
    "brain_correlation_V3 = []\n",
    "brain_correlation_V4 = []\n",
    "brain_correlation_HV = []\n",
    "brain_correlation_NSD = []\n",
    "\n",
    "folders = {\"vdvae_distribution\" : 2, \"clip_distribution\" : 1, \"clip+vdvae_distribution\" : 3, \"iter_0\" : 4, \"iter_1\" : 5 , \"iter_2\" : 6, \"iter_3\" : 7, \"iter_4\" : 8, \"iter_5\" : 9}\n",
    "x = [\"vdvae\", \"clip\", \"clip+\\nvdvae\", \"iter 0\", \"iter 1\", \"iter 2\", \"iter 3\", \"iter 4\", \"iter 5\"]\n",
    "\n",
    "v1 = {2 : [], 1: [], 3: [], 4 : [], 5 : [], 6: [], 7: [], 8: [], 9: []}\n",
    "v2 = {2 : [], 1: [], 3: [], 4 : [], 5 : [], 6: [], 7: [], 8: [], 9: []}\n",
    "v3 = {2 : [], 1: [], 3: [], 4 : [], 5 : [], 6: [], 7: [], 8: [], 9: []}\n",
    "v4 = {2 : [], 1: [], 3: [], 4 : [], 5 : [], 6: [], 7: [], 8: [], 9: []}\n",
    "hv = {2 : [], 1: [], 3: [], 4 : [], 5 : [], 6: [], 7: [], 8: [], 9: []}\n",
    "nsd = {2 : [], 1: [], 3: [], 4 : [], 5 : [], 6: [], 7: [], 8: [], 9: []}\n",
    "\n",
    "\n",
    "for i in idx:\n",
    "    \n",
    "    sample = df.loc[(df['ID'] == i)]\n",
    "        \n",
    "    for folder, sample_indicator in folders.items():\n",
    "\n",
    "        iteration_val_v1 = sample[(df['Sample Indicator'] == sample_indicator)]['Brain Correlation V1'].var()\n",
    "        iteration_val_v2 = sample[(df['Sample Indicator'] == sample_indicator)]['Brain Correlation V2'].var()\n",
    "        iteration_val_v3 = sample[(df['Sample Indicator'] == sample_indicator)]['Brain Correlation V3'].var()\n",
    "        iteration_val_v4 = sample[(df['Sample Indicator'] == sample_indicator)]['Brain Correlation V4'].var()\n",
    "        iteration_val_hv = sample[(df['Sample Indicator'] == sample_indicator)]['Brain Correlation Higher Visual'].var()\n",
    "        iteration_val_nsd = sample[(df['Sample Indicator'] == sample_indicator)]['Brain Correlation NSD General'].var()\n",
    "        \n",
    "        v1[sample_indicator].append(iteration_val_v1)\n",
    "        v2[sample_indicator].append(iteration_val_v2)\n",
    "        v3[sample_indicator].append(iteration_val_v3)\n",
    "        v4[sample_indicator].append(iteration_val_v4)\n",
    "        hv[sample_indicator].append(iteration_val_hv)\n",
    "        nsd[sample_indicator].append(iteration_val_nsd)\n",
    "    \n",
    "# for sample_indicator, variance_list in v1.items():\n",
    "#         brain_correlation_V1.append(sum(variance_list) / len(variance_list))\n",
    "#         brain_correlation_V2.append(sum(v2[sample_indicator]) / len(v2[sample_indicator]))\n",
    "#         brain_correlation_V3.append(sum(v3[sample_indicator]) / len(v3[sample_indicator]))\n",
    "#         brain_correlation_V4.append(sum(v4[sample_indicator]) / len(v4[sample_indicator]))\n",
    "#         brain_correlation_HV.append(sum(hv[sample_indicator]) / len(hv[sample_indicator]))\n",
    "#         brain_correlation_NSD.append(sum(nsd[sample_indicator]) / len(nsd[sample_indicator]))\n",
    "\n",
    "for sample_indicator, variance_list in v1.items():\n",
    "        brain_correlation_V1.append(variance_list)\n",
    "        brain_correlation_V2.append(v2[sample_indicator])\n",
    "        brain_correlation_V3.append(v3[sample_indicator])\n",
    "        brain_correlation_V4.append(v4[sample_indicator])\n",
    "        brain_correlation_HV.append(hv[sample_indicator])\n",
    "        brain_correlation_NSD.append(nsd[sample_indicator])\n",
    "        \n",
    "# fig, axs = plt.subplots()\n",
    "\n",
    "\n",
    "\n",
    "# axs.scatter(x, brain_correlation_V1)\n",
    "# scatter_nsd = { \"labels\": [\"vdvae\", \"clip\", \"clip+\\nvdvae\", \"iter 0\", \"iter 1\", \"iter 2\", \"iter 3\", \"iter 4\", \"iter 5\"], \n",
    "#                 \"correlation\":  brain_correlation_NSD}\n",
    "\n",
    "df_data = pd.DataFrame(columns = ['Search Iterations', 'Brain Area', 'Variance Of Brain Correlation'])\n",
    "\n",
    "stage_labels = [\"VDVAE\", \"CLIP\", \"CLIP+VDVAE\", \"Iteration 0\", \"Iteration 1\", \"Iteration 2\", \"Iteration 3\", \"Iteration 4\", \"Iteration 5\", ]\n",
    "brain_areas = [v1, v2, v3, v4, hv, nsd]\n",
    "brain_area_labels = [\"V1\", \"V2\", \"V3\", \"V4\", \"Higher\\nVisual\", \"NSD\\nGeneral\"]\n",
    "\n",
    "df_row_num = 0\n",
    "for brain_area, label in zip(brain_areas, brain_area_labels):\n",
    "        for s, stage in enumerate([2, 1, 3, 4, 5, 6, 7, 8, 9]):\n",
    "                # print(brain_area[stage])\n",
    "                for i in tqdm(range(len(brain_area[stage]))):\n",
    "                        row = pd.DataFrame({'Search Iterations' : stage_labels[s], 'Brain Area' : label, 'Variance Of Brain Correlation' : brain_area[stage][i]}, index=[df_row_num])\n",
    "                        df_data = pd.concat([df_data, row])\n",
    "                        df_row_num += 1\n",
    "df_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(df_data.tail())\n",
    "custom_palette = [\"#e3342f\", \"#f6993f\", \"#ffed4a\", \"#38c172\", \"#4dc0b5\", \"#3490dc\", \"#6574cd\", \"#9561e2\", \"#f66d9b\"]\n",
    "\n",
    "# sns.set_palette(custom_palette)\n",
    "# sns.catplot(data=df_data, x=\"Brain Area\", y=\"Variance Of Brain Correlation\", hue=\"Search Iterations\", s=5).set(title='Variance Of Brain Correlation Across Iterations')\n",
    "# sns.barplot(data=df_data, x=\"Brain Area\", y=\"Variance Of Brain Correlation\", hue=\"Search Iterations\").set(title='Variance Of Brain Correlation Across Iterations')\n",
    "x = brain_area_labels\n",
    "x_axis = np.arange(len(x))\n",
    "\n",
    "n = 6\n",
    "r = np.arange(n)\n",
    "width = 0.10\n",
    "print(df_data.loc[df_data[\"Search Iterations\"] == \"VDVAE\"].groupby([\"Brain Area\"]).mean())\n",
    "vdvae = df_data.loc[df_data[\"Search Iterations\"] == \"VDVAE\"].groupby([\"Brain Area\"]).mean()[\"Variance Of Brain Correlation\"]\n",
    "plt.bar(r - width * 4, vdvae[2:].append(vdvae[0:2]), color = '#e3342f',\n",
    "        width = width, edgecolor = 'black',\n",
    "        label='VDVAE')\n",
    "clip = df_data.loc[df_data[\"Search Iterations\"] == \"CLIP\"].groupby([\"Brain Area\"]).mean()[\"Variance Of Brain Correlation\"]\n",
    "plt.bar(r - width * 3, clip[2:].append(clip[0:2]), color = '#f6993f',\n",
    "        width = width, edgecolor = 'black',\n",
    "        label='CLIP')\n",
    "cv = df_data.loc[df_data[\"Search Iterations\"] == \"CLIP+VDVAE\"].groupby([\"Brain Area\"]).mean()[\"Variance Of Brain Correlation\"]\n",
    "plt.bar(r - width * 2, cv[2:].append(cv[0:2]), color = '#ffed4a',\n",
    "        width = width, edgecolor = 'black',\n",
    "        label='CLIP+VDVAE')\n",
    "i0 = df_data.loc[df_data[\"Search Iterations\"] == \"Iteration 0\"].groupby([\"Brain Area\"]).mean()[\"Variance Of Brain Correlation\"]\n",
    "plt.bar(r - width, i0[2:].append(i0[0:2]), color = '#38c172',\n",
    "        width = width, edgecolor = 'black',\n",
    "        label='Iteration 0')\n",
    "i1 = df_data.loc[df_data[\"Search Iterations\"] == \"Iteration 1\"].groupby([\"Brain Area\"]).mean()[\"Variance Of Brain Correlation\"]\n",
    "plt.bar(r, i1[2:].append(i1[0:2]), color = '#4dc0b5',\n",
    "        width = width, edgecolor = 'black',\n",
    "        label='Iteration 1')\n",
    "i2 = df_data.loc[df_data[\"Search Iterations\"] == \"Iteration 2\"].groupby([\"Brain Area\"]).mean()[\"Variance Of Brain Correlation\"]\n",
    "plt.bar(r + width, i2[2:].append(i2[0:2]), color = '#3490dc',\n",
    "        width = width, edgecolor = 'black',\n",
    "        label='Iteration 2')\n",
    "i3 = df_data.loc[df_data[\"Search Iterations\"] == \"Iteration 3\"].groupby([\"Brain Area\"]).mean()[\"Variance Of Brain Correlation\"]\n",
    "plt.bar(r + width * 2, i3[2:].append(i3[0:2]), color = '#6574cd',\n",
    "        width = width, edgecolor = 'black',\n",
    "        label='Iteration 3')\n",
    "i4 = df_data.loc[df_data[\"Search Iterations\"] == \"Iteration 4\"].groupby([\"Brain Area\"]).mean()[\"Variance Of Brain Correlation\"]\n",
    "plt.bar(r + width * 3, i4[2:].append(i4[0:2]), color = '#9561e2',\n",
    "        width = width, edgecolor = 'black',\n",
    "        label='Iteration 4')\n",
    "i5 = df_data.loc[df_data[\"Search Iterations\"] == \"Iteration 5\"].groupby([\"Brain Area\"]).mean()[\"Variance Of Brain Correlation\"]\n",
    "plt.bar(r + width * 4, i5[2:].append(i5[0:2]), color = '#f66d9b',\n",
    "        width = width, edgecolor = 'black',\n",
    "        label='Iteration 5')\n",
    "\n",
    "plt.xticks(x_axis, x)\n",
    "plt.xlabel(\"Brain Areas\")\n",
    "plt.ylabel(\"Variance Of Brain Correlation Across Sample Distributions\")\n",
    "plt.title(\"Convergence of Image Distribution Variance Across Iterations\")\n",
    "#plt.xlim(897)\n",
    "plt.legend(fontsize = \"x-small\")\n",
    "mpl.rcParams['figure.dpi'] = 500\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SS_vd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
